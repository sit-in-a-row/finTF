text
"['\n4. 연구개발실적\n☞ 본문 위치로 이동\n연구과제\n개발 내용\n연구결과 및 기대효과\nShift-Left Testing\n리플레이 테스트 자동화\n사용자 입력 정보를 녹화하고, 이를 기반으로 리플레이를할 수 있는 구조를 만들어 회귀테스트를 자동으로 수행할 수 있는 도구를 개발한다.\n기획서 검증\xa0\n테이블 형태로 작성된 기획서에 대해서 게임 데이터와 연동하여 실시간 오류를 검증할 수 있는 도구, 이를 통해 기획단계에서 오류를 빠르게 검출하여 테스트 비용을 낮추는 방식을 도입한다.\nCI/CD 프로세스\n정규화된 프로세스 구축\n정규화 된 배포 프로세스를 구축하고, 이를 통해 가장 빠르고, 안정적인 배포 할 수 있는 개발 환경을 구축한다.\n4족 보행 애니메이션\n절차적 경로 모션 생성\n내비게이션 포인트를 연속적으로 부드럽게 이동하는 경로 애니메이션을 하나의 기초 애니메이션으로부터 절차적으로 생성하는 기술로서 4족 동물 애니메이션 생산 비용과 MMO 게임의 리소스 예산을 절감할 수 있다.\n모션 매칭 시스템\n게임 엔진 용 모션 매칭 시스템\n기존 애니메이션 시스템과 혼용하여 사용할 수 있고 모션 DB를 효율적으로 검색할 수 있는 모션 매칭 시스템을 자체 개발함으로써, 비구조적인 모션 캡쳐 데이터를 사용하여 기존에는 표현이 힘들었던 풍부한 애니메이션을 구현할 수 있다.\n풀바디 \xa0IK시스템\n(IK: Inverse Kinematics)\nIK 솔버\n풀바디 IK에 필요한 여러 바디 파츠와 관절 제약을 동시에 계산할 수 있는 IK 솔버를 개발하여 게임 캐릭터에 실시간으로 IK를 적용할 수 있다.\n2족/4족 보행 포즈 솔루션\n다양한 경사로에서 2족/4족 캐릭터의 보행 포즈를 균형 잡히고 부드러운 연속 모션으로 생성해주어 게임 내 여러 지형 환경에서 자연스러운 캐릭터 애니메이션을 표현할 수 있다.\n인게임 컷씬 연출\n컷씬 에디터\n사용자 친화적인 인터페이스의 컷신 에디터를 개발하여, 게임플레이 화면과 컷씬 간의 끊김없는 전환과 동적 분기 및 다국어 자막 통합 관리 등을 지원한다.\n실시간 GI 개선\n*GI : Global Illumination)\n실시간 GI 성능 개선\n공간 분석을 통한 효율적인 라이트 프로브 배치 자동화와 독자적인 근거리 간접광 계산을 사용하여 결함이 적으면서 효율적인 실시간 GI 솔루션을 제공한다.\n게임 최적화 UI tool chain 개발\xa0\nUI engine 개발\n게임 엔진 및 서비스 플랫폼 환경과 무관하게 고품질 UI를 제작하고 다양한 게임에 재활용할 수 있다.\xa0\nUI Authoring tool 개발\n제공한 도구들은 기존 UI개발 워크플로의 문제를 효과적으로 개선한다. 또한 UX가 검증된 UI 템플릿을 활용해 기초 작업을 생략할 수 있다. 이를 통해 디자이너 주도의 효율적인 UI제작이 가능하다.\xa0\nguide 방식 hair 시스템\nguide 방식의 interactive groom으로 효율적인 헤어 제작\n기존 보다 가벼운 데이터로 시뮬레이션 및 베이크 가능한 guide 방식의 Interactive groom을 도입하여 데이터 양에 따른 엔진의 렌더링 에러 및 헤어 제어의 문제를 해결하고 효율적인 헤어 제작 가능\n헤어 시뮬레이션\n엔진에서 헤어의 디테일한 움직임 구현\n엔진에서 디테일하고 실제와 같은 헤어를 구현하기 위해, 기존 XGen 및 guide 방식의 헤어를 시뮬레이션하고 베이킹하여 영상에 적용할 수 있는 기술 구현\nFACS (Facial Action Cording System) rig skinning\nUnreal Engine에서 캐릭터의 디테일한 페이셜을 구현\n기존 blend shape 방식은 버텍스의 노멀을 엔진에서 제대로 표현하지 못해 눈꺼풀 및 얼굴 주름의 디테일한 표현 시에 쉐이딩이 제대로 되지 않아 얼룩이 생기는 문제가 발생하였고, 이를 해결하기 위하여 skinning 방식으로 변환\nBifrost를 활용한 실시간 FACS target\n기존 대비 효율적인 FACS 타겟의 구성\nFACS 기존 구성 방식 보다 파일 관리 및 분리 작업 시간을 획기적으로 단축하고, 작업과 동시에 페이셜 데이터의 수정 작업이나 분리작업이 가능. 이로 인해 타겟 수정 부담을 줄이고, 퀄리티를 높이는데 용이\n메타휴먼 페이셜 애님 트랙 추출\n메타휴먼 혹은 메타휴먼 릭을 사용할 때 페이셜 키를 추출\n기존 메타휴먼의 페이셜 데이터는 컨트롤 리그에 키 데이터를 적용해야만 페이셜이 확인 가능하여, 페이셜을 수정하거나 길이 수정을 할 때 타이밍 및 데이터 입력 오류 등의 이슈가 있었고, 이를 페이셜 부분만 애님 시퀀서로 교체하여, 페이셜 수정이 용이하도록 구성\n페이셜 애니메이션\n광학식 마커 데이터 테스트 및 활용\n광학식 마커 방식 테스트로 기존 마커 방식에서 문제가 되었던 데이터의 왜곡이나 흔들림 등을 해결하고 선행 테스트로 문제점 파악\nbody 관절 디테일 향상 기법\n디지털 캐릭터의 디테일한 관절 구현\n디지털 캐릭터 관절이 움직일 때 접혀지는 부분의 근육 표현이나, 잘못된 형태로 접히는 것을 방지하기 위해 추가 디폼 컨트롤러 및 타겟 등의 보정으로 관절 부분 디테일을 높일 수 있는 기술 구현\n디지털 휴먼의 근육 시뮬레이션\n디지털 휴먼의 디테일 높은 근육 표현\n사실적인 근육 움직임을 리깅에 구현하여 캐릭터의 움직임에 맞는 근육 표현\n의복 물리 시뮬레이션 (Bake)\n캐릭터의 의복을 디테일하고 볼륨감 있게 표현\n마블러스의 재봉선에 맞게 제작된 의복들에 실제 애니메이션을 적용하여, 더욱 디테일하고 자연스러운 의복의 움직임을 표현\n군중 시뮬레이션\n디지털 캐릭터의 군중 표현\n다양한 캐릭터의 군중 시뮬레이션 구현으로 대규모 전쟁 및 많은 수의 캐릭터 움직임을 효과적으로 표현\nVFX VDB 활용\nVDB plug-in Unreal Engine 5 적용\nopen VDB를 nano VDB로 바꿔서 데이터를 줄임으로써, 렌더링 부하를 줄이거나 VDB를 3d Volume Texture로 쉽게 변경함으로 VFX 퀄리티 향상 기여\nUSD의 언리얼 환경 적용\n툴 간에 데이터 호환이 가능하게 하는 USD의 엔진 적용\n서로 다른 툴 간에 데이터의 호환이 가능한 USD를 테스트 함으로써, 언리얼 엔진에서 마야, 맥스, 후디니 간 데이터 호환 여부 확인. 차후 다른 툴에서 영상 렌더링까지 가능하도록 계획\nToon shading\n언리얼 엔진에서 툰 느낌의 영상 구현\n언리얼 엔진에서 카툰 느낌의 영상을 제작하기 위해 각 캐릭터별 쉐이더, 포스트 쉐이더, 배경분할 등을 통한 각 단위의 컬러변형, 마스킹 등을 통하여 셀 쉐이딩 구현\ncustom import tool\nUnreal Engine에서 애니메이션을 빠르게 임포트 할 수 있는 툴 구현\n기존 FBX 방식 대비 애니메이션에 사용되는 정보만 추출하여 빠르게 export & import 가능한 플러그인 구축\ncustom render pass\n합성 혹은 컬러그레이딩을 위한 채널 분리 시스템\n엔진에서 후반 혹은 합성 작업 시, 배경, 캐릭터, 포그 등의 데이터들을 따로 분리하여 영상 출력함으로써, 합성 혹은 컬러그레이딩에 효과적으로 분리된 레이어들을 활용\nAlembic cache streaming\xa0\nAlembic 캐쉬를 스트리밍하여 처리 속도를 높임\n언리얼 엔진에서 alembic 파일을 기존의 alembic Import가 아닌 스트리밍 방식으로 변환하여, 데이터 임포트 시간, 전체적인 데이터의 부하 그리고 비디오 메모리 오버를 통한 크래쉬를 줄이기 위한 기술\n광학식 Finger 서비스\n광학식 장비를 활용한 손가락 모션캡처 데이터 제공\n기존 광학식 모션캡처 시스템에서 Body와 Finger를 동시에 촬영하고 그 데이터를 제공함으로써 애니메이션 작업을 보다 효율화하고 사실적인 움직임을 구현할 수 있음\n모션캡쳐 실시간 언리얼 프리뷰 환경 지원\n바디, 페이셜, 핑거 등 풀퍼포먼스 모션캡쳐 시 언리얼 실시간 프리뷰 환경 구성\n풀퍼포먼스 모션캡쳐 촬영 시 게임 환경이 구성되어 있는 언리얼에 실시간으로 구현하여 촬영하면서 바디, 페이셜, 핑거 등이 적용된 캐릭터를 직관적으로 확인이 가능할 수 있게 하고, 실시간 디지털 휴먼 개발에 필요한 환경을 제공\n바이브 트래커를 이용한 자이로 장비 개선\nXsens 자이로 모션캡쳐 수트 장비에 Vive 장비를 결합하여 모션캡쳐 데이터 퀄리티 개선\nRotation 데이터를 사용하여 촬영되는 자이로 모션캡쳐 시스템에 Translate 값을 보정해 줄 수 있는 VIVE 장비를 같이 착용하고 촬영함으로써 보다 정확한 위치값을 가진 데이터를 얻을 수 있음\nDynamyXYZ와 Faceware 간 호환성 연구\nDynamiXYZ를 사용하는 개발실을 위해 Faceware촬영 데이터와 호환성 검증\n두 페이셜 캡쳐 장비간 촬영 데이터 교차적용으로 트래킹 및 리타겟 품질 비교 후 호환 가능 확인. DynamiXYZ 서비스 종료에 따라 이를 지속적으로 사용하는 개발실에 Faceware 촬영 데이터로도 서비스 가능.\n극사실주의 캐릭터 표현\n4D Capture 기술을 활용한 극사실적인 페이셜 스캔\n4D Capture 파이프라인을 구축하여 자연스러운 페이셜 데이터를 캐릭터에 적용해 사용자의 경험과 몰입감을 극대화. 다양하게 활용할 수 있는 기술 기반을 마련\n다수의 스캔을 혼합하여 극사실적인 캐릭터 생성\n다수의 캐릭터 스캔 데이터를 혼합하여 사실적이고 개성 있는 디지털 캐릭터를 생성. 다양하게 활용할 수 있는 기술 기반을 마련\nLight Cage를 이용한 극사실적인 질감 스캔\nLight Cage스캔 기술 연구를 통해 추출한 극사실적인 질감 데이터를 캐릭터에 적용해 사용자의 경험과 몰입감을 극대화. 다양하게 활용할 수 있는 기술 기반을 마련\n메타휴먼 리그에 스캔 데이터 연동\n메타휴먼 리그와 스캔을 연동하여 스캔 활용성 확장\n언리얼 엔진의 메타휴먼 리그를 스캔 결과물과 연동하여 개발 환경에서의 스캔 데이터 작업 편의성 및 효율성을 높임. 다양하게 활용할 수 있는 기술 기반을 마련\n극사실주의 배경 표현\n모듈화 기법을 통해 스캔 데이터를 효율적으로 활용\n극사실적인 배경 스캔 데이터를 모듈화 하여 데이터 작업 편의성 및 효율성을 높임. 다양하게 활용할 수 있는 기술 기반을 마련\n언리얼 엔진 나나이트 활용한 스캔 프로세스 확장\n언리얼 엔진 나나이트에 적합한 스캔 프로세스를 구축하여 나나이트 활용성을 높임. 다양하게 활용할 수 있는 기술 기반을 마련\n광대역 스캔 기법을 이용해 극사실적인 레벨을 구축\n광대역 스캔 기법을 활용해 실제 구역을 빠르게 스캔하여 사실적이고 정확한 레벨을 구현. 다양하게 활용할 수 있는 기술 기반을 마련\n차세대 스캔방식 연구\nNeRF(Neural Radience Fields) 추적 연구 및 활용범위 확장\nAI를 활용한 스캔 방식인 NeRF 를 추적 연구하여 게임 및 영상 제작에 활용될 수 있는 환경을 구축\nFacial시스템 (인게임 및 디지털휴먼)\nFacial Rig 자동화 구현\n캐릭터의 표정을 만들어내는 Facial Rig을 범용성을 기준으로 자동화 제작하여, 캐릭터 제작 및 페이셜 애니메이션 표현에 있어서 효율 향상을 제공한다.\nFacial Rig의 표정 메쉬 복제 기술 구현\n캐릭터의 Facial Rig을 구성할 때, 포토스캔으로 만들어 둔 다른 모델의 표정을 복제하여 보다 쉽게 자연스럽고 특징 있는 표정을 만들어 낼 수 있다.\nFacial Rig의 표정 메쉬 제작에 4D 캡쳐 데이터 응용\n캐릭터의 Facial Rig을 구성할 때 사용했던 표정 메쉬 리스트에 4D캡쳐 데이터(애니메이션을 실시간 3D데이터로 변환한 것)를 응용하여 품질을 보완하고 지속적으로 업데이트한다.\n게임 플레이에서 캐릭터의 표정을 상황에 맞게 출력하는 기술 구현\n인게임 캐릭터의 반복된 표정 애니메이션 출력 설정을 간소화할 수 있는 제작 기술을 구현하여, AI 립싱크 애니메이션에 응용할 수 있는 기반을 마련한다.\n3D메쉬 Tension View 기능\n메타휴먼 토폴로지에 맞춘 페이셜 시스템\n메타휴먼 캐릭터의 토폴로지와 싱크를 맞추어 다양한 캐릭터 데이터의 활용성을 확장한다.\n3D메쉬 Tension View 기능\n매쉬의 변화를 실시간 버텍스 컬러로 전환하여 보여주는 기능 구현\n메쉬의 움직임에 따라 변화하는 상태를 버텍스 컬러로 전환하고, 이를 응용하면 캐릭터나 의상의 주름 표현을 보다 자연스럽게 연출할 수 있다.\n3D메쉬 Fitting 기능\n3D메쉬의 변형된 외형에 기 제작된 3D 아이템의 형태를 맞춰주는 기능 구현\n기존에 제작된 의상 등 변형이 필요한 다량의 3D매쉬를 나중에 제작된 캐릭터의 다양한 형태에 맞춰 조정하여, 수정에 따른 제작 비용을 절감케 해주는 기능을 구현한다.\n디지털 액터 모션 공유 과정 구성\n디지털 액터에 사용할 바디 및 페이셜 모션을 공유할 수 있는 제작 과정을 구성\n디지털 액터의 뼈대 구성을 통일 후 리타게팅 하는 방법으로 바디 및 페이셜 애니메이션을 자연스럽게 공유하는 제작 과정을 구성하여, 디지털 액터 애니메이션 제작 효율을 높인다.\n전투 시스템\n전투 상황별 조건 설정 및 인터렉션 구현\n공격 위치, 대상과의 거리 조절, 회피, 가드, 공격 형태에 따른 데미지 범위 등 다양한 전투 상황을 설정하고, 다양한 인터렉션 연출을 구현하여, 몰입도 있는 전투 경험을 제공한다.\nCamera연출 기술\n게임 플레이에서 카메라 연출 자동화 기술 정립\n인게임 캐릭터의 상황에 따라 자연스러운 카메라 워크가 제작자의 의도를 반영하여 연출될 수 있도록 구성하여, 플레이 몰입도를 향상시킬 수 있는 기술을 정립한다.\n캐릭터 Customizing\n해부학 기반 캐릭터 커스터마이징 기술 구현\n인체의 뼈대, 근육을 바탕으로 캐릭터의 외형을 해부학을 기반으로 변경 가능하는 기술을 구현한다.\nGroom Hair\n거리별 헤어 표현 방법 리서치\n품질 높은 헤어 표현 수단인 Groom을 활용하기 위해 최적화 기술을 적극적으로 사용하기 위한 제작 방법을 연구한다.\n모션 매칭 R&D\n고품질의 이동 애니메이션 구현\n실시간 애니메이션 포즈 매칭 시스템으로 상황에 맞는 사실적인 고품질의 캐릭터 이동 모션을 구현한다.\nWater System\n언리얼 엔진과 플러그인 활용 리서치\n언리얼 엔진에서의 Water와 Fluid플러그인을 활용하여 사실적인 물표현을 다양하고 쉽게 사용할 수 있는 방법을 연구한다.\xa0\n제작 편의성 Tool\n배경 제작 편의 Tool 리서치\xa0\n배경 제작에 있어서 효율적으로 제작할 수 있는 다양한 편의성 Tool을 연구한다.\n업무 효율화 플랫폼\n프로젝트 관리도구\nNC 사용성에 기반한 프로젝트 관리 Tool 구축/서비스를 통한 전사 프로젝트 관리 프로세스 개선 및 효율 증대\n아트 소통 및 외주 프로덕션 관리도구\n아트 결과물 관리, 효율적 아트 협업 위한 전문 도구를 제공하여 아트 제작 효율성 향상\n통합업무관리 플랫폼\nHQ/지사/3rd Party 간 직접 소통 가능하며, 조직 업무관리부터 게임개발 프로세스까지 아우르는 통합 업무관리 서비스 구축을 통해 NC 협업 효율 제고\n글로벌 L10N 플랫폼\nL10N text 리소스 관리 및 송수신 효율화 도구\nText 로컬라이제이션에 소요되는 송수신 업무의 자동화/리소스 관리도구 개발 및 업무 표준화를 통하여 NC text 로컬라이제이션 협업 효율 증대 및 에러 감축\nL10N voice 음성녹음 통합업무관리도구\nVoice 녹음 업무/ Voice 리소스 로컬라이제이션 업무의 통합관리 플랫폼 구축 및 업무 표준화를 통하여 데이터 축적 및 NC 글로벌 음성 로컬라이제이션 협업 환경 고도화\n연구과제\n연구주제\n연구결과 및 기대효과\n영상 AI 기술\n사진 기반 게임 캐릭터 생성 기술\n인물 사진으로부터 게임 캐릭터를 자동으로 생성하는 기술로 사진과 닮은 게임 캐릭터를 쉽게 생성할 수 있는 기능을 제공 가능.\xa0\n2D 디지털휴먼 자동 생성 기술\n딥페이크에서 파생되는 여러 얼굴 영상 합성 기술들을 활용하여 2D 영상 형태의 디지털휴먼을 자동으로 생성해내고 디지털휴먼을 이용한 콘텐츠들을 쉽게 생성하게 하기 위한 다양한 기술 개발.\xa0\n일반 카메라 기반 모션 캡처 기술\n고가의 모션 캡처 장비나 수트 없이도 일반 카메라를 통해서도 모션 캡처를 가능하게 하여 게임 애니메이션 제작 및 영상 제작의 시간과 비용을 크게 단축하게 할 수 있음.\n인물 행동 기반 영상 이해 기술\n영상에서 사람의 행동을 이해하는 기술을 통해 디지털휴먼이 영상 내에서 사용자의 특정 동작을 인지하여 더 풍부한 대화를 이끌어 낼 수 있게 함. 또한 축적된 대량의 영상 데이터를 보다 쉽게 검색하거나, 영상의 메타 데이터를 자동으로 Tagging하게 할 수 있는 시스템 개발할 수 있음.\n야구 하이라이트 영상 생성 기술\n야구 중계 영상에서 특정 이벤트에 해당하는 영상 구간을 찾아내서 야구 중계에 필수적인 하이라이트 영상을 자동으로 만들어내는 기술 개발\n드론 영상을 위한 실시간 영상 인식 기술\n드론 카메라를 통해 입력되는 영상 정보에서 인물/물체/장소 정보 등을 실시간으로 인식하는 기술을 개발함. 딥러닝 기반 인식 모델의 경량화 및 최적화 기술과 열악한 실제 환경에서의 영상 인식 기술을 개발함.\n뉴럴렌더링 기반 3D 아바타 생성 기술\n3D 스캔 및 모델링, 리깅 과정 없이, 몇 대의 카메라로 촬영된 영상에서 사실적인 3차원 휴먼 아바타를 제작하는 기술 개발.  NeRF 기반 뉴럴렌더링 기술 연구를 통해 디지털 휴먼 및 3D 모델 제작의 시간과 비용을 크게 단축하게 할 수 있음.\n인터랙티브 디지털휴먼을 위한 영상 인지 기술\n디지털휴먼이 영상 내에서 사용자의 표정과 제스처를 인식하여 감정 상태를 파악하여 자연스럽고 적절한 대화를 하거나,  주변의 물건 및 상황을 인지하여 능동적이고 풍부한 대화할 수 있게 함. 거대 언어모델 기반으로 멀티모달 인지로의 확장 연구 진행\nAI 기반 컨텐츠 생성 기술\n생성형 AI 기술을 통하여 게임 아트 리소스나 디지털휴먼 관련 동영상 컨텐츠를 효율적으로 제작하는 기술 개발.\n음성 AI 기술\n다국어 음성 인식 기술\n한국어 포함 해외 서비스에 필요한 다국어를 인식하는 기술 개발 진행 (영어, 중국어, 일어 등 주요 언어 포함)\n다국어 음성 합성 기술\n특정 사람의 목소리를 담아 인위적으로 사람의 대화 소리를 합성하는 AI 기술 개발 진행\n한국어 이외에 영어, 중국어 등 해외 서비스에 필요한 다국어를 자동으로 생성하는 기술 개발 진행\n감정인식 기술\n주로 음성 정보를 사용하여 발화자의 현재 감정을 인식하는 AI 기술 개발 진행\n감정표현 음성 합성 기술 개발 및 고도화\n슬픔, 행복, 분노 등 다양한 감정의 표현 및 강약까지 조절가능한 소리를 합성하는 AI 기술 개발 진행\n연기(영화, 드라마), 뉴스, 정보전달, 독서 등 다양한 콘텐츠의 여러 상황에서 어울리는 음성을 생성할 수 있음\n음성 변환 (Voice Conversion) 기술\n입력한 음성을 특정인물이나 가상인물의 목소리로 변환하거나, 길이, 높낮이, 음색에 변화를 주어 다양한 콘텐츠에서 상황에 어울리는 효과를 제공할 수 있는 기술로, 목소리의 익명화에도 응용 가능한 기술 개발\n대화형 Agent를 위한 음성 응용 기술\n(Low-Latency, 중단 가능한 대화형 Agent)\n디지털휴먼이 실제 사람처럼 원활하고 중단 가능한 대화를 진행하기 위해 여러 음성 응용 기술을 개발함. 호출어 인식 기술, 화자 식별 기술, 화자 음성 분리 기술 등 세부 기술 등을 포함하고 있음\nMusic 합성/생성 관련 기술\n노래를 부르는 목소리를 합성하는 AI 기술 개발함. 정해진 악보대로 노래를 부르거나 현재 노래에 대한 화음을 넣어서 사람과 같이 노래를 불러주는 등 엔터테인먼트 콘텐츠에 다양하게 활용 가능한 응용 기술 개발을 포함함\n보이스 채팅을 위한 De-Reverberation 기술\n게임 플레이 중 혹은 카페 등 잡음이 존재하는 모든 환경에서 쾌적하고 조용한 보이스 채팅 상황을 제공하기 위해 스트리밍 환경에서의 에코 및 다른 사람의 목소리 제거 (De-Reverberation, Denoiser) 기술을 개발\n음성 자동 검수 기술\n텍스트 대사와 녹음된 음성의 일치 여부를 검사하는 AI기반 발화검증 (Utterance Verification) 기능을 개발. 사내 사용 중인 작업 도구에 내장되어 서비스 중, 발음의 정확성 평가 등에도 응용이 가능함 (한국어, 영어, 중국어 등 다국어 지원)\nAI 모델 경량화 기술\n머신 러닝으로 생성된 AI의 모델을 서버환경 이외의 환경에서도 동작 가능하도록, 성능을 유지하며 모델의 크기를 줄여 PC 혹은 휴대폰/게임기와 같은 휴대기기에서도 독립적으로 동작가능한 기술을 개발\nEnrollable Keyword Spotting 연구\n쉽게 정의할 수 있도록 한번의 발화로 사용자 호출어를 정의, 학습, 배포하는 연구 및 시스템 연구\nVirtual Speaker Generation 연구\n특정인의 짧은 음성을 분석한 후 Text로부터 특정인의 음색으로 합성이 가능한 음성합성 시스템 개발\n다양한 음색을 갖는 가상 인물의 목소리를 생성할 수 있는 음성합성 시스템 개발\nUniversal Audio Model 연구\n인식과 생성에서 다양한 역할을 수행할 수 있는 Speech/Music/Sound/Event/Singing 등을 모두 포함한 Audio용 거대모델의 개발\n그래픽스 AI 기술\n4D 기반 고품질 얼굴 애니메이션 캡처 기술\n고품질 카메라로 촬영한 사람의 얼굴 영상을 이용하여 동일한 외모와 움직임의 캐릭터를 생성하는 차세대 얼굴 캡쳐 시스템 개발.\n기존 사진 기반 3D 얼굴 스캔 기술 대비 얼굴 움직임도 동일하게 재현할 수 있기 때문에 더욱 자연스러운 캐릭터를 만들 수 있음. 디지털 더블 수준의 캐릭터 제작이 가능하며 디지털 휴먼 제작에 활용 가능.\nHMC 기반 얼굴 애니메이션 캡처 기술\n편의성이 높은 Head-Mount-Camera로 얼굴 연기를 캡쳐 하는 기술. 경쟁사 기술 대비 세밀한 움직임을 캡쳐 할 수 있어 보다 고품질의 캐릭터 얼굴 애니메이션을 간편하게 제작할 수 있음\n얼굴 애니메이션 자동 생성 기술\n음성을 발화에 적합한 얼굴 애니메이션을 AI가 자동으로 생성하는 기술. 모션 캡처나 아티스트 수작업이 필요 없고, 품질이 뛰어나서 대량의 시네마틱 영상, 다이얼로그 씬 제작에 필수적으로 요구되는 기술.\n모션 캡처 데이터 자동 후보정 기술 개발\n모션 캡처 과정에서 발생하는 마커 데이터의 오류를 AI에 의해서 자동으로 검출하고 수정하는 기술을 개발\n신경망 기반 캐릭터 애니메이션 시스템\n디지털휴먼과 게임에 모두 사용할 수 있는 딥러닝 기반 캐릭터 애니메이션 생성 기술 개발. AI 지식이 많지 않은 아트 작업자들이 쉽게 다룰 수 있도록 Controllable하게 구현하고 이를 통해 기존 게임 등에서 선보이기 차별화된 Scene을 구현할 수 있는 기술을 개발\n캐릭터 애니메이션 사운드 효과음 자동 배치 기술\n캐릭터 애니메이션 시퀀스에 효과음을 AI로 자동 배치하는 기술 개발. 사운드 디자이너들의 단순 반복 작업을 줄이고, 사운드 에셋 생성이나 편집 등 창의적 활동에 더 많은 시간을 쏟을 수 있도록 도움을 줄 수 있음\n제스처 애니메이션 자동 생성 기술\n대화형 디지털 휴먼에 활용하기 위하여, 대화 내용과 상황에 적합한 제스처를 생성하고, 사람의 무의식적인 동작 생성을 생성하는 기술. 제스처를 통해 정보 전달력을 높이고, 일상 행동으로 사실성과 친밀감을 높일 수 있는 등 대화를 효율적으로 수행할 수 있음.\n지능 Agent 기술\nAI 기반 PvP 게임 콘텐츠 실험 및 개발\nMMORPG PvP 콘텐츠에서 동작하는 AI들을 개발하여 새로운 형태의 게임 콘텐츠를 실험하고 제작함\nAI 기반 PvE 게임 콘텐츠 실험 및 개발\nMMORPG PvE 콘텐츠에서 동작하는 AI들을 개발하여 새로운 형태의 게임 콘텐츠를 실험하고 제작함\n']"
