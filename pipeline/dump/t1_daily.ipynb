{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from sub_func import *\n",
    "from pipeline_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_metrics(sector_info):\n",
    "    \"\"\"섹터 정보에서 Carhart 4 factor 관련 주요 지표 추출\"\"\"\n",
    "    if sector_info is None:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'market_beta': sector_info.get('market_beta', 0),\n",
    "        'size_factor': sector_info.get('size_factor', 0),\n",
    "        'value_factor': sector_info.get('value_factor', 0),\n",
    "        'momentum_factor': sector_info.get('momentum_factor', 0)\n",
    "    }\n",
    "\n",
    "def extract_sentiment_score(df):\n",
    "    \"\"\"감성분석 결과를 numerical score로 변환\"\"\"\n",
    "    def get_score(result):\n",
    "        if isinstance(result, dict):\n",
    "            # 딕셔너리에서 감성 결과 추출 (예: result.get('sentiment') 등)\n",
    "            sentiment = result.get('sentiment', 'neutral')  # 적절한 키로 수정\n",
    "        else:\n",
    "            sentiment = result\n",
    "            \n",
    "        score_mapping = {\n",
    "            'positive': 1.0,\n",
    "            'neutral': 0.0,\n",
    "            'negative': -1.0\n",
    "        }\n",
    "        return score_mapping.get(sentiment, 0.0)\n",
    "    \n",
    "    df['sentiment_score'] = df['SA_result'].apply(get_score)\n",
    "    return df\n",
    "\n",
    "def filter_by_percentile_and_label(df, label, percentile):\n",
    "    \"\"\"특정 감성의 상위/하위 percentile에 해당하는 뉴스 필터링\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # label에 따라 필터링\n",
    "    if label == 'positive':\n",
    "        filtered_df = df[df['SA_result'] == 'positive']\n",
    "        return filtered_df.nlargest(int(len(filtered_df) * percentile/100), 'sentiment_score')\n",
    "    else:  # negative\n",
    "        filtered_df = df[df['SA_result'] == 'negative']\n",
    "        return filtered_df.nsmallest(int(len(filtered_df) * percentile/100), 'sentiment_score')\n",
    "    \n",
    "def get_final_tickers(content):\n",
    "    \"\"\"content['final_portfolio']['corp_analysis_report']에서 invest가 True인 ticker 리스트 반환\"\"\"\n",
    "    corp_analysis_report = content.get('final_portfolio', {}).get('corp_analysis_report', {})\n",
    "    \n",
    "    # invest가 'True'인 ticker만 리스트로 추출\n",
    "    invest_tickers = [ticker for ticker, data in corp_analysis_report.items() if data.get('invest') == 'True']\n",
    "    \n",
    "    return invest_tickers\n",
    "\n",
    "def get_tickers_from_json(agent_type, title):\n",
    "    data = read_json(json_file_path)\n",
    "    if agent_type in data and title in data[agent_type]:\n",
    "        page_id = data[agent_type][title]\n",
    "        content = get_all_text_from_page(page_id)\n",
    "        \n",
    "    try:\n",
    "        data = read_json(json_file_path)\n",
    "        if agent_type in data and title in data[agent_type]:\n",
    "            page_id = data[agent_type][title]\n",
    "            content = eval(get_all_text_from_page(page_id))\n",
    "            tickers = get_final_tickers(content)\n",
    "\n",
    "            return tickers\n",
    "        else:\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "def get_analyst_rp(agent_type, title):\n",
    "    data = read_json(json_file_path)\n",
    "    if agent_type in data and title in data[agent_type]:\n",
    "        page_id = data[agent_type][title]\n",
    "        content = get_all_text_from_page(page_id)\n",
    "        return content\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_current_portfolio(target_year, target_quarter):\n",
    "    jsons_list = os.listdir(f'./pf_logs/{target_year}_{target_quarter}')\n",
    "    not_init = any(filename.endswith('_weights.json') for filename in jsons_list)\n",
    "\n",
    "    if not_init:\n",
    "        target_pf = sorted(jsons_list)[-2]\n",
    "\n",
    "        with open(f'./pf_logs/{target_year}_{target_quarter}/{target_pf}', 'r') as f:\n",
    "            current_portfolio = json.load(f)\n",
    "    else:\n",
    "        with open(f'./pf_logs/{target_year}_{target_quarter}/{target_year}_{target_quarter}_init_pf.json', 'r') as f:\n",
    "            current_portfolio = json.load(f)\n",
    "\n",
    "    return current_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class t1_analyst:\n",
    "    \"\"\"Investment report generation class with GPT integration\"\"\"\n",
    "    \n",
    "    MARKDOWN_INSTRUCTION = \"\"\"\n",
    "    응답은 반드시 markdown 문법에 따라 작성되어야 합니다.\n",
    "    ** 보고서에는 반드시 주어진 정보에 대한 분석이 필요합니다 **\n",
    "    \"\"\"\n",
    "\n",
    "    ANALYST_BASE_PROMPT = \"\"\"\n",
    "    당신은 증권회사에 고용된 {role}입니다.\n",
    "    주식투자의 관점에서 주어진 정보들을 요약하고, 이에 대한 의견을 알려주세요.\n",
    "    {additional_instructions}\n",
    "    {markdown_instruction}\n",
    "    \"\"\"\n",
    "\n",
    "    INDIVIDUAL_REPORT_SYSTEM = \"\"\"증권사 애널리스트로서 종목 분석 보고서 작성\n",
    "        # 필수 섹션\n",
    "        1. 기업 개요\n",
    "        - 사업 모델과 핵심 역량\n",
    "        - 시장 포지셔닝\n",
    "\n",
    "        2. 재무 분석\n",
    "        - 핵심 재무지표 분석\n",
    "        - 수익성/성장성 평가\n",
    "\n",
    "        3. 섹터 분석\n",
    "        - 산업 동향과 경쟁력\n",
    "        - 기술적 분석 시사점\n",
    "\n",
    "        4. 투자의견\n",
    "        - 투자포인트 3개\n",
    "        - 주요 리스크\n",
    "        - 목표가 및 근거\n",
    "\n",
    "        요구사항:\n",
    "        - 구체적 데이터 기반\n",
    "        - 명확한 투자 논리 제시\n",
    "        \"\"\" + MARKDOWN_INSTRUCTION\n",
    "\n",
    "    def __init__(self, today, tickers: list, year: str, quarter: str):\n",
    "        self.tickers = tickers\n",
    "        self.year = year\n",
    "        self.quarter = quarter\n",
    "        self.prompts = self._initialize_prompts()\n",
    "        self.responses = {ticker: {} for ticker in tickers}\n",
    "        self.individual_reports = {}\n",
    "        self.start_date, self.end_date = self._get_date_range()\n",
    "        self.today = today\n",
    "        \n",
    "    def generate_individual_report(self, ticker: str) -> str:\n",
    "        \"\"\"Generate a comprehensive report for a single stock\"\"\"\n",
    "        print(f\"\\n=== {ticker} 분석 중... ===\")\n",
    "\n",
    "        # report_prompt를 빈 문자열로 초기화하여 예외 발생 시에도 접근 가능하게 만듦\n",
    "        report_prompt = \"\"\n",
    "\n",
    "        try:\n",
    "            # Financial analysis\n",
    "            financial_data = self.analyze_financial_data(ticker)\n",
    "\n",
    "            # Sector and pattern analysis\n",
    "            sector_analysis = self.analyze_sector_and_pattern(ticker)\n",
    "\n",
    "            # News analysis with cross-year support\n",
    "            try:\n",
    "                start_year = self.start_date[:4]\n",
    "                end_year = self.end_date[:4]\n",
    "\n",
    "                if start_year == end_year:\n",
    "                    # 같은 연도면 기존 방식대로 호출\n",
    "                    news_data = corp_rel_news_info(ticker, self.year, self.start_date, self.end_date)\n",
    "                else:\n",
    "                    # 연도가 다르면 두 번 호출 후 합침\n",
    "                    df1 = corp_rel_news_info(ticker, start_year, self.start_date, f\"{start_year}1231\")\n",
    "                    df2 = corp_rel_news_info(ticker, end_year, f\"{end_year}0101\", self.end_date)\n",
    "\n",
    "                    # 두 개의 DataFrame을 합치고 정렬\n",
    "                    news_data = pd.concat([df1, df2], axis=0).sort_index() if df1 is not None and df2 is not None else None\n",
    "\n",
    "                news_summary = self._process_news(news_data) if news_data is not None else {\"Positive\": [], \"Negative\": []}\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"{ticker}의 뉴스 데이터가 없습니다. 분석을 계속합니다.\")\n",
    "                news_summary = {\"Positive\": [], \"Negative\": []}\n",
    "            except Exception as e:\n",
    "                print(f\"{ticker}의 뉴스 처리 중 오류 발생: {e}. 분석을 계속합니다.\")\n",
    "                news_summary = {\"Positive\": [], \"Negative\": []}\n",
    "\n",
    "            # Stock price data\n",
    "            try:\n",
    "                stock_price = stock_price_info(ticker, self.start_date, self.today)[['Close', 'RSI_14']]\n",
    "                price_dict = stock_price.to_dict() if stock_price is not None and not stock_price.empty else None\n",
    "            except Exception as e:\n",
    "                print(f\"{ticker}의 주가 정보 처리 중 오류 발생: {e}. 분석을 계속합니다.\")\n",
    "                price_dict = None\n",
    "\n",
    "            # Combine all data for individual report\n",
    "            report_prompt = \"\\n\".join([\n",
    "                f\"재무제표 및 재무 비율 분석: {financial_data}\",\n",
    "                f\"섹터 분석: {sector_analysis}\",\n",
    "                f\"종목 관련 뉴스: {news_summary}\",\n",
    "                f\"주가 정보: {price_dict}\"\n",
    "            ])\n",
    "\n",
    "            # Generate individual report\n",
    "            report = to_GPT(self.INDIVIDUAL_REPORT_SYSTEM, report_prompt)\n",
    "            self.individual_reports[ticker] = report\n",
    "            return report\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{ticker} 분석 중 오류 발생: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _initialize_prompts(self) -> Dict[str, str]:\n",
    "        \"\"\"Initialize system prompts with templated format\"\"\"\n",
    "        return {\n",
    "            \"financial_system\": self.ANALYST_BASE_PROMPT.format(\n",
    "                role=\"재무전문가\",\n",
    "                additional_instructions=\"보고서 근거 기반 의견 제시\",\n",
    "                markdown_instruction=self.MARKDOWN_INSTRUCTION\n",
    "            ),\n",
    "            \"intl_macro_system\": self.ANALYST_BASE_PROMPT.format(\n",
    "                role=\"국제관계전문가\",\n",
    "                additional_instructions=\"국가별 금리, GDP, 인플레이션 등 거시경제 정보 분석\",\n",
    "                markdown_instruction=self.MARKDOWN_INSTRUCTION\n",
    "            ),\n",
    "            \"sector_system\": \"\"\"증권사 경제전문가로서 투자 관점에서 정보 분석 및 의견 제시\n",
    "                # 필수 포함 사항\n",
    "                - 섹터별 성과와 동향 분석\n",
    "                - 투자 매력도 평가 (근거 제시)\n",
    "                - 차트 패턴 분석 및 기술적 시사점\n",
    "                \"\"\" + self.MARKDOWN_INSTRUCTION,\n",
    "            \"final_system\": \"\"\"증권사 리서치센터장으로서 개별 애널리스트 보고서들을 종합하여 최종 투자전략 보고서 작성\n",
    "                # 필수 섹션\n",
    "                1. 거시경제 분석 요약\n",
    "                - 글로벌 동향 핵심 포인트\n",
    "                - 주요 리스크 요인\n",
    "\n",
    "                2. 개별 종목 분석 종합\n",
    "                - 각 종목 투자매력도 비교\n",
    "                - 상대가치 평가\n",
    "\n",
    "                3. 최종 포트폴리오 전략\n",
    "                - 종목별 투자비중 추천과 근거\n",
    "                - 위험관리 방안\n",
    "\n",
    "                4. 핵심 결론\n",
    "                - 최우선 투자 추천 종목\n",
    "                - 중점 모니터링 요소\n",
    "\n",
    "                작성 지침:\n",
    "                - 개별 애널리스트 보고서의 분석을 비교/종합하여 결론 도출\n",
    "                - 종목간 상대매력도를 구체적 근거와 함께 제시\n",
    "                - 실행 가능한 투자전략 제안\n",
    "                \"\"\" + self.MARKDOWN_INSTRUCTION\n",
    "        }\n",
    "\n",
    "    def _get_previous_quarter(self) -> tuple:\n",
    "        \"\"\"Get the previous quarter's year and quarter\"\"\"\n",
    "        quarter_order = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "        prev_index = quarter_order.index(self.quarter) - 1  # 이전 분기 인덱스\n",
    "\n",
    "        if prev_index < 0:  # 현재가 Q1이면 이전 해의 Q4로 이동\n",
    "            prev_year = str(int(self.year) - 1)\n",
    "            prev_quarter = 'Q4'\n",
    "        else:\n",
    "            prev_year = self.year\n",
    "            prev_quarter = quarter_order[prev_index]\n",
    "\n",
    "        return prev_year, prev_quarter\n",
    "\n",
    "    def _get_date_range(self) -> tuple:\n",
    "        \"\"\"Get start and end dates for the previous quarter\"\"\"\n",
    "        quarter_months = {\n",
    "            'Q1': ('01', '03'),\n",
    "            'Q2': ('04', '06'),\n",
    "            'Q3': ('07', '09'),\n",
    "            'Q4': ('10', '12')\n",
    "        }\n",
    "\n",
    "        # 이전 분기 계산\n",
    "        prev_year, prev_quarter = self._get_previous_quarter()\n",
    "        \n",
    "        if prev_quarter in quarter_months:\n",
    "            start_month, end_month = quarter_months[prev_quarter]\n",
    "            start_date = f\"{prev_year}{start_month}01\"\n",
    "            end_date = f\"{prev_year}{end_month}{'30' if end_month in ['06', '09'] else '31'}\"\n",
    "            return start_date, end_date\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid quarter: {prev_quarter}\")\n",
    "\n",
    "    def analyze_financial_data(self, ticker: str) -> str:\n",
    "        \"\"\"Analyze financial statements and generate report\"\"\"\n",
    "        try:\n",
    "            fin_statement = get_raw_fin_statement_info(ticker, self.year, self.quarter)\n",
    "            fin_statement_dict = fin_statement.T.to_dict() if fin_statement is not None else {}\n",
    "        except Exception:\n",
    "            fin_statement_dict = {}\n",
    "\n",
    "        try:\n",
    "            fin_ratio = fin_statement_info(ticker, self.year, self.quarter)\n",
    "            fin_ratio_dict = fin_ratio.to_dict('records')[0] if fin_ratio is not None and not fin_ratio.empty else {}\n",
    "        except Exception:\n",
    "            fin_ratio_dict = {}\n",
    "\n",
    "        try:\n",
    "            fin_report = reports_info(ticker, self.year, self.quarter)\n",
    "            report_content = fin_report['1. 요약재무정보.csv'][0][4:-4] if not fin_report.empty else \"정보 없음\"\n",
    "        except Exception:\n",
    "            report_content = \"정보 없음\"\n",
    "        \n",
    "        prompt_data = {\n",
    "            \"재무제표\": fin_statement_dict,\n",
    "            \"주요 재무 비율\": fin_ratio_dict,\n",
    "            \"재무보고서\": report_content\n",
    "        }\n",
    "        \n",
    "        financial_prompt = \"\\n\".join(f\"{k}: {v}\" for k, v in prompt_data.items())\n",
    "        report = to_GPT(self.prompts[\"financial_system\"], financial_prompt)\n",
    "\n",
    "        print('analyze_financial_data의 GPT 요청 결과:', report) # 디버깅용\n",
    "\n",
    "        return report\n",
    "\n",
    "    def analyze_international_macro(self) -> str:\n",
    "        \"\"\"Analyze international news and macroeconomic data with cross-year support\"\"\"\n",
    "\n",
    "        # 뉴스의 경우 매일매일 업데이트 되기 때문에 그에 맞춰서 일별로 새로운 데이터 포함해서 생성하도록 함\n",
    "        try:\n",
    "            start_year = self.start_date[:4]\n",
    "            end_year = self.today[:4]\n",
    "\n",
    "            if start_year == end_year:\n",
    "                # 같은 연도면 기존 방식대로 호출\n",
    "                intl_news = intl_news_info(self.year, self.start_date, self.today)\n",
    "            else:\n",
    "                # 연도가 다르면 두 번 호출 후 합치기\n",
    "                df1 = intl_news_info(start_year, self.start_date, f\"{start_year}1231\")\n",
    "                df2 = intl_news_info(end_year, f\"{end_year}0101\", self.today)\n",
    "\n",
    "                # 두 개의 DataFrame을 합치고 정렬\n",
    "                intl_news = pd.concat([df1, df2], axis=0).sort_index()\n",
    "\n",
    "            news_titles = list(intl_news['news_title']) if intl_news is not None and not intl_news.empty else []\n",
    "        except Exception as e:\n",
    "            print(f\"국제 뉴스 데이터 처리 중 오류 발생: {e}\")\n",
    "            news_titles = []\n",
    "\n",
    "        # 거시경제는 분기별이니까 그대로 직전 분기에 대한 정보만 사용\n",
    "        try:\n",
    "            macro_data = macro_econ_info(self.year, self.start_date, self.end_date)\n",
    "        except Exception:\n",
    "            macro_data = \"거시경제 데이터 없음\"\n",
    "\n",
    "        self.prompts[\"intl_macro_prompt\"] = \"\\n\".join([\n",
    "            f\"국제 뉴스 헤드라인: {news_titles}\",\n",
    "            f\"거시경제 관련 정보: {macro_data}\"\n",
    "        ])\n",
    "\n",
    "        return to_GPT(self.prompts[\"intl_macro_system\"], self.prompts[\"intl_macro_prompt\"])\n",
    "\n",
    "    def analyze_sector_and_pattern(self, ticker: str) -> str:\n",
    "        \"\"\"Analyze sector trends and chart patterns\"\"\"\n",
    "        index_prices = {}\n",
    "        try:\n",
    "            sector_list = [s for s in os.listdir('../store_data/raw/market_data/sector') \n",
    "                          if '코스피' not in s]\n",
    "        except Exception:\n",
    "            sector_list = []\n",
    "        \n",
    "        # Collect sector data\n",
    "        # for sector in sector_list:\n",
    "        #     try:\n",
    "        #         # 이것도 직전분기 시작일 ~ 당일까지의 데이터로\n",
    "        #         index_price = index_price_info(sector, self.start_date, self.today)\n",
    "        #         if index_price is not None and not index_price.empty:\n",
    "        #             index_price = index_price[['Close', 'Transaction_Val', 'Market_Cap', 'RSI_14']]\n",
    "        #             index_prices[sector] = index_price.T.to_dict()\n",
    "        #     except Exception:\n",
    "        #         continue\n",
    "        \n",
    "        # Collect sector analysis\n",
    "        sector_infos = {}\n",
    "        for sector in sector_list:\n",
    "            try:\n",
    "                # 이건 분기별로 유지\n",
    "                sector_analysis = sector_analysis_info(sector, self.year, self.quarter)\n",
    "                if sector_analysis is not None:\n",
    "                    sector_infos[sector] = extract_key_metrics(sector_analysis)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # try:\n",
    "        #     pattern_data = pattern_info(ticker, self.today)\n",
    "        #     pattern_dict = pattern_data.to_dict('records') if pattern_data is not None and not pattern_data.empty else None\n",
    "        # except Exception:\n",
    "        #     pattern_dict = None\n",
    "        \n",
    "        self.prompts[\"sector_prompt\"] = \"\\n\".join([\n",
    "            # f\"섹터별 가격 정보: {index_prices}\",\n",
    "            f\"섹터별 carhart 4 factor 분석: {sector_infos}\",\n",
    "            # f\"차트 패턴 분석 결과: {pattern_dict}\"\n",
    "        ])\n",
    "        \n",
    "        response = to_GPT(self.prompts[\"sector_system\"], self.prompts[\"sector_prompt\"])\n",
    "\n",
    "        print('analyze_sector_and_pattern의 GPT 요청 결과:', response) # 디버깅용\n",
    "\n",
    "        return response\n",
    "\n",
    "    def analyze_stocks(self):\n",
    "        \"\"\"Execute analysis for all stocks\"\"\"\n",
    "        # Only analyze macro once\n",
    "        macro_response = self.analyze_international_macro()\n",
    "        self.responses[\"international_macro\"] = macro_response\n",
    "        \n",
    "        # for ticker in self.tickers:\n",
    "        #     print(f\"\\n=== {ticker} 분석 중... ===\")\n",
    "        #     try:\n",
    "        #         self.responses[ticker].update({\n",
    "        #             \"financial\": self.analyze_financial_data(ticker),\n",
    "        #             # \"sector_pattern_analysis\": self.analyze_sector_and_pattern(ticker)\n",
    "        #         })\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"{ticker} 분석 중 오류 발생: {e}\")\n",
    "\n",
    "    def generate_final_report(self) -> dict:\n",
    "        try:\n",
    "            # 종목들의 개별 보고서만 포함하기\n",
    "            combined_prompt = []\n",
    "            \n",
    "            for ticker in self.tickers:\n",
    "                if ticker not in self.individual_reports:\n",
    "                    print(f\"{ticker} 보고서 없음\")\n",
    "                    pass\n",
    "                \n",
    "                report = self.individual_reports.get(ticker)\n",
    "                if report:\n",
    "                    combined_prompt.append(f\"\\n=== {ticker} 종목 분석 ===\")\n",
    "                    report_content = report.get('choices', [{}])[0].get('message', {}).get('content', '') if isinstance(report, dict) else str(report)\n",
    "                    combined_prompt.append(report_content)\n",
    "\n",
    "            prompt = \"\\n\".join(combined_prompt)\n",
    "\n",
    "            # 최종 보고서 생성 요청\n",
    "            final_response = to_GPT(self.prompts[\"final_system\"], prompt)\n",
    "            return final_response\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"generate_final_report에서 예외 발생: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _process_news(self, corp_news_df) -> Dict[str, list]:\n",
    "        \"\"\"Process corporate news and extract sentiment\"\"\"\n",
    "        news_summary = {'Positive': [], 'Negative': []}\n",
    "        \n",
    "        if corp_news_df is not None and not corp_news_df.empty:\n",
    "            try:\n",
    "                # 증권 카테고리 필터링\n",
    "                corp_news_df = corp_news_df[corp_news_df['news_category'].str.contains('증권', na=False)]\n",
    "                \n",
    "                if not corp_news_df.empty:\n",
    "                    # SA 결과 및 감성 점수 추출\n",
    "                    corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x: \n",
    "                        get_SA_result(x) if pd.notna(x) else None)\n",
    "                    \n",
    "                    # None이나 NaN이 아닌 행만 감성 점수 추출\n",
    "                    valid_news = corp_news_df.dropna(subset=['SA_result'])\n",
    "                    if not valid_news.empty:\n",
    "                        valid_news = extract_sentiment_score(valid_news)\n",
    "                        \n",
    "                        for sentiment in ['positive', 'negative']:\n",
    "                            try:\n",
    "                                news = filter_by_percentile_and_label(valid_news, sentiment, 20)\n",
    "                                if not news.empty:\n",
    "                                    news_summary[sentiment.capitalize()] = list(news['news_title'])\n",
    "                            except Exception:\n",
    "                                continue\n",
    "            except Exception as e:\n",
    "                print(f\"뉴스 처리 중 오류 발생: {e}\")\n",
    "        \n",
    "        return news_summary\n",
    "\n",
    "    def _get_response_content(self, response: Dict) -> str:\n",
    "        \"\"\"GPT 응답에서 content 추출\"\"\"\n",
    "        try:\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"\"\n",
    "        \n",
    "    def save_final_report(self, final_response: Dict) -> None:\n",
    "        \"\"\"최종 애널리스트 보고서 저장\"\"\"\n",
    "        page_title = f\"{self.today}_t_1_analyst_rp\"\n",
    "        content = self._get_response_content(final_response)\n",
    "        \n",
    "        print(f\"{page_title} 보고서를 노션 DB에 저장합니다...\")\n",
    "        to_DB('t_1', page_title, f\"{self.start_date}_{self.today}\", content)\n",
    "\n",
    "class t1_pf_manager:\n",
    "    def __init__(self, today, analyst_report, tickers: list, year: str, quarter: str, target_year, target_quarter):\n",
    "        self.tickers = tickers\n",
    "        self.year = year\n",
    "        self.quarter = quarter\n",
    "        self.prompts = self._initialize_prompts()\n",
    "        self.responses = {}\n",
    "        self.report_data = {}\n",
    "        self.analyst_report = analyst_report\n",
    "        self.current_portfolio = None\n",
    "        self.individual_reports = {}\n",
    "        self.today = today\n",
    "        self.target_year = target_year\n",
    "        self.target_quarter = target_quarter\n",
    "        \n",
    "    def _initialize_prompts(self) -> Dict[str, str]:\n",
    "        return {\n",
    "            \"individual_portfolio_system\": \"\"\"당신은 자산운용사의 포트폴리오 매니저입니다.\n",
    "해당 종목에 대한 애널리스트 리서치 보고서를 검토하여 포트폴리오 운용 전략을 제시하세요.\n",
    "\n",
    "# 1. 종목 현황\n",
    "- 현재 비중과 추이\n",
    "- 주요 위험/수익 지표\n",
    "- 투자 성과 분석\n",
    "\n",
    "# 2. 투자 전략\n",
    "- 적정 비중과 근거\n",
    "- 핵심 매력도/리스크\n",
    "- 비중 조정 방향\n",
    "\n",
    "# 3. 리스크 관리\n",
    "- 손절/이익실현 기준\n",
    "- 주요 모니터링 지표\n",
    "\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "\n",
    "            \"final_portfolio_system\": \"\"\"당신은 자산운용사의 수석 포트폴리오 매니저입니다.\n",
    "개별 종목 포트폴리오 보고서들을 종합하여 전체 포트폴리오 최종 운용 전략을 제시하세요.\n",
    "\n",
    "# 1. 포트폴리오 종합 현황\n",
    "- 전체 구성과 섹터 비중\n",
    "- 종목별 성과 비교\n",
    "- 핵심 위험/수익 특성\n",
    "\n",
    "# 2. 전략적 자산배분\n",
    "- 섹터별 비중 전략\n",
    "- 종목간 상대매력도\n",
    "- 전체 위험분산 방안\n",
    "\n",
    "# 3. 최종 포트폴리오 조정안\n",
    "- 종목별 비중 조정 방향\n",
    "- 편입/편출 검토\n",
    "- 우선순위와 실행계획\n",
    "\n",
    "# 4. 종합 리스크 관리\n",
    "- 포트폴리오 전체 관점\n",
    "- 개별종목 리스크 통합 관리\n",
    "- 주요 모니터링 지표\n",
    "\n",
    "작성 지침:\n",
    "- 개별 보고서들의 분석을 통합하여 결론 도출\n",
    "- 종목간 상대가치 고려한 전략 수립\n",
    "- 구체적 실행방안 제시\n",
    "\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "            \"individual_portfolio_prompt\": \"\",\n",
    "            \"final_portfolio_prompt\": \"\"\n",
    "        }\n",
    "        \n",
    "    def generate_individual_report(self, ticker: str, analyst_report: str, portfolio: Dict) -> Dict:\n",
    "        \"\"\"개별 종목 포트폴리오 보고서 생성\"\"\"\n",
    "        prompt = f\"종목코드: {ticker}\\n\"\n",
    "        prompt += f\"현재 포트폴리오 구성: {portfolio}\\n\"\n",
    "        prompt += f\"애널리스트 보고서: {analyst_report}\\n\\n\"\n",
    "        prompt += \"응답 형식:\\n\\n\"\n",
    "        prompt += \"1. 투자 전략 및 분석 보고서 (Markdown 형식)\\n\"\n",
    "        prompt += \"2. 포트폴리오 내 적정 비중 (JSON 형식: {'ticker': 'weight'})\"\n",
    "\n",
    "        response = to_GPT(self.prompts[\"individual_portfolio_system\"], prompt)\n",
    "\n",
    "        # 응답에서 내용 추출\n",
    "        report_text = self._get_response_content(response)\n",
    "\n",
    "        # JSON 형식의 비중 정보 추출\n",
    "        weight_info = self._extract_weight_info(response)\n",
    "\n",
    "        self.individual_reports[ticker] = {\n",
    "            \"report\": report_text,\n",
    "            \"weight\": weight_info\n",
    "        }\n",
    "        return self.individual_reports[ticker]\n",
    "\n",
    "    def _extract_weight_info(self, response: Dict) -> Dict:\n",
    "        \"\"\"GPT 응답에서 비중 정보를 추출하는 메서드\"\"\"\n",
    "        try:\n",
    "            content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "            match = re.search(r'({.*?})', content, re.DOTALL)\n",
    "            if match:\n",
    "                return json.loads(match.group(1))  # JSON 변환\n",
    "        except (KeyError, IndexError, json.JSONDecodeError):\n",
    "            return {}\n",
    "        return {}\n",
    "\n",
    "        \n",
    "    def set_current_portfolio(self, portfolio: Dict) -> None:\n",
    "        \"\"\"현재 포트폴리오 설정\"\"\"\n",
    "        self.current_portfolio = portfolio\n",
    "        \n",
    "    def generate_final_report(self) -> Dict:\n",
    "        \"\"\"최종 포트폴리오 매니저 보고서 생성\"\"\"\n",
    "        if not self.individual_reports:\n",
    "            raise ValueError(\"Individual reports must be generated first\")\n",
    "\n",
    "        combined_prompt = []\n",
    "        final_weights = {}\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            if ticker in self.individual_reports:\n",
    "                combined_prompt.append(f\"\\n=== {ticker} 포트폴리오 보고서 ===\")\n",
    "                combined_prompt.append(self.individual_reports[ticker][\"report\"])\n",
    "                \n",
    "                # 종목별 비중 저장\n",
    "                final_weights[ticker] = self.individual_reports[ticker][\"weight\"].get(ticker, \"N/A\")\n",
    "\n",
    "        self.prompts[\"final_portfolio_prompt\"] = \"\\n\".join(combined_prompt)\n",
    "        final_response = to_GPT(self.prompts[\"final_portfolio_system\"], self.prompts[\"final_portfolio_prompt\"])\n",
    "\n",
    "        return {\n",
    "            \"final_report\": self._get_response_content(final_response),\n",
    "            \"final_weights\": final_weights\n",
    "        }\n",
    "\n",
    "    def _get_response_content(self, response: Dict) -> str:\n",
    "        \"\"\"GPT 응답에서 content 추출\"\"\"\n",
    "        try:\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"\"\n",
    "\n",
    "    def save_final_report(self, final_response: Dict) -> None:\n",
    "        \"\"\"최종 포트폴리오 매니저 보고서 저장\"\"\"\n",
    "        page_title = f\"{self.today}_final_portfolio_report\"\n",
    "        content = final_response[\"final_report\"]\n",
    "        weights = final_response[\"final_weights\"]\n",
    "\n",
    "        print(f\"{page_title} 보고서를 노션 DB에 저장합니다...\")\n",
    "\n",
    "        # 노션 DB 저장\n",
    "        to_DB('t_1', page_title, f\"{self.quarter}_{self.year}\", content)\n",
    "        to_DB('t_1', f\"{self.today}_portfolio_weights\", f\"{self.quarter}_{self.year}\", json.dumps(weights, indent=2))\n",
    "\n",
    "        # JSON 파일 저장할 디렉토리 경로\n",
    "        log_dir = f\"./pf_logs/{self.target_year}_{self.target_quarter}\"\n",
    "        os.makedirs(log_dir, exist_ok=True)  # 디렉토리 없으면 생성\n",
    "\n",
    "        # 파일 경로\n",
    "        file_path = os.path.join(log_dir, f\"{self.today}_portfolio_weights.json\")\n",
    "\n",
    "        # JSON 파일 저장\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(weights, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"포트폴리오 비중 데이터가 {file_path}에 저장되었습니다.\")\n",
    "\n",
    "class t1_trader:\n",
    "    def __init__(self, today, tickers: list, year: str, quarter: str):\n",
    "        self.tickers = tickers\n",
    "        self.year = year\n",
    "        self.quarter = quarter\n",
    "        self.prompts = self._initialize_prompts()\n",
    "        self.individual_reports = {}\n",
    "        self.responses = {ticker: {} for ticker in tickers}\n",
    "        self.report_data = {}\n",
    "        self.start_date, self.end_date = self._get_date_range()\n",
    "        self.today = today\n",
    "        self.price_data = {}\n",
    "        self.analyst_reports = {}\n",
    "        self.pm_reports = {}\n",
    "        self.price_predictions = {}\n",
    "        \n",
    "    def _initialize_prompts(self) -> Dict[str, str]:\n",
    "        \"\"\"프롬프트 초기화\"\"\"\n",
    "        return {\n",
    "            \"individual_trader_system\": \"\"\"당신은 증권사의 트레이더입니다. 해당 종목의 데이터와 보고서를 분석하여 구체적인 매매 전략을 제시하세요.\n",
    "\n",
    "# 종목 기본 분석\n",
    "- 현재가 동향과 기술적 신호\n",
    "- 예측가격 분석\n",
    "- 거래량 특징\n",
    "\n",
    "# 매매 전략\n",
    "- 매매 방향과 근거\n",
    "- 진입/청산 가격대\n",
    "- 리스크 관리 전략\n",
    "\n",
    "모든 분석은 제공된 데이터에 기반하여 작성하세요.\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "\n",
    "            \"final_trader_system\": \"\"\"당신은 증권사의 수석 트레이더입니다. 개별 종목 트레이딩 보고서들을 종합하여 최종 매매 전략을 제시하세요.\n",
    "\n",
    "# 시장 종합 분석\n",
    "- 주요 매매 환경\n",
    "- 전반적 매매 전략\n",
    "\n",
    "# 우선 매매 종목\n",
    "- 상위 5-7개 종목 선정과 근거\n",
    "- 구체적 매매 전략\n",
    "- 핵심 리스크 관리\n",
    "\n",
    "# 기타 종목 전략\n",
    "- 실제 매수/매도 대상 종목 분석\n",
    "- 종목별 구체적 진입/청산 전략\n",
    "- 종목별 리스크 관리 방안\n",
    "\n",
    "작성 지침:\n",
    "- 개별 보고서 분석 통합\n",
    "- 우선순위 기반 전략 수립\n",
    "- 구체적 실행 방안 제시\n",
    "- 가정이나 예시가 아닌 실제 종목과 데이터 기반 분석 필수\n",
    "- 각 종목별 현재 시장 상황과 기업 실적 반영\n",
    "\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "            \"individual_trader_prompt\": \"\",\n",
    "            \"final_trader_prompt\": \"\"\n",
    "        }\n",
    "    \n",
    "    def _get_previous_quarter(self) -> tuple:\n",
    "        \"\"\"Get the previous quarter's year and quarter\"\"\"\n",
    "        quarter_order = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "        prev_index = quarter_order.index(self.quarter) - 1  # 이전 분기 인덱스\n",
    "\n",
    "        if prev_index < 0:  # 현재가 Q1이면 이전 해의 Q4로 이동\n",
    "            prev_year = str(int(self.year) - 1)\n",
    "            prev_quarter = 'Q4'\n",
    "        else:\n",
    "            prev_year = self.year\n",
    "            prev_quarter = quarter_order[prev_index]\n",
    "\n",
    "        return prev_year, prev_quarter\n",
    "\n",
    "\n",
    "    def _get_date_range(self) -> tuple:\n",
    "        \"\"\"Get start and end dates for the previous quarter\"\"\"\n",
    "        quarter_months = {\n",
    "            'Q1': ('01', '03'),\n",
    "            'Q2': ('04', '06'),\n",
    "            'Q3': ('07', '09'),\n",
    "            'Q4': ('10', '12')\n",
    "        }\n",
    "\n",
    "        # 이전 분기 계산\n",
    "        prev_year, prev_quarter = self._get_previous_quarter()\n",
    "        \n",
    "        if prev_quarter in quarter_months:\n",
    "            start_month, end_month = quarter_months[prev_quarter]\n",
    "            start_date = f\"{prev_year}{start_month}01\"\n",
    "            end_date = f\"{prev_year}{end_month}{'30' if end_month in ['06', '09'] else '31'}\"\n",
    "            return start_date, end_date\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid quarter: {prev_quarter}\")\n",
    "\n",
    "    def set_price_data(self) -> None:\n",
    "        \"\"\"주가 데이터 설정\"\"\"\n",
    "        try:\n",
    "            for ticker in self.tickers:\n",
    "                self.price_data[ticker] = stock_price_info(ticker, self.start_date, self.today)\n",
    "        except Exception as e:\n",
    "            print(f\"가격 데이터 설정 중 오류 발생: {str(e)}\")\n",
    "\n",
    "\n",
    "    def set_analyst_report(self, report: str) -> None:\n",
    "        \"\"\"애널리스트 보고서 설정\"\"\"\n",
    "        self.analyst_report = report\n",
    "\n",
    "    def set_pm_report(self, report: str) -> None:\n",
    "        \"\"\"포트폴리오 매니저 보고서 설정\"\"\"\n",
    "        self.pm_report = report\n",
    "\n",
    "    def get_price_prediction(self) -> None:\n",
    "        \"\"\"GRU 모델을 사용한 가격 예측\"\"\"\n",
    "        try:\n",
    "            self.price_predictions = predict_multiple_prices(\n",
    "                self.tickers,\n",
    "                self.start_date,\n",
    "                self.end_date\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"가격 예측 모델 실행 중 오류 발생: {str(e)}\")\n",
    "    \n",
    "    def generate_individual_report(self, ticker: str) -> str:\n",
    "        \"\"\"개별 종목 트레이더 보고서 생성\"\"\"\n",
    "        price_data = self.price_data.get(ticker, {})\n",
    "        if hasattr(price_data, 'to_dict'):\n",
    "            price_data = price_data.to_dict()\n",
    "            \n",
    "        prompt = f\"종목코드: {ticker}\\n\"\n",
    "        prompt += f\"가격 데이터: {price_data}\\n\"\n",
    "        prompt += f\"가격 예측: {self.price_predictions.get(ticker, {})}\\n\"\n",
    "        prompt += f\"애널리스트 보고서: {self.analyst_reports.get(ticker, '정보 없음')}\\n\"\n",
    "        prompt += f\"PM 보고서: {self.pm_reports.get(ticker, '정보 없음')}\"\n",
    "\n",
    "        response = to_GPT(self.prompts[\"individual_trader_system\"], prompt)\n",
    "        self.individual_reports[ticker] = response\n",
    "        return response\n",
    "\n",
    "    def generate_final_report(self) -> str:\n",
    "        \"\"\"최종 트레이더 보고서 생성\"\"\"\n",
    "        if not self.individual_reports:\n",
    "            raise ValueError(\"Individual reports must be generated first\")\n",
    "        \n",
    "        combined_prompt = []\n",
    "        for ticker in self.tickers:\n",
    "            if ticker in self.individual_reports:\n",
    "                combined_prompt.append(f\"\\n=== {ticker} 트레이딩 보고서 ===\")\n",
    "                combined_prompt.append(self._get_response_content(self.individual_reports[ticker]))\n",
    "        \n",
    "        self.prompts[\"final_trader_prompt\"] = \"\\n\".join(combined_prompt)\n",
    "        final_response = to_GPT(self.prompts[\"final_trader_system\"], \n",
    "                              self.prompts[\"final_trader_prompt\"])\n",
    "        return final_response\n",
    "    \n",
    "    def _get_response_content(self, response: Dict) -> str:\n",
    "        try:\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"\"\n",
    "\n",
    "    def save_final_report(self, final_response: Dict) -> None:\n",
    "        page_title = f\"{self.today}_final_trader_report\"\n",
    "        content = self._get_response_content(final_response)\n",
    "        \n",
    "        print(f\"{page_title} 보고서를 노션 DB에 저장합니다...\")\n",
    "        to_DB('t_1', page_title, f\"{self.quarter}_{self.year}\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1547063"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = '20230101'\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_file_path = \"./notion_page_ids.json\"\n",
    "\n",
    "# 조회할 정보들의 기준 연도\n",
    "base_year = \"2022\"\n",
    "base_quarter = \"Q4\"\n",
    "\n",
    "# 현재 시기 (투자를 진행할 현재 시점)\n",
    "target_year = '2023'\n",
    "target_quarter = 'Q1'\n",
    "\n",
    "# 'pf_selection_agent'에서 종목 코드 가져오기\n",
    "tickers = get_tickers_from_json('pf_selection_agent', f'{target_year}_{target_quarter}_init_pf')\n",
    "\n",
    "# 한번 실행에 약 40분 (26개 종목 기준) 소요, 150만토큰 소모\n",
    "def t1_analyst_main(today, tickers, base_year, base_quarter):\n",
    "\n",
    "    # 분석기 객체 생성\n",
    "    analyzer = t1_analyst(today, tickers, base_year, base_quarter)\n",
    "\n",
    "    print('[t1_analyst] === 종목별 분석 시작 ===')\n",
    "    # 분석 실행\n",
    "    analyzer.analyze_stocks()\n",
    "\n",
    "    # 개별 보고서 생성 \n",
    "    for ticker in tickers:\n",
    "        analyzer.generate_individual_report(ticker)\n",
    "\n",
    "    print('[t1_analyst] === 최종 보고서 생성 ===')\n",
    "    # 최종 보고서 생성\n",
    "    final_report = analyzer.generate_final_report()\n",
    "\n",
    "    # 노션에 저장\n",
    "    analyzer.save_final_report(final_report)\n",
    "\n",
    "def t1_pf_manager_main(today, tickers, base_year, base_quarter, target_year, target_quarter):\n",
    "    analyst_report = get_analyst_rp('t_1', f'{today}_t_1_analyst_rp')\n",
    "\n",
    "    # 2. 종합 포트폴리오 매니저 보고서 생성\n",
    "    print('[t1_pf_manager] === 종합 포트폴리오 매니저 보고서 생성 ===')\n",
    "    portfolio_manager = t1_pf_manager(today, analyst_report, tickers, base_year, base_quarter, target_year, target_quarter)\n",
    "\n",
    "    # 각 종목별 포트폴리오 보고서 생성\n",
    "    for ticker in tickers:\n",
    "        current_portfolio = portfolio_manager.set_current_portfolio(get_current_portfolio(target_year, target_quarter))# 현재 포트폴리오 정보 가져오기\n",
    "        portfolio_manager.generate_individual_report(ticker, analyst_report, current_portfolio)\n",
    "        print(f\"{ticker} 포폴 매니저 보고서 추출 완료\")\n",
    "        \n",
    "    print('[t1_pf_manager] === 최종 보고서 생성 ===')\n",
    "    # 보고서 생성\n",
    "    portfolio_report = portfolio_manager.generate_final_report()\n",
    "\n",
    "    # 보고서 출력\n",
    "    print(\"\\n=== 포트폴리오 매니저 종합 보고서 ===\")\n",
    "    print(portfolio_report)\n",
    "    print(\"=== 보고서 끝 ===\")\n",
    "\n",
    "    # 보고서 저장\n",
    "    portfolio_manager.save_final_report(portfolio_report)\n",
    "\n",
    "# 한번 실행에 약 10분 (26개 종목 기준) 소요\n",
    "def t1_trader_main(today, tickers, base_year, base_quarter):\n",
    "    trader = t1_trader(today, tickers, base_year, base_quarter)\n",
    "\n",
    "    print('[t1_trader] === 종목별 트레이더 보고서 생성 ===')\n",
    "    # 필요한 데이터 설정\n",
    "    trader.set_price_data()\n",
    "    trader.get_price_prediction()\n",
    "\n",
    "    # 각 종목별 트레이더 보고서 생성\n",
    "    for ticker in tickers:\n",
    "        trader.generate_individual_report(ticker)\n",
    "        print(f\"{ticker} 트레이더 보고서 추출 완료\")\n",
    "\n",
    "    # 최종 트레이더 보고서 생성\n",
    "    print('[t1_trader] === 최종 보고서 생성 ===')\n",
    "    final_report = trader.generate_final_report()\n",
    "    trader.save_final_report(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.07/2022.07_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.08/2022.08_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.09/2022.09_033660.csv 파일을 찾을 수 없습니다.\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "033660의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "033660의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 로드 실패: \"None of [Index(['TRD_DD', 'LIST_SHRS', 'FORN_HD_QTY', 'FORN_SHR_RT', 'FORN_ORD_LMT_QTY',\\n       'FORN_LMT_EXHST_RT'],\\n      dtype='object')] are in the [columns]\"\n",
      "[DEBUG] 최종 데이터 shape: (0, 5)\n",
      "[WARNING] PER이 모두 0입니다. 평균값으로 대체합니다.\n",
      "033660 예측 중 오류 발생: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by MinMaxScaler.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.1177 - mae: 0.4477 - val_loss: 0.0062 - val_mae: 0.1012 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0729 - mae: 0.3313 - val_loss: 0.0049 - val_mae: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0454 - mae: 0.2366 - val_loss: 0.0073 - val_mae: 0.0902 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0253 - mae: 0.1739 - val_loss: 0.0128 - val_mae: 0.1302 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0146 - mae: 0.1379 - val_loss: 0.0204 - val_mae: 0.1801 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0117 - mae: 0.1306 - val_loss: 0.0274 - val_mae: 0.2161 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - mae: 0.1345 - val_loss: 0.0312 - val_mae: 0.2331 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0129 - mae: 0.1438 - val_loss: 0.0306 - val_mae: 0.2305 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0122 - mae: 0.1403 - val_loss: 0.0282 - val_mae: 0.2195 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0116 - mae: 0.1379 - val_loss: 0.0251 - val_mae: 0.2048 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0114 - mae: 0.1337 - val_loss: 0.0218 - val_mae: 0.1877 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.1227 - val_loss: 0.0194 - val_mae: 0.1742 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "검증 세트 MSE: 0.017196923762240187\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.1802 - mae: 0.5307 - val_loss: 0.0483 - val_mae: 0.2687 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1671 - mae: 0.5026 - val_loss: 0.0356 - val_mae: 0.2222 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1217 - mae: 0.4193 - val_loss: 0.0260 - val_mae: 0.1860 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1026 - mae: 0.3790 - val_loss: 0.0192 - val_mae: 0.1597 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0875 - mae: 0.3463 - val_loss: 0.0158 - val_mae: 0.1400 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0606 - mae: 0.2792 - val_loss: 0.0156 - val_mae: 0.1523 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0510 - mae: 0.2589 - val_loss: 0.0187 - val_mae: 0.1676 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.2403 - val_loss: 0.0246 - val_mae: 0.1913 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0311 - mae: 0.2249 - val_loss: 0.0320 - val_mae: 0.2209 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0313 - mae: 0.2324 - val_loss: 0.0374 - val_mae: 0.2384 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0279 - mae: 0.2154 - val_loss: 0.0389 - val_mae: 0.2430 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0267 - mae: 0.2033 - val_loss: 0.0372 - val_mae: 0.2380 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0262 - mae: 0.2017 - val_loss: 0.0336 - val_mae: 0.2268 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0245 - mae: 0.1961 - val_loss: 0.0300 - val_mae: 0.2142 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0220 - mae: 0.1850 - val_loss: 0.0267 - val_mae: 0.2008 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0227 - mae: 0.1868 - val_loss: 0.0236 - val_mae: 0.1874 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "검증 세트 MSE: 0.021245802195997514\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.3682 - mae: 0.8434 - val_loss: 0.0540 - val_mae: 0.2720 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2961 - mae: 0.7538 - val_loss: 0.0382 - val_mae: 0.2257 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2211 - mae: 0.6497 - val_loss: 0.0282 - val_mae: 0.1958 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1692 - mae: 0.5664 - val_loss: 0.0207 - val_mae: 0.1762 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1156 - mae: 0.4663 - val_loss: 0.0152 - val_mae: 0.1577 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0764 - mae: 0.3746 - val_loss: 0.0137 - val_mae: 0.1421 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0450 - mae: 0.2764 - val_loss: 0.0180 - val_mae: 0.1564 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0183 - mae: 0.1638 - val_loss: 0.0293 - val_mae: 0.2011 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0885 - val_loss: 0.0451 - val_mae: 0.2637 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0088 - mae: 0.1052 - val_loss: 0.0565 - val_mae: 0.3053 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.1401 - val_loss: 0.0581 - val_mae: 0.3109 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.1401 - val_loss: 0.0546 - val_mae: 0.2992 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.1252 - val_loss: 0.0489 - val_mae: 0.2789 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0430 - val_mae: 0.2558 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0062 - mae: 0.0897 - val_loss: 0.0378 - val_mae: 0.2340 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0879 - val_loss: 0.0339 - val_mae: 0.2165 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "검증 세트 MSE: 0.04316306435845637\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.1995 - mae: 0.5724 - val_loss: 0.2758 - val_mae: 0.7341 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1364 - mae: 0.4672 - val_loss: 0.2279 - val_mae: 0.6654 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1046 - mae: 0.3954 - val_loss: 0.1824 - val_mae: 0.5925 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0776 - mae: 0.3385 - val_loss: 0.1403 - val_mae: 0.5161 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0567 - mae: 0.2740 - val_loss: 0.1035 - val_mae: 0.4382 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0429 - mae: 0.2250 - val_loss: 0.0697 - val_mae: 0.3534 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0268 - mae: 0.1747 - val_loss: 0.0441 - val_mae: 0.2722 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0174 - mae: 0.1439 - val_loss: 0.0275 - val_mae: 0.2100 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.1421 - val_loss: 0.0191 - val_mae: 0.1733 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0166 - mae: 0.1487 - val_loss: 0.0156 - val_mae: 0.1591 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.1527 - val_loss: 0.0152 - val_mae: 0.1576 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1480 - val_loss: 0.0166 - val_mae: 0.1633 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - mae: 0.1347 - val_loss: 0.0194 - val_mae: 0.1743 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - mae: 0.1306 - val_loss: 0.0225 - val_mae: 0.1851 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0140 - mae: 0.1307 - val_loss: 0.0248 - val_mae: 0.1941 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0121 - mae: 0.1186 - val_loss: 0.0264 - val_mae: 0.2023 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - mae: 0.1122 - val_loss: 0.0261 - val_mae: 0.2009 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.1162 - val_loss: 0.0254 - val_mae: 0.1974 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - mae: 0.1211 - val_loss: 0.0235 - val_mae: 0.1889 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0133 - mae: 0.1223 - val_loss: 0.0214 - val_mae: 0.1803 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.1095 - val_loss: 0.0195 - val_mae: 0.1734 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "검증 세트 MSE: 0.03270352744135654\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "011420의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "011420의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.05769230769230793 ~ 1.0\n",
      "011420 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/sklearn/utils/_array_api.py:701: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/sklearn/utils/_array_api.py:718: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0000000000000004\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1649 - mae: 0.5578 - val_loss: 0.0206 - val_mae: 0.1544 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1248 - mae: 0.4857 - val_loss: 0.0157 - val_mae: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0970 - mae: 0.4192 - val_loss: 0.0120 - val_mae: 0.1296 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0604 - mae: 0.3235 - val_loss: 0.0093 - val_mae: 0.1210 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0361 - mae: 0.2268 - val_loss: 0.0100 - val_mae: 0.1259 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.1301 - val_loss: 0.0144 - val_mae: 0.1424 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0107 - mae: 0.1105 - val_loss: 0.0209 - val_mae: 0.1741 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - mae: 0.1387 - val_loss: 0.0249 - val_mae: 0.1931 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1517 - val_loss: 0.0245 - val_mae: 0.1915 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.1534 - val_loss: 0.0227 - val_mae: 0.1839 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - mae: 0.1428 - val_loss: 0.0205 - val_mae: 0.1740 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110 - mae: 0.1272 - val_loss: 0.0183 - val_mae: 0.1634 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0120 - mae: 0.1257 - val_loss: 0.0165 - val_mae: 0.1540 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0081 - mae: 0.0979 - val_loss: 0.0152 - val_mae: 0.1468 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "검증 세트 MSE: 0.01970409646427407\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.4152 - mae: 0.9041 - val_loss: 0.0328 - val_mae: 0.1918 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2983 - mae: 0.7636 - val_loss: 0.0182 - val_mae: 0.1569 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1992 - mae: 0.6205 - val_loss: 0.0124 - val_mae: 0.1493 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1098 - mae: 0.4576 - val_loss: 0.0169 - val_mae: 0.1554 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0484 - mae: 0.2978 - val_loss: 0.0333 - val_mae: 0.2333 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1565 - val_loss: 0.0592 - val_mae: 0.3318 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0699 - val_loss: 0.0868 - val_mae: 0.4093 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0094 - mae: 0.1133 - val_loss: 0.1048 - val_mae: 0.4523 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - mae: 0.1676 - val_loss: 0.1058 - val_mae: 0.4546 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0174 - mae: 0.1664 - val_loss: 0.1007 - val_mae: 0.4431 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0163 - mae: 0.1596 - val_loss: 0.0922 - val_mae: 0.4230 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110 - mae: 0.1266 - val_loss: 0.0827 - val_mae: 0.3995 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0088 - mae: 0.1075 - val_loss: 0.0738 - val_mae: 0.3758 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "검증 세트 MSE: 0.03917593571020486\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0000000000000009\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.2193 - mae: 0.5810 - val_loss: 0.0021 - val_mae: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1960 - mae: 0.5664 - val_loss: 0.0062 - val_mae: 0.1001 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1545 - mae: 0.4987 - val_loss: 0.0128 - val_mae: 0.1525 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1109 - mae: 0.4201 - val_loss: 0.0209 - val_mae: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0886 - mae: 0.3936 - val_loss: 0.0291 - val_mae: 0.2363 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0621 - mae: 0.3344 - val_loss: 0.0346 - val_mae: 0.2585 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0510 - mae: 0.3118 - val_loss: 0.0364 - val_mae: 0.2653 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0431 - mae: 0.2828 - val_loss: 0.0372 - val_mae: 0.2681 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0381 - mae: 0.2657 - val_loss: 0.0365 - val_mae: 0.2656 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0320 - mae: 0.2398 - val_loss: 0.0345 - val_mae: 0.2578 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0309 - mae: 0.2307 - val_loss: 0.0310 - val_mae: 0.2439 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "검증 세트 MSE: 0.0043342225385716426\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/025820'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/025820'\n",
      "025820의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "025820의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "025820 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/sklearn/utils/_array_api.py:701: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/sklearn/utils/_array_api.py:718: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.21076233183856496 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0906 - mae: 0.4013 - val_loss: 0.1579 - val_mae: 0.5346 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0483 - mae: 0.2801 - val_loss: 0.1087 - val_mae: 0.4381 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0247 - mae: 0.1892 - val_loss: 0.0674 - val_mae: 0.3341 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.1182 - val_loss: 0.0403 - val_mae: 0.2424 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0091 - mae: 0.1097 - val_loss: 0.0270 - val_mae: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.1257 - val_loss: 0.0235 - val_mae: 0.1772 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0146 - mae: 0.1385 - val_loss: 0.0267 - val_mae: 0.1910 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0112 - mae: 0.1173 - val_loss: 0.0342 - val_mae: 0.2211 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0435 - val_mae: 0.2551 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0079 - mae: 0.1056 - val_loss: 0.0521 - val_mae: 0.2857 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0082 - mae: 0.1088 - val_loss: 0.0577 - val_mae: 0.3042 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.1134 - val_loss: 0.0588 - val_mae: 0.3077 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092 - mae: 0.1150 - val_loss: 0.0580 - val_mae: 0.3049 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.1015 - val_loss: 0.0559 - val_mae: 0.2982 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0095 - mae: 0.1158 - val_loss: 0.0521 - val_mae: 0.2857 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0076 - mae: 0.1020 - val_loss: 0.0488 - val_mae: 0.2746 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "검증 세트 MSE: 0.0823812287365337\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.1575757575757577 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.1977 - mae: 0.5923 - val_loss: 0.1839 - val_mae: 0.5929 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1108 - mae: 0.4347 - val_loss: 0.1063 - val_mae: 0.4393 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0815 - mae: 0.3730 - val_loss: 0.0563 - val_mae: 0.3040 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.2744 - val_loss: 0.0234 - val_mae: 0.1864 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0192 - mae: 0.1742 - val_loss: 0.0103 - val_mae: 0.1294 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0069 - mae: 0.0996 - val_loss: 0.0135 - val_mae: 0.1280 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0028 - mae: 0.0583 - val_loss: 0.0254 - val_mae: 0.1749 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0801 - val_loss: 0.0379 - val_mae: 0.2348 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067 - mae: 0.0983 - val_loss: 0.0418 - val_mae: 0.2511 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0079 - mae: 0.1095 - val_loss: 0.0365 - val_mae: 0.2291 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0064 - mae: 0.0979 - val_loss: 0.0317 - val_mae: 0.2072 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0917 - val_loss: 0.0263 - val_mae: 0.1797 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - mae: 0.0766 - val_loss: 0.0216 - val_mae: 0.1573 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0711 - val_loss: 0.0181 - val_mae: 0.1393 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0638 - val_loss: 0.0157 - val_mae: 0.1321 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "검증 세트 MSE: 0.01962299766725148\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 0.7675977653631285\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.2152 - mae: 0.6436 - val_loss: 0.0367 - val_mae: 0.2133 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1622 - mae: 0.5562 - val_loss: 0.0259 - val_mae: 0.1684 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1198 - mae: 0.4742 - val_loss: 0.0197 - val_mae: 0.1425 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0906 - mae: 0.4093 - val_loss: 0.0168 - val_mae: 0.1310 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0778 - mae: 0.3792 - val_loss: 0.0159 - val_mae: 0.1389 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0583 - mae: 0.3245 - val_loss: 0.0163 - val_mae: 0.1565 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.2633 - val_loss: 0.0182 - val_mae: 0.1737 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0290 - mae: 0.2238 - val_loss: 0.0218 - val_mae: 0.1919 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0168 - mae: 0.1655 - val_loss: 0.0273 - val_mae: 0.2107 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0100 - mae: 0.1268 - val_loss: 0.0348 - val_mae: 0.2349 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0924 - val_loss: 0.0389 - val_mae: 0.2475 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0809 - val_loss: 0.0425 - val_mae: 0.2605 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0715 - val_loss: 0.0454 - val_mae: 0.2704 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0040 - mae: 0.0654 - val_loss: 0.0475 - val_mae: 0.2772 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0738 - val_loss: 0.0485 - val_mae: 0.2806 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "검증 세트 MSE: 0.0330694117976886\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.2554 - mae: 0.6969 - val_loss: 0.0523 - val_mae: 0.2443 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2001 - mae: 0.6160 - val_loss: 0.0388 - val_mae: 0.2178 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1549 - mae: 0.5346 - val_loss: 0.0273 - val_mae: 0.1961 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1211 - mae: 0.4670 - val_loss: 0.0232 - val_mae: 0.1975 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0945 - mae: 0.4083 - val_loss: 0.0231 - val_mae: 0.1993 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0612 - mae: 0.3214 - val_loss: 0.0276 - val_mae: 0.2136 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0407 - mae: 0.2606 - val_loss: 0.0364 - val_mae: 0.2284 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0220 - mae: 0.1870 - val_loss: 0.0494 - val_mae: 0.2598 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - mae: 0.1365 - val_loss: 0.0657 - val_mae: 0.3045 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - mae: 0.1252 - val_loss: 0.0729 - val_mae: 0.3235 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0130 - mae: 0.1204 - val_loss: 0.0774 - val_mae: 0.3368 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0166 - mae: 0.1353 - val_loss: 0.0787 - val_mae: 0.3413 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0163 - mae: 0.1328 - val_loss: 0.0774 - val_mae: 0.3380 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0146 - mae: 0.1258 - val_loss: 0.0738 - val_mae: 0.3279 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - mae: 0.1199 - val_loss: 0.0715 - val_mae: 0.3215 - learning_rate: 2.5000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "검증 세트 MSE: 0.05797915737477976\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 0.7518248175182483\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0590 - mae: 0.3315 - val_loss: 0.0054 - val_mae: 0.0944 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0255 - mae: 0.2117 - val_loss: 0.0056 - val_mae: 0.0825 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.1226 - val_loss: 0.0095 - val_mae: 0.1071 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0767 - val_loss: 0.0148 - val_mae: 0.1488 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0704 - val_loss: 0.0193 - val_mae: 0.1772 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0811 - val_loss: 0.0211 - val_mae: 0.1876 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0860 - val_loss: 0.0207 - val_mae: 0.1852 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0828 - val_loss: 0.0194 - val_mae: 0.1782 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - mae: 0.0737 - val_loss: 0.0177 - val_mae: 0.1681 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - mae: 0.0702 - val_loss: 0.0160 - val_mae: 0.1573 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0668 - val_loss: 0.0145 - val_mae: 0.1471 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "검증 세트 MSE: 0.01857310362056235\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0000000000000002\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.4849 - mae: 0.9790 - val_loss: 0.0815 - val_mae: 0.3214 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4042 - mae: 0.8887 - val_loss: 0.0629 - val_mae: 0.2753 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3444 - mae: 0.8179 - val_loss: 0.0506 - val_mae: 0.2516 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2951 - mae: 0.7552 - val_loss: 0.0399 - val_mae: 0.2273 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2374 - mae: 0.6760 - val_loss: 0.0319 - val_mae: 0.2163 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2095 - mae: 0.6346 - val_loss: 0.0263 - val_mae: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1692 - mae: 0.5663 - val_loss: 0.0235 - val_mae: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1309 - mae: 0.4955 - val_loss: 0.0236 - val_mae: 0.1990 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1094 - mae: 0.4473 - val_loss: 0.0262 - val_mae: 0.2010 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0835 - mae: 0.3845 - val_loss: 0.0320 - val_mae: 0.2059 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0618 - mae: 0.3251 - val_loss: 0.0430 - val_mae: 0.2238 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0412 - mae: 0.2495 - val_loss: 0.0602 - val_mae: 0.2883 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0255 - mae: 0.1833 - val_loss: 0.0706 - val_mae: 0.3229 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0200 - mae: 0.1532 - val_loss: 0.0818 - val_mae: 0.3564 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0115 - mae: 0.1123 - val_loss: 0.0931 - val_mae: 0.3876 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0113 - mae: 0.1163 - val_loss: 0.1040 - val_mae: 0.4152 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - mae: 0.1175 - val_loss: 0.1124 - val_mae: 0.4355 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "검증 세트 MSE: 0.043360719007495996\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 0.9145299145299148\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.5927 - mae: 1.0923 - val_loss: 0.1565 - val_mae: 0.5064 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4697 - mae: 0.9659 - val_loss: 0.1131 - val_mae: 0.4174 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3905 - mae: 0.8785 - val_loss: 0.0820 - val_mae: 0.3422 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3077 - mae: 0.7790 - val_loss: 0.0551 - val_mae: 0.2624 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2405 - mae: 0.6868 - val_loss: 0.0331 - val_mae: 0.1911 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1819 - mae: 0.5937 - val_loss: 0.0187 - val_mae: 0.1589 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1205 - mae: 0.4807 - val_loss: 0.0123 - val_mae: 0.1467 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0825 - mae: 0.3908 - val_loss: 0.0131 - val_mae: 0.1477 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0493 - mae: 0.2966 - val_loss: 0.0196 - val_mae: 0.1641 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0244 - mae: 0.1982 - val_loss: 0.0312 - val_mae: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0122 - mae: 0.1238 - val_loss: 0.0466 - val_mae: 0.2770 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0770 - val_loss: 0.0634 - val_mae: 0.3341 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0868 - val_loss: 0.0706 - val_mae: 0.3558 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060 - mae: 0.0990 - val_loss: 0.0757 - val_mae: 0.3703 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0065 - mae: 0.1019 - val_loss: 0.0779 - val_mae: 0.3764 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0998 - val_loss: 0.0780 - val_mae: 0.3771 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - mae: 0.1037 - val_loss: 0.0760 - val_mae: 0.3717 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "검증 세트 MSE: 0.032811848593072915\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.2404 - mae: 0.6808 - val_loss: 0.0228 - val_mae: 0.1810 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1601 - mae: 0.5541 - val_loss: 0.0132 - val_mae: 0.1392 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1128 - mae: 0.4609 - val_loss: 0.0087 - val_mae: 0.1212 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0686 - mae: 0.3558 - val_loss: 0.0086 - val_mae: 0.1137 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0409 - mae: 0.2684 - val_loss: 0.0125 - val_mae: 0.1200 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0210 - mae: 0.1829 - val_loss: 0.0196 - val_mae: 0.1645 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0079 - mae: 0.1041 - val_loss: 0.0292 - val_mae: 0.2172 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0766 - val_loss: 0.0397 - val_mae: 0.2625 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0684 - val_loss: 0.0439 - val_mae: 0.2783 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0701 - val_loss: 0.0464 - val_mae: 0.2874 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - mae: 0.0746 - val_loss: 0.0472 - val_mae: 0.2901 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0047 - mae: 0.0759 - val_loss: 0.0466 - val_mae: 0.2876 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0780 - val_loss: 0.0448 - val_mae: 0.2810 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0704 - val_loss: 0.0436 - val_mae: 0.2767 - learning_rate: 2.5000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "검증 세트 MSE: 0.032934376955647354\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - loss: 0.2823 - mae: 0.7433 - val_loss: 0.2001 - val_mae: 0.5367 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2322 - mae: 0.6732 - val_loss: 0.1572 - val_mae: 0.4659 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1955 - mae: 0.6187 - val_loss: 0.1232 - val_mae: 0.4134 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1644 - mae: 0.5649 - val_loss: 0.1002 - val_mae: 0.3731 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1346 - mae: 0.5098 - val_loss: 0.0830 - val_mae: 0.3461 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1050 - mae: 0.4487 - val_loss: 0.0688 - val_mae: 0.3183 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0808 - mae: 0.3904 - val_loss: 0.0570 - val_mae: 0.2914 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0575 - mae: 0.3255 - val_loss: 0.0499 - val_mae: 0.2815 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0387 - mae: 0.2591 - val_loss: 0.0493 - val_mae: 0.2801 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0221 - mae: 0.1878 - val_loss: 0.0564 - val_mae: 0.2827 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096 - mae: 0.1144 - val_loss: 0.0719 - val_mae: 0.3185 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0841 - val_loss: 0.0931 - val_mae: 0.3511 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0821 - val_loss: 0.1122 - val_mae: 0.3742 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - mae: 0.0972 - val_loss: 0.1198 - val_mae: 0.3863 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0097 - mae: 0.1169 - val_loss: 0.1170 - val_mae: 0.3813 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0085 - mae: 0.1072 - val_loss: 0.1102 - val_mae: 0.3709 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - mae: 0.0869 - val_loss: 0.1021 - val_mae: 0.3612 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0847 - val_loss: 0.0938 - val_mae: 0.3506 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - mae: 0.0761 - val_loss: 0.0866 - val_mae: 0.3408 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "검증 세트 MSE: 0.13443220407195255\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.3409 - mae: 0.8017 - val_loss: 0.0214 - val_mae: 0.1521 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2375 - mae: 0.6644 - val_loss: 0.0134 - val_mae: 0.1315 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1539 - mae: 0.5263 - val_loss: 0.0088 - val_mae: 0.1235 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0870 - mae: 0.3877 - val_loss: 0.0077 - val_mae: 0.1142 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0468 - mae: 0.2685 - val_loss: 0.0113 - val_mae: 0.1236 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0214 - mae: 0.1611 - val_loss: 0.0197 - val_mae: 0.1714 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0100 - mae: 0.1239 - val_loss: 0.0311 - val_mae: 0.2318 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0135 - mae: 0.1341 - val_loss: 0.0400 - val_mae: 0.2692 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0213 - mae: 0.1710 - val_loss: 0.0411 - val_mae: 0.2737 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0198 - mae: 0.1610 - val_loss: 0.0390 - val_mae: 0.2656 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0197 - mae: 0.1611 - val_loss: 0.0350 - val_mae: 0.2493 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0140 - mae: 0.1354 - val_loss: 0.0306 - val_mae: 0.2305 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0134 - mae: 0.1344 - val_loss: 0.0267 - val_mae: 0.2118 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - mae: 0.1238 - val_loss: 0.0235 - val_mae: 0.1954 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "검증 세트 MSE: 0.022506894190733744\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0000000000000002\n",
      "y_train 값 범위: 0.07692307692307665 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1711 - mae: 0.5204 - val_loss: 0.0179 - val_mae: 0.1610 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1338 - mae: 0.4516 - val_loss: 0.0102 - val_mae: 0.1162 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0953 - mae: 0.3768 - val_loss: 0.0064 - val_mae: 0.0948 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0595 - mae: 0.2913 - val_loss: 0.0060 - val_mae: 0.0911 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0371 - mae: 0.2178 - val_loss: 0.0094 - val_mae: 0.1167 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0222 - mae: 0.1604 - val_loss: 0.0170 - val_mae: 0.1567 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0111 - mae: 0.1175 - val_loss: 0.0272 - val_mae: 0.2015 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0104 - mae: 0.1239 - val_loss: 0.0370 - val_mae: 0.2437 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0119 - mae: 0.1379 - val_loss: 0.0426 - val_mae: 0.2648 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0139 - mae: 0.1462 - val_loss: 0.0433 - val_mae: 0.2673 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0145 - mae: 0.1502 - val_loss: 0.0424 - val_mae: 0.2640 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0130 - mae: 0.1435 - val_loss: 0.0397 - val_mae: 0.2538 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0114 - mae: 0.1331 - val_loss: 0.0360 - val_mae: 0.2392 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0113 - mae: 0.1353 - val_loss: 0.0322 - val_mae: 0.2230 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "검증 세트 MSE: 0.011277415925102514\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.6423 - mae: 1.1399 - val_loss: 0.0465 - val_mae: 0.2568 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4895 - mae: 0.9813 - val_loss: 0.0331 - val_mae: 0.2125 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4098 - mae: 0.8942 - val_loss: 0.0248 - val_mae: 0.1807 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3288 - mae: 0.8019 - val_loss: 0.0174 - val_mae: 0.1477 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2740 - mae: 0.7307 - val_loss: 0.0119 - val_mae: 0.1292 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2223 - mae: 0.6579 - val_loss: 0.0084 - val_mae: 0.1130 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1702 - mae: 0.5737 - val_loss: 0.0066 - val_mae: 0.1035 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1219 - mae: 0.4852 - val_loss: 0.0059 - val_mae: 0.0989 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0895 - mae: 0.4138 - val_loss: 0.0065 - val_mae: 0.0950 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0650 - mae: 0.3495 - val_loss: 0.0087 - val_mae: 0.0982 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.2666 - val_loss: 0.0128 - val_mae: 0.1299 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0258 - mae: 0.2109 - val_loss: 0.0191 - val_mae: 0.1698 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110 - mae: 0.1266 - val_loss: 0.0269 - val_mae: 0.2120 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0814 - val_loss: 0.0311 - val_mae: 0.2313 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0640 - val_loss: 0.0347 - val_mae: 0.2467 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0641 - val_loss: 0.0378 - val_mae: 0.2592 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0677 - val_loss: 0.0399 - val_mae: 0.2673 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0680 - val_loss: 0.0412 - val_mae: 0.2720 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "검증 세트 MSE: 0.022903680093424222\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0000000000000009\n",
      "y_train 값 범위: 0.3125 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.1272 - mae: 0.4799 - val_loss: 0.0664 - val_mae: 0.3108 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0657 - mae: 0.3368 - val_loss: 0.0329 - val_mae: 0.2173 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0370 - mae: 0.2393 - val_loss: 0.0214 - val_mae: 0.1819 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0194 - mae: 0.1593 - val_loss: 0.0265 - val_mae: 0.1903 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0119 - mae: 0.1400 - val_loss: 0.0432 - val_mae: 0.2355 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0111 - mae: 0.1244 - val_loss: 0.0598 - val_mae: 0.2877 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0143 - mae: 0.1294 - val_loss: 0.0665 - val_mae: 0.3069 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0164 - mae: 0.1332 - val_loss: 0.0600 - val_mae: 0.2897 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0151 - mae: 0.1367 - val_loss: 0.0536 - val_mae: 0.2711 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.1288 - val_loss: 0.0467 - val_mae: 0.2492 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0097 - mae: 0.1150 - val_loss: 0.0398 - val_mae: 0.2276 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0089 - mae: 0.1129 - val_loss: 0.0337 - val_mae: 0.2080 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - mae: 0.1189 - val_loss: 0.0291 - val_mae: 0.1951 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "검증 세트 MSE: 0.053818152106586185\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.10330578512396715 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.2907 - mae: 0.7064 - val_loss: 0.2546 - val_mae: 0.7046 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2258 - mae: 0.6177 - val_loss: 0.2047 - val_mae: 0.6296 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1828 - mae: 0.5535 - val_loss: 0.1625 - val_mae: 0.5584 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1578 - mae: 0.5154 - val_loss: 0.1310 - val_mae: 0.4984 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1406 - mae: 0.4873 - val_loss: 0.1072 - val_mae: 0.4479 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1110 - mae: 0.4350 - val_loss: 0.0855 - val_mae: 0.3964 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1046 - mae: 0.4179 - val_loss: 0.0657 - val_mae: 0.3425 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0817 - mae: 0.3653 - val_loss: 0.0484 - val_mae: 0.2871 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0606 - mae: 0.3110 - val_loss: 0.0336 - val_mae: 0.2290 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0489 - mae: 0.2763 - val_loss: 0.0215 - val_mae: 0.1691 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0339 - mae: 0.2276 - val_loss: 0.0126 - val_mae: 0.1358 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0210 - mae: 0.1761 - val_loss: 0.0081 - val_mae: 0.1133 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.1528 - val_loss: 0.0090 - val_mae: 0.1047 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0095 - mae: 0.1144 - val_loss: 0.0149 - val_mae: 0.1393 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0815 - val_loss: 0.0242 - val_mae: 0.1890 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0898 - val_loss: 0.0337 - val_mae: 0.2261 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067 - mae: 0.0947 - val_loss: 0.0391 - val_mae: 0.2484 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0069 - mae: 0.0971 - val_loss: 0.0390 - val_mae: 0.2482 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0079 - mae: 0.1053 - val_loss: 0.0370 - val_mae: 0.2398 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.1004 - val_loss: 0.0338 - val_mae: 0.2266 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0886 - val_loss: 0.0302 - val_mae: 0.2133 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0915 - val_loss: 0.0266 - val_mae: 0.1990 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "검증 세트 MSE: 0.015046321689456936\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 0.9227053140096617\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1809 - mae: 0.5580 - val_loss: 0.0249 - val_mae: 0.1940 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1415 - mae: 0.4814 - val_loss: 0.0138 - val_mae: 0.1513 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0850 - mae: 0.3532 - val_loss: 0.0127 - val_mae: 0.1330 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0531 - mae: 0.2563 - val_loss: 0.0230 - val_mae: 0.1573 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0270 - mae: 0.1630 - val_loss: 0.0429 - val_mae: 0.2536 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0200 - mae: 0.1747 - val_loss: 0.0712 - val_mae: 0.3487 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - mae: 0.1840 - val_loss: 0.0981 - val_mae: 0.4195 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.1926 - val_loss: 0.1082 - val_mae: 0.4431 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0251 - mae: 0.1890 - val_loss: 0.1064 - val_mae: 0.4391 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.1865 - val_loss: 0.0992 - val_mae: 0.4225 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0224 - mae: 0.1858 - val_loss: 0.0896 - val_mae: 0.3990 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0189 - mae: 0.1764 - val_loss: 0.0798 - val_mae: 0.3735 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0168 - mae: 0.1728 - val_loss: 0.0713 - val_mae: 0.3496 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "검증 세트 MSE: 0.02969572840442937\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 07\n",
      "[DEBUG] 매핑된 분기: Q3\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (63, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (48, 15, 3)\n",
      "y_train shape: (48,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.3765 - mae: 0.8394 - val_loss: 0.0702 - val_mae: 0.3238 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3350 - mae: 0.7922 - val_loss: 0.0510 - val_mae: 0.2666 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2738 - mae: 0.7149 - val_loss: 0.0368 - val_mae: 0.2274 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2095 - mae: 0.6225 - val_loss: 0.0262 - val_mae: 0.1920 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1852 - mae: 0.5847 - val_loss: 0.0202 - val_mae: 0.1798 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1467 - mae: 0.5191 - val_loss: 0.0162 - val_mae: 0.1685 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1027 - mae: 0.4320 - val_loss: 0.0154 - val_mae: 0.1534 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0750 - mae: 0.3634 - val_loss: 0.0204 - val_mae: 0.1485 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.2545 - val_loss: 0.0335 - val_mae: 0.1997 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0255 - mae: 0.1916 - val_loss: 0.0553 - val_mae: 0.2916 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - mae: 0.1252 - val_loss: 0.0833 - val_mae: 0.3770 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0084 - mae: 0.1040 - val_loss: 0.1105 - val_mae: 0.4441 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - mae: 0.1165 - val_loss: 0.1196 - val_mae: 0.4643 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - mae: 0.1300 - val_loss: 0.1216 - val_mae: 0.4684 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0149 - mae: 0.1344 - val_loss: 0.1179 - val_mae: 0.4600 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0120 - mae: 0.1213 - val_loss: 0.1112 - val_mae: 0.4448 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0101 - mae: 0.1116 - val_loss: 0.1033 - val_mae: 0.4262 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "검증 세트 MSE: 0.03958717100403588\n",
      "033660 트레이더 보고서 추출 완료\n",
      "020000 트레이더 보고서 추출 완료\n",
      "031430 트레이더 보고서 추출 완료\n",
      "093050 트레이더 보고서 추출 완료\n",
      "004370 트레이더 보고서 추출 완료\n",
      "011420 트레이더 보고서 추출 완료\n",
      "001740 트레이더 보고서 추출 완료\n",
      "002880 트레이더 보고서 추출 완료\n",
      "180640 트레이더 보고서 추출 완료\n",
      "025820 트레이더 보고서 추출 완료\n",
      "023800 트레이더 보고서 추출 완료\n",
      "003670 트레이더 보고서 추출 완료\n",
      "000040 트레이더 보고서 추출 완료\n",
      "195870 트레이더 보고서 추출 완료\n",
      "000990 트레이더 보고서 추출 완료\n",
      "003160 트레이더 보고서 추출 완료\n",
      "029460 트레이더 보고서 추출 완료\n",
      "007810 트레이더 보고서 추출 완료\n",
      "092220 트레이더 보고서 추출 완료\n",
      "025560 트레이더 보고서 추출 완료\n",
      "117580 트레이더 보고서 추출 완료\n",
      "128820 트레이더 보고서 추출 완료\n",
      "006400 트레이더 보고서 추출 완료\n",
      "267260 트레이더 보고서 추출 완료\n",
      "009440 트레이더 보고서 추출 완료\n",
      "071970 트레이더 보고서 추출 완료\n",
      "20230101_final_trader_report 보고서를 노션 DB에 저장합니다...\n",
      "페이지 생성 완료: 190cd049-9633-816a-9414-fa678628a001\n",
      "텍스트 블럭 추가 완료\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
