from sub_func import *
from pf_selection import *
from pipeline_utils import *

from crawl_tradingview import *

from datetime import datetime, timedelta

current_dir = os.path.dirname(os.path.abspath(__file__))

# trader ì¤‘ì‹¬ ì½”ë“œ
def generate_trade_log(all_stocks):
    """GPTë¥¼ ì´ìš©í•˜ì—¬ ê±°ë˜ ë¡œê·¸ ìƒì„± (ë§¤ìˆ˜/ë§¤ë„ í¬í•¨)"""
    system_prompt = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ íŠ¸ë ˆì´ë”ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ ì¢…ëª© ì½”ë“œì— ëŒ€í•´ ê±°ë˜ ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”. "
    )

    print("\nDEBUG: ì¢…ëª© ì½”ë“œ ì‚¬ìš© (Before Sending to GPT)")
    for code, stock in all_stocks.items():
        print(f"ğŸ“Œ ì¢…ëª© ì½”ë“œ: {code}")  # ì¢…ëª© ì½”ë“œë§Œ ì¶œë ¥

    stock_list = "\n".join([
        f"{code}: {stock['ë§¤ìˆ˜/ë§¤ë„']} | ëª©í‘œê°€ {stock.get('ëª©í‘œê°€', 'Unknown')}ì›, íˆ¬ìí¬ì¸íŠ¸ {stock.get('íˆ¬ìí¬ì¸íŠ¸', 'N/A')}"
        for code, stock in all_stocks.items()
    ])
    
    prompt = f"""
    ë‹¤ìŒ ì¢…ëª©ë“¤ì— ëŒ€í•œ ê±°ë˜ ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    í•´ë‹¹ ì¢…ëª©ì˜ ë§¤ìˆ˜/ë§¤ë„ ì „ëµì„ í¬í•¨í•˜ì—¬ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

    í˜•ì‹:
    ì¢…ëª© ì½”ë“œ | ë§¤ìˆ˜/ë§¤ë„ | ê°€ê²© | íˆ¬ìí¬ì¸íŠ¸

    ì¢…ëª© ë¦¬ìŠ¤íŠ¸:
    {stock_list}
    
    ë˜í•œ ì¢…ëª©ë“¤ì— ëŒ€í•œ ë§¤ìˆ˜/ë§¤ë„ ì „ëµì´ ëë‚¬ë‹¤ë©´ íˆ¬ì ìˆœìœ„ì™€ ì£¼ì˜í•  ì  ë“±ì„ ë§ˆì§€ë§‰ì— í•œê¸€ë¡œ ì²¨ë¶€í•´ì£¼ì„¸ìš”.
    """

    print("\nğŸ“ Sending trade log request to GPT...")
    print(f"DEBUG: GPTë¡œ ì „ë‹¬í•˜ëŠ” ë°ì´í„°:\n{stock_list}")  # GPTì— ì „ë‹¬í•˜ëŠ” ë°ì´í„° í™•ì¸

    response = to_GPT(system_prompt, prompt)

    trade_log = response["choices"][0]["message"]["content"]
    print("\nâœ… Generated Trade Log:", trade_log)  # ìµœì¢… ì¶œë ¥ í™•ì¸
    
    return trade_log


# analyst ì¤‘ì‹¬ ì½”ë“œ
def fetch_news_data(ticker: str, year: int, quarter: int) -> pd.DataFrame:
    base_path = f"store_data/raw/crawling/corp_rel_news/{ticker}/{year}"
    quarter_months = {1: ['01', '02', '03'], 2: ['04', '05', '06'], 3: ['07', '08', '09'], 4: ['10', '11', '12']}
    news_data = []

    for month in quarter_months[quarter]:
        month_path = os.path.join(base_path, month)
        if os.path.exists(month_path):
            for file in os.listdir(month_path):
                if file.endswith(".csv"):
                    file_path = os.path.join(month_path, file)
                    print(f"ğŸ“‚ CSV íŒŒì¼ ë¡œë“œ ì‹œë„: {file_path}")
                    try:
                        df = pd.read_csv(file_path, encoding='utf-8')  # CSV íŒŒì¼ ì½ê¸°
                        
                        # 1ï¸**íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸**
                        print(f"CSV ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ({file_path}):")
                        print(df.head())  # CSV ë‚´ìš© í™•ì¸
                        
                        # 2ï¸**ì»¬ëŸ¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸**
                        print(f"CSV íŒŒì¼ì˜ ì»¬ëŸ¼ëª…: {df.columns.tolist()}")

                        df.columns = [col.strip() for col in df.columns]  # ê³µë°± ì œê±°
                        
                        # 3ï¸*í•„ìš”í•œ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸**
                        if not {'news_title', 'news_category', 'news_date'}.issubset(df.columns):
                            print(f"CSV íŒŒì¼ {file_path}ì— ì˜ˆìƒëœ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {df.columns}")
                            continue  # ì»¬ëŸ¼ì´ ë‹¤ë¥´ë©´ ìŠ¤í‚µ

                        # 4ï¸**ë‚ ì§œ ë³€í™˜ì´ ì •ìƒì ìœ¼ë¡œ ë˜ëŠ”ì§€ í™•ì¸**
                        df['news_date'] = pd.to_datetime(df['news_date'], format='%Y.%m.%d', errors='coerce')
                        print(f"ë³€í™˜ëœ ë‚ ì§œ ë°ì´í„° (ìµœì´ˆ 5ê°œ):")
                        print(df['news_date'].head())

                        df = df.dropna(subset=['news_date'])  # ë³€í™˜ ì‹¤íŒ¨í•œ ë‚ ì§œ ì œê±°
                        df.rename(columns={'news_title': 'headline'}, inplace=True)  # ì»¬ëŸ¼ëª… ë³€ê²½
                        news_data.append(df[['news_date', 'headline']])
                    
                    except Exception as e:
                        print(f"âš ï¸ CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path} - {e}")

    if news_data:
        news_df = pd.concat(news_data, ignore_index=True)
        news_df = news_df.sort_values(by='news_date')
        news_df.set_index('news_date', inplace=True)
    else:
        print(f"âš ï¸ {ticker}ì— ëŒ€í•œ {year} Q{quarter} ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        news_df = pd.DataFrame(columns=['news_date', 'headline'])

    return news_df


def analyze_news_combined(all_stocks, year, quarter):
    """ëª¨ë“  ì¢…ëª©ì˜ ë‰´ìŠ¤ ë¶„ì„ì„ í•œê¸€ë¡œ ìš”ì•½í•˜ì—¬ 2000ì ì œí•œìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±"""
    system_prompt = f"""
    ë‹¹ì‹ ì€ ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸ì´ë©°, ì£¼ì‹ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    ë¶„ì„ ëŒ€ìƒ ê¸°ê°„ì€ ë°˜ë“œì‹œ **{year}ë…„ {quarter}ë¶„ê¸°**ì…ë‹ˆë‹¤. 
    ë‹¤ë¥¸ ì—°ë„ë‚˜ ë¶„ê¸°ì˜ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ê³ , ì œê³µëœ ë°ì´í„°ë§Œ í™œìš©í•˜ì„¸ìš”.
    """

    stock_news = []
    for ticker in all_stocks.keys():
        news_df = fetch_news_data(ticker, year, quarter)

        if news_df.empty or 'headline' not in news_df.columns:
            print(f"ğŸš¨ {ticker} ë‰´ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŒ: news_df.empty = {news_df.empty}")
            stock_news.append(f"**ì¢…ëª© ì½”ë“œ: {ticker}**\ní˜„ì¬ í•´ë‹¹ ì¢…ëª©ê³¼ ê´€ë ¨ëœ ì£¼ìš” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"âœ… {ticker} ë‰´ìŠ¤ ë¶„ì„ ì¤‘...")
            stock_news.append(f"**ì¢…ëª© ì½”ë“œ: {ticker}**\n" + "\n".join(news_df['headline'].tolist()))

    news_report = "\n\n".join(stock_news)

    prompt = f"""
    ì•„ë˜ëŠ” {year}ë…„ {quarter}ë¶„ê¸° ë™ì•ˆ ê° ì¢…ëª©ê³¼ ê´€ë ¨ëœ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì…ë‹ˆë‹¤.
    ë°˜ë“œì‹œ **{year}ë…„ {quarter}ë¶„ê¸°**ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ë§Œ ë°˜ì˜í•˜ì—¬ í•œêµ­ì–´ë¡œ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    **ë‹¤ë¥¸ ì—°ë„ë‚˜ ìµœì‹  ë°ì´í„°ë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.**
    
    {news_report}
    
    **ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ**:
    
    **í†µí•© ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸**
    
    {year}ë…„ {quarter}ë¶„ê¸° ê¸°ì¤€ìœ¼ë¡œ ì—¬ëŸ¬ ì£¼ìš” ì¢…ëª©ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ì™€ ì‹œì¥ ë™í–¥ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
    
    1. **ì‚¼ì„±ì „ì (005930)**  
    - ìµœê·¼ ë°˜ë„ì²´ ì‹œì¥ ì „ë§ì´ ê¸ì •ì ì´ë©°, {year}ë…„ {quarter}ë¶„ê¸° ì‹¤ì ì´ ì˜ˆìƒë³´ë‹¤ ê°•ì„¸ë¥¼ ë³´ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŒ.
    
    2. **í˜„ëŒ€ì°¨ (005380)**  
    - ì „ê¸°ì°¨ ì‚¬ì—… í™•ì¥ê³¼ ê¸€ë¡œë²Œ ê³µê¸‰ë§ ê°œì„ ì´ ì˜ˆìƒë˜ë©°, {year}ë…„ {quarter}ë¶„ê¸° ë™ì•ˆ ì§€ì†ì ì¸ ì„±ì¥ì„¸ë¥¼ ìœ ì§€ ì¤‘.

    ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    """

    response = to_GPT(system_prompt, prompt)
    
    return response["choices"][0]["message"]["content"][:2000]

def get_t_1_trader_report(today):
    json_file_path = os.path.join(current_dir, './notion_page_ids.json')
    data = read_json(json_file_path)
    t_1_trader_report_id = data['t_1'][f'{today}_t_1_trader_report']
    t_1_trader_report = get_all_text_from_page(t_1_trader_report_id)

    return t_1_trader_report

def get_t_2_t_4_trader_prompts(t_1_trader_report):
    trader_output_format = """{
        "log": "{ë§¤ìˆ˜/ë§¤ë„} | {ìˆ˜ëŸ‰} | {ê°€ê²©}"
    }"""

    trader_prompt = f"""ë‹¹ì‹ ì€ ì£¼ì‹ íŠ¸ë ˆì´ë”ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§¤ìˆ˜ ë˜ëŠ” ë§¤ë„, ê´€ë§ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ê³  ê±°ë˜ ë¡œê·¸ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    ì´ë•Œ, ì´ì „ì— ì €ì¥ëœ t1ì˜ íŠ¸ë ˆì´ë” outputì„ ì°¸ê³ í•˜ì—¬ ë”ìš± ì •í™•í•œ ê±°ë˜ë¥¼ í•´ì•¼ í•©ë‹ˆë‹¤.

    ë§Œì•½ ë§¤ìˆ˜ ë˜ëŠ” ë§¤ë„ë¥¼ ì§„í–‰í•œë‹¤ë©´, ë‹¤ìŒ ì–‘ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤: {trader_output_format}
    ë§Œì•½ ê´€ë§ì„ ì§„í–‰í•œë‹¤ë©´, "ê´€ë§"ì´ë¼ê³  ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    ì¶”ê°€ì ì¸ ë‹¨ì–´ ìƒì„± ì—†ì´, ë°˜ë“œì‹œ {trader_output_format}ì— ë”°ë¼ dictë§Œì„ ì‘ì„±í•˜ê±°ë‚˜, "ê´€ë§"ì´ë¼ê³  ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    ë‹¹ì‹ ì˜ ì—­í• ì€ ìˆ˜ìµì„±ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ì •í™•í•˜ê³  ì‹ ì†í•œ ê±°ë˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ê±°ë˜ ë¡œê·¸ëŠ” ë°˜ë“œì‹œ ì§€ì •ëœ í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

    t1ì˜ íŠ¸ë ˆì´ë” output: {t_1_trader_report}
    """

    return trader_prompt

def get_pf_weights_prompts(target_year, target_quarter, today, logs):
    pf_path = os.path.join(current_dir, f'./pf_logs/{target_year}_{target_quarter}/{today}_portfolio_weights.json')
    pf_before_update = read_json(pf_path)

    pf_update_system = """ì£¼ì–´ì§„ ë‹¤ìŒ ê±°ë˜ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì •í™•íˆ ì—…ë°ì´íŠ¸ í•˜ì„¸ìš”.
    ì¶”ê°€ì ì¸ ê¸€ì´ë‚˜ json delimiter ë”°ìœ„ë¥¼ ìƒì„±í•˜ì§€ ë§ê³ , outputì„ ë°”ë¡œ jsonìœ¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆë„ë¡ ì¶œë ¥í•˜ì„¸ìš”.

    í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ë°˜ë“œì‹œ {ticker: weight} í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì´ë•Œ, ëª¨ë“  ì¢…ëª©ì˜ weightì˜ í•©ì€ ë°˜ë“œì‹œ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    """

    pf_update_prompt = f"""
    ì˜¤ëŠ˜ì˜ ê±°ë˜ ë¡œê·¸: {logs}
    ì´ì „ í¬íŠ¸í´ë¦¬ì˜¤: {pf_before_update}
    """

    return {
        'pf_update_system': pf_update_system,
        'pf_update_prompt': pf_update_prompt
    }

def get_hourly_sp(tickers, start_date, today):
    sp_dict = {}

    # t2_trader
    for i, ticker in enumerate(tickers):
        print(f'=== {i+1}/{len(tickers)} ===')

        try:
            sp_dict[ticker] = {}

            sp = stock_price_info(ticker, start_date, today)[['Close', 'RSI_14', 'BBP_20_2.0']]
            date_obj = datetime.strptime(today, "%Y%m%d")
            new_date_obj = date_obj + timedelta(days=10)
            end_day = new_date_obj.strftime("%Y%m%d")
            sp_dict[ticker]['sp'] = sp

            df = scrape_tradingview_data(ticker, today, end_day)
            filtered_df = df[df['Timestamp'].dt.strftime('%Y%m%d') == today]
            sp_dict[ticker]['hourly_sp'] = filtered_df
        except Exception as e:
            print(f'{e} | Error occurred at {ticker}')
            continue    

    return sp_dict

def t_2_t_4_main(tickers, start_date, today, target_year, target_quarter, base_year, base_quarter):

    t_1_trader_report = get_t_1_trader_report(today)
    trader_prompt = get_t_2_t_4_trader_prompts(t_1_trader_report)

    sp_dict = get_hourly_sp(tickers, start_date, today)


    curr_hour = 9
    t_2_trader_response = {}

    while curr_hour < 16:
        t_2_trader_response[curr_hour] = {}

        for i, ticker in enumerate(tickers):
            print(f'=== [{curr_hour}] {i+1}/{len(tickers)} ({ticker}) ===')

            sp = sp_dict[ticker]['sp'] if ticker in sp_dict and 'sp' in sp_dict[ticker] else 'ì—­ëŒ€ ê°€ê²© ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'

            # `sp_dict[ticker]['hourly_sp']`ì´ ì¡´ì¬í•˜ë©´ DataFrameì„ í•„í„°ë§í•˜ì—¬ ë°”ì¸ë”©
            if ticker in sp_dict and 'hourly_sp' in sp_dict[ticker]:
                df = sp_dict[ticker]['hourly_sp']

                # curr_hour ì´ì „ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                filtered_df = df[df['Timestamp'].dt.hour < curr_hour]

                # ë°ì´í„°ê°€ ì¡´ì¬í•˜ë©´ ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Timestamp ê¸°ì¤€ ê°€ì¥ ìµœê·¼ ê°’)
                if not filtered_df.empty:
                    hourly_sp = filtered_df  # ê°€ì¥ ìµœê·¼ ë°ì´í„° ì„ íƒ
                else:
                    hourly_sp = 'í•´ë‹¹ ì‹œê°„ ì´ì „ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
            else:
                hourly_sp = 'ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'

            price_info = f"""ì—­ëŒ€ ì£¼ì‹ ê°€ê²©: {sp}
            ì‹¤ì‹œê°„ ì£¼ì‹ ê°€ê²©: {hourly_sp}"""

            response = to_GPT(trader_prompt, price_info)['choices'][0]['message']['content']
            t_2_trader_response[curr_hour][ticker] = response

        curr_hour += 1

    to_DB('t_2', f'{today}_t_2_t_4_trader_log', f'{base_quarter}_{base_year}', str(t_2_trader_response))

    pf_weight_prompts = get_pf_weights_prompts(target_year, target_quarter, today, str(t_2_trader_response))
    pf_update_system = pf_weight_prompts['pf_update_system']
    pf_update_prompt = pf_weight_prompts['pf_update_prompt']

    pf_update = to_GPT(pf_update_system, pf_update_prompt)['choices'][0]['message']['content']

    # íŒŒì¼ ê²½ë¡œ
    file_path = os.path.join(os.path.join(current_dir, f'./pf_logs/{target_year}_{target_quarter}'), f"{today}_portfolio_weights.json")

    # JSON íŒŒì¼ ì €ì¥
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(eval(pf_update), f, indent=2, ensure_ascii=False)

    print(f"í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ë°ì´í„°ê°€ {file_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    to_DB('t_2', f'{today}_t_2_t_4_pf_update', f'{base_quarter}_{base_year}', str(pf_update))