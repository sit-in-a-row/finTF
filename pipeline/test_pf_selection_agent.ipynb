{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sub_func import *\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 모델 및 토크나이저 불러오기\n",
    "model_name = \"snunlp/KR-FinBert-SC\"  # Hugging Face에서 제공되는 KR-FinBert\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_selection_report_format = \"\"\"{\n",
    "report: '(생성한 레포트 본문 전체)',\n",
    "sector: '[레포트 내에 언급된 주요 섹터를 리스트 형식으로 반환]'\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "pf_selection_system = f\"\"\"당신은 증권회사의 포트폴리오 전문가입니다.\n",
    "주어진 다음 정보들은 이전 분기의 국제 뉴스, 거시경제 정보, 인덱스 지표들의 가격입니다.\n",
    "이를 바탕으로 다음 분기에 주목해야 할 섹터를 정리해서 보고서 형식으로 출력해야 합니다.\n",
    "보고서의 의견은 반드시 주어진 정보에 기반하여야 합니다.\n",
    "보고서의 형식은 반드시 다음을 따라야 합니다. {pf_selection_report_format}\n",
    "\n",
    "** Return only pure JSON format without any code block or delimiters. **\n",
    "** Make sure that the response does not create JSON decode error. **\n",
    "\"\"\"\n",
    "\n",
    "pf_selection_prompt = f\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_year = '2021'\n",
    "target_quarter = 'Q1'\n",
    "\n",
    "start_date = '20210101'\n",
    "end_date = '20210331'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK에 대해 Inflation Rate 정보를 찾을 수 없습니다. | [Errno 2] No such file or directory: '/Users/yeonsuk/investment/finTF/pipeline/sub_func/get_info/../../../store_data/raw/FRED/UK/Inflation Rate/2021/2021_Inflation Rate.csv'\n"
     ]
    }
   ],
   "source": [
    "# ==== 국제 뉴스 수집 ==== #\n",
    "intl_news_title_list = list(intl_news_info(target_year, start_date, end_date)['news_title'])\n",
    "pf_selection_prompt += f\"\"\"국제 뉴스 헤드라인: {intl_news_title_list}\\n\"\"\"\n",
    "\n",
    "# ==== 거시경제 정보 수집 ==== #\n",
    "def create_macro_econ_dict(country, econ_item):\n",
    "    result_dict = macro_econ_dict[country][econ_item].set_index('Date').to_dict('index')\n",
    "    final_dict = {k: v[list(v.keys())[0]] for k, v in result_dict.items()}\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "reports_dict = {}\n",
    "macro_econ_dict = macro_econ_info(target_year, start_date, end_date)\n",
    "country_list = list(macro_econ_dict.keys())\n",
    "\n",
    "for country in country_list:\n",
    "    target_country_dict = macro_econ_dict[country]\n",
    "    econ_items = list(target_country_dict.keys())\n",
    "    for econ_item in econ_items:\n",
    "        final_dict = create_macro_econ_dict(country, econ_item)\n",
    "        reports_dict[f\"{country}_{econ_item}\"] = final_dict\n",
    "pf_selection_prompt += f\"\"\"국가별 거시경제 정보: {reports_dict}\\n\"\"\"\n",
    "\n",
    "# ==== 인덱스 가격 수집 ==== #\n",
    "index_prices = {}\n",
    "sector_list = [s for s in os.listdir('../store_data/raw/market_data/sector') if '코스피' not in s]\n",
    "\n",
    "for sector in sector_list:\n",
    "    # 토큰수 제한때문에 컬럼 선별해서 넣기...\n",
    "    index_price = index_price_info(sector, start_date, end_date)[['Close', 'Transaction_Val','Market_Cap', 'RSI_14']]\n",
    "    index_prices[sector] = index_price.T.to_dict()\n",
    "\n",
    "pf_selection_prompt += f\"\"\"인덱스 가격 지표: {index_prices}\\n\"\"\"\n",
    "\n",
    "# 201375 -> 293650 -> 385768\n",
    "stock_selection_response = to_GPT(pf_selection_system, pf_selection_prompt)\n",
    "\n",
    "# 여기까지 해서, 투자할 섹터 결정\n",
    "try:\n",
    "    sample = eval(stock_selection_response['choices'][0]['message']['content'])\n",
    "    pf_selection_report = sample['report']\n",
    "    pf_selection_sector = sample['sector']\n",
    "except Exception as e:\n",
    "    print('-'*50)\n",
    "    print(f\"GPT 응답 구조가 올바르지 않음: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 투자 섹터와 연관있는 종목을 찾기 위해 재무 보고서와 임베딩 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = reports_info('005930', target_year, target_quarter)\n",
    "target_report = target_df['1. 회사의 개요.csv'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finTF/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 문장을 벡터로 변환하는 함수 정의\n",
    "def get_sentence_embedding(sentence):\n",
    "    # 문장 토큰화\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    # 모델에서 출력 얻기\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # [CLS] 토큰의 벡터를 사용\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # Batch, CLS token, Hidden size\n",
    "    return cls_embedding\n",
    "\n",
    "# 코사인 유사도 계산 함수\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    # 텐서를 NumPy 배열로 변환 후 코사인 유사도 계산\n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()\n",
    "    return cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "def finBERT_cosine_similarity(sentence, keyword):\n",
    "    \"\"\"\n",
    "    KR-FinBERT으로 임베딩해서 재무보고서와 섹터간의 유사도 분석\n",
    "    \"\"\"\n",
    "    # 문장을 임베딩으로 변환\n",
    "    embedding = get_sentence_embedding(sentence)\n",
    "    keyword_embedding = get_sentence_embedding(keyword)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity = calculate_cosine_similarity(embedding, keyword_embedding)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_dict = {}\n",
    "for sector in pf_selection_sector:\n",
    "    similarity_dict[sector] = finBERT_cosine_similarity(target_report, sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'반도체': 0.30658692,\n",
       " '전기차 및 배터리': 0.26650867,\n",
       " '친환경 및 ESG': 0.80780256,\n",
       " '유통업': 0.55815053,\n",
       " '금융업': 0.7398901}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
