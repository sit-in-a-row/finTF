import notion_client
import pandas as pd
import yaml
import os
import sys
import re

#ì‹œì‘ ì „ ì„¸íŒ…

# pipeline ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../pipeline/sub_func")))
from to_gpt import to_GPT

# API ë° DB ì„¤ì •
def load_api_keys():
    """api_keys.yamlì—ì„œ API í‚¤ë¥¼ ë¡œë“œ"""
    config_path = os.path.join(os.path.dirname(__file__), "../config/api_keys.yaml")
    with open(config_path, "r") as file:
        return yaml.safe_load(file)

api_keys = load_api_keys()
NOTION_API_KEY = api_keys["api_keys"]["NOTION_API_TOKEN"]
T1_DB_ID = api_keys["DB_IDs"]["t_1"]
T4_DB_ID = api_keys["DB_IDs"]["t_4"]

notion = notion_client.Client(auth=NOTION_API_KEY)

def fetch_specific_notion_data(database_id, titles):
    """ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŠ¹ì • ì œëª©ì„ ê°€ì§„ í˜ì´ì§€ ëª©ë¡ì„ ê°€ì ¸ì˜´"""
    response = notion.databases.query(database_id)
    results = []

    for page in response["results"]:
        title_property = page["properties"].get("Title", {}).get("title", [])
        if title_property:
            title = title_property[0]["text"]["content"]
            if title in titles:
                results.append(page)

    print("\nğŸ” Fetched Notion Pages:", results)  
    return results

def fetch_notion_page_content(page_id):
    """Notion í˜ì´ì§€ì˜ ë³¸ë¬¸ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ê¸°"""
    response = notion.blocks.children.list(block_id=page_id)
    content = []

    for block in response["results"]:
        if block["type"] == "paragraph":
            text_content = block["paragraph"]["rich_text"]
            if text_content:
                content.append(text_content[0]["plain_text"])

    full_text = "\n".join(content)
    print("\nğŸ“œ Extracted Text from Notion:\n", full_text[:500])  
    return full_text

def extract_stocks_from_text(text):
    """Notion ë³¸ë¬¸ì—ì„œ ì¢…ëª© ì •ë³´ë¥¼ ì¶”ì¶œ"""
    stock_dict = {}

    pattern_table = r"\|\s*(\d{6})\s*\|\s*(.*?)\s*\|\s*([\d.]+)\s*\|\s*([\d.]+)\s*\|\s*([\d.]+%)\s*\|\s*([\d.]+%)\s*\|\s*([\d,]+)\s*\|\s*(.*?)\s*\|"
    matches_table = re.findall(pattern_table, text)

    print("\nDEBUG: Extracted Stocks (Before Saving)")
    
    for match in matches_table:
        stock_code, company_name, per, pbr, roe, growth, target_price, notes = match
        # ë§¤ìˆ˜/ë§¤ë„ ì—¬ë¶€ íŒë³„
        action = "ë§¤ìˆ˜" if "ì €í‰ê°€" in notes or "ë°˜ë“±" in notes else "ë§¤ë„"

        stock_dict[stock_code] = {
            "ì¢…ëª©ëª…": company_name.strip(),
            "PER": float(per),
            "PBR": float(pbr),
            "ROE": roe,
            "ì´ìµ ì„±ì¥ë¥ ": growth,
            "ëª©í‘œê°€": int(target_price.replace(",", "")),
            "íˆ¬ìí¬ì¸íŠ¸": notes.strip(),
            "ë§¤ìˆ˜/ë§¤ë„": action
        }

        print(f"ğŸ“Œ ì¢…ëª© ì½”ë“œ: {stock_code}, ì¢…ëª©ëª…: {company_name.strip()}")  # ë””ë²„ê¹…ìš©

    return stock_dict


# trader ì¤‘ì‹¬ ì½”ë“œ
def generate_trade_log(all_stocks):
    """GPTë¥¼ ì´ìš©í•˜ì—¬ ê±°ë˜ ë¡œê·¸ ìƒì„± (ë§¤ìˆ˜/ë§¤ë„ í¬í•¨)"""
    system_prompt = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ íŠ¸ë ˆì´ë”ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ ì¢…ëª© ì½”ë“œì— ëŒ€í•´ ê±°ë˜ ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”. "
    )

    print("\nDEBUG: ì¢…ëª© ì½”ë“œ ì‚¬ìš© (Before Sending to GPT)")
    for code, stock in all_stocks.items():
        print(f"ğŸ“Œ ì¢…ëª© ì½”ë“œ: {code}")  # ì¢…ëª© ì½”ë“œë§Œ ì¶œë ¥

    stock_list = "\n".join([
        f"{code}: {stock['ë§¤ìˆ˜/ë§¤ë„']} | ëª©í‘œê°€ {stock.get('ëª©í‘œê°€', 'Unknown')}ì›, íˆ¬ìí¬ì¸íŠ¸ {stock.get('íˆ¬ìí¬ì¸íŠ¸', 'N/A')}"
        for code, stock in all_stocks.items()
    ])
    
    prompt = f"""
    ë‹¤ìŒ ì¢…ëª©ë“¤ì— ëŒ€í•œ ê±°ë˜ ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    í•´ë‹¹ ì¢…ëª©ì˜ ë§¤ìˆ˜/ë§¤ë„ ì „ëµì„ í¬í•¨í•˜ì—¬ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

    í˜•ì‹:
    ì¢…ëª© ì½”ë“œ | ë§¤ìˆ˜/ë§¤ë„ | ê°€ê²© | íˆ¬ìí¬ì¸íŠ¸

    ì¢…ëª© ë¦¬ìŠ¤íŠ¸:
    {stock_list}
    
    ë˜í•œ ì¢…ëª©ë“¤ì— ëŒ€í•œ ë§¤ìˆ˜/ë§¤ë„ ì „ëµì´ ëë‚¬ë‹¤ë©´ íˆ¬ì ìˆœìœ„ì™€ ì£¼ì˜í•  ì  ë“±ì„ ë§ˆì§€ë§‰ì— í•œê¸€ë¡œ ì²¨ë¶€í•´ì£¼ì„¸ìš”.
    """

    print("\nğŸ“ Sending trade log request to GPT...")
    print(f"DEBUG: GPTë¡œ ì „ë‹¬í•˜ëŠ” ë°ì´í„°:\n{stock_list}")  # GPTì— ì „ë‹¬í•˜ëŠ” ë°ì´í„° í™•ì¸

    response = to_GPT(system_prompt, prompt)

    trade_log = response["choices"][0]["message"]["content"]
    print("\nâœ… Generated Trade Log:", trade_log)  # ìµœì¢… ì¶œë ¥ í™•ì¸
    
    return trade_log


# analyst ì¤‘ì‹¬ ì½”ë“œ
def fetch_news_data(ticker: str, year: int, quarter: int) -> pd.DataFrame:
    base_path = f"store_data/raw/crawling/corp_rel_news/{ticker}/{year}"
    quarter_months = {1: ['01', '02', '03'], 2: ['04', '05', '06'], 3: ['07', '08', '09'], 4: ['10', '11', '12']}
    news_data = []

    for month in quarter_months[quarter]:
        month_path = os.path.join(base_path, month)
        if os.path.exists(month_path):
            for file in os.listdir(month_path):
                if file.endswith(".csv"):
                    file_path = os.path.join(month_path, file)
                    print(f"ğŸ“‚ CSV íŒŒì¼ ë¡œë“œ ì‹œë„: {file_path}")
                    try:
                        df = pd.read_csv(file_path, encoding='utf-8')  # CSV íŒŒì¼ ì½ê¸°
                        
                        # 1ï¸**íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸**
                        print(f"CSV ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ({file_path}):")
                        print(df.head())  # CSV ë‚´ìš© í™•ì¸
                        
                        # 2ï¸**ì»¬ëŸ¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸**
                        print(f"CSV íŒŒì¼ì˜ ì»¬ëŸ¼ëª…: {df.columns.tolist()}")

                        df.columns = [col.strip() for col in df.columns]  # ê³µë°± ì œê±°
                        
                        # 3ï¸*í•„ìš”í•œ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸**
                        if not {'news_title', 'news_category', 'news_date'}.issubset(df.columns):
                            print(f"CSV íŒŒì¼ {file_path}ì— ì˜ˆìƒëœ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {df.columns}")
                            continue  # ì»¬ëŸ¼ì´ ë‹¤ë¥´ë©´ ìŠ¤í‚µ

                        # 4ï¸**ë‚ ì§œ ë³€í™˜ì´ ì •ìƒì ìœ¼ë¡œ ë˜ëŠ”ì§€ í™•ì¸**
                        df['news_date'] = pd.to_datetime(df['news_date'], format='%Y.%m.%d', errors='coerce')
                        print(f"ë³€í™˜ëœ ë‚ ì§œ ë°ì´í„° (ìµœì´ˆ 5ê°œ):")
                        print(df['news_date'].head())

                        df = df.dropna(subset=['news_date'])  # ë³€í™˜ ì‹¤íŒ¨í•œ ë‚ ì§œ ì œê±°
                        df.rename(columns={'news_title': 'headline'}, inplace=True)  # ì»¬ëŸ¼ëª… ë³€ê²½
                        news_data.append(df[['news_date', 'headline']])
                    
                    except Exception as e:
                        print(f"âš ï¸ CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path} - {e}")

    if news_data:
        news_df = pd.concat(news_data, ignore_index=True)
        news_df = news_df.sort_values(by='news_date')
        news_df.set_index('news_date', inplace=True)
    else:
        print(f"âš ï¸ {ticker}ì— ëŒ€í•œ {year} Q{quarter} ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        news_df = pd.DataFrame(columns=['news_date', 'headline'])

    return news_df


def analyze_news_combined(all_stocks, year, quarter):
    """ëª¨ë“  ì¢…ëª©ì˜ ë‰´ìŠ¤ ë¶„ì„ì„ í•œê¸€ë¡œ ìš”ì•½í•˜ì—¬ 2000ì ì œí•œìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±"""
    system_prompt = f"""
    ë‹¹ì‹ ì€ ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸ì´ë©°, ì£¼ì‹ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    ë¶„ì„ ëŒ€ìƒ ê¸°ê°„ì€ ë°˜ë“œì‹œ **{year}ë…„ {quarter}ë¶„ê¸°**ì…ë‹ˆë‹¤. 
    ë‹¤ë¥¸ ì—°ë„ë‚˜ ë¶„ê¸°ì˜ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ê³ , ì œê³µëœ ë°ì´í„°ë§Œ í™œìš©í•˜ì„¸ìš”.
    """

    stock_news = []
    for ticker in all_stocks.keys():
        news_df = fetch_news_data(ticker, year, quarter)

        if news_df.empty or 'headline' not in news_df.columns:
            print(f"ğŸš¨ {ticker} ë‰´ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŒ: news_df.empty = {news_df.empty}")
            stock_news.append(f"**ì¢…ëª© ì½”ë“œ: {ticker}**\ní˜„ì¬ í•´ë‹¹ ì¢…ëª©ê³¼ ê´€ë ¨ëœ ì£¼ìš” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"âœ… {ticker} ë‰´ìŠ¤ ë¶„ì„ ì¤‘...")
            stock_news.append(f"**ì¢…ëª© ì½”ë“œ: {ticker}**\n" + "\n".join(news_df['headline'].tolist()))

    news_report = "\n\n".join(stock_news)

    prompt = f"""
    ì•„ë˜ëŠ” {year}ë…„ {quarter}ë¶„ê¸° ë™ì•ˆ ê° ì¢…ëª©ê³¼ ê´€ë ¨ëœ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì…ë‹ˆë‹¤.
    ë°˜ë“œì‹œ **{year}ë…„ {quarter}ë¶„ê¸°**ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ë§Œ ë°˜ì˜í•˜ì—¬ í•œêµ­ì–´ë¡œ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    **ë‹¤ë¥¸ ì—°ë„ë‚˜ ìµœì‹  ë°ì´í„°ë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.**
    
    {news_report}
    
    **ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ**:
    
    **í†µí•© ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸**
    
    {year}ë…„ {quarter}ë¶„ê¸° ê¸°ì¤€ìœ¼ë¡œ ì—¬ëŸ¬ ì£¼ìš” ì¢…ëª©ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ì™€ ì‹œì¥ ë™í–¥ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
    
    1. **ì‚¼ì„±ì „ì (005930)**  
    - ìµœê·¼ ë°˜ë„ì²´ ì‹œì¥ ì „ë§ì´ ê¸ì •ì ì´ë©°, {year}ë…„ {quarter}ë¶„ê¸° ì‹¤ì ì´ ì˜ˆìƒë³´ë‹¤ ê°•ì„¸ë¥¼ ë³´ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŒ.
    
    2. **í˜„ëŒ€ì°¨ (005380)**  
    - ì „ê¸°ì°¨ ì‚¬ì—… í™•ì¥ê³¼ ê¸€ë¡œë²Œ ê³µê¸‰ë§ ê°œì„ ì´ ì˜ˆìƒë˜ë©°, {year}ë…„ {quarter}ë¶„ê¸° ë™ì•ˆ ì§€ì†ì ì¸ ì„±ì¥ì„¸ë¥¼ ìœ ì§€ ì¤‘.

    ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    """

    response = to_GPT(system_prompt, prompt)
    
    return response["choices"][0]["message"]["content"][:2000]


# ë…¸ì…˜ì— ì €ì¥
def save_to_notion(title, content, database_id, period):
    """Notion ë°ì´í„°ë² ì´ìŠ¤ì— ìƒˆë¡œìš´ í˜ì´ì§€ë¥¼ ì¶”ê°€í•˜ê³  ë³¸ë¬¸ì„ í•œê¸€ë¡œ ì±„ì›€"""

    new_page = notion.pages.create(
        parent={"database_id": database_id},
        properties={
            "Title": {
                "title": [{"text": {"content": title}}]
            },
            "Period": {
                "rich_text": [{"text": {"content": period}}]
            }
        }
    )

    page_id = new_page["id"]
    notion.blocks.children.append(
        block_id=page_id,
        children=[
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": content[:2000]}}]
                }
            }
        ]
    )

# ë©”ì¸
def main(year, quarter):
    period = f"{year}_Q{quarter}"  

    pages = fetch_specific_notion_data(T1_DB_ID, [f"{period}_analyst_rp", f"{period}_final_trader_report"])
    all_stocks = {}

    for page in pages:
        stocks = extract_stocks_from_text(fetch_notion_page_content(page["id"]))
        all_stocks.update(stocks)

    trade_log = generate_trade_log(all_stocks)
    save_to_notion(f"{period}_trader_log", trade_log, T4_DB_ID, period)

    analyst_report = analyze_news_combined(all_stocks, year, quarter)
    save_to_notion(f"{period}_analyst_report", analyst_report, T4_DB_ID, period)

if __name__ == "__main__":
    main(2022, 4) # ì˜ˆì‹œ
