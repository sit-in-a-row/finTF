{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from sub_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_metrics(sector_info):\n",
    "    \"\"\"섹터 정보에서 Carhart 4 factor 관련 주요 지표 추출\"\"\"\n",
    "    if sector_info is None:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'market_beta': sector_info.get('market_beta', 0),\n",
    "        'size_factor': sector_info.get('size_factor', 0),\n",
    "        'value_factor': sector_info.get('value_factor', 0),\n",
    "        'momentum_factor': sector_info.get('momentum_factor', 0)\n",
    "    }\n",
    "\n",
    "def extract_sentiment_score(df):\n",
    "    \"\"\"감성분석 결과를 numerical score로 변환\"\"\"\n",
    "    def get_score(result):\n",
    "        if isinstance(result, dict):\n",
    "            # 딕셔너리에서 감성 결과 추출 (예: result.get('sentiment') 등)\n",
    "            sentiment = result.get('sentiment', 'neutral')  # 적절한 키로 수정\n",
    "        else:\n",
    "            sentiment = result\n",
    "            \n",
    "        score_mapping = {\n",
    "            'positive': 1.0,\n",
    "            'neutral': 0.0,\n",
    "            'negative': -1.0\n",
    "        }\n",
    "        return score_mapping.get(sentiment, 0.0)\n",
    "    \n",
    "    df['sentiment_score'] = df['SA_result'].apply(get_score)\n",
    "    return df\n",
    "\n",
    "def filter_by_percentile_and_label(df, label, percentile):\n",
    "    \"\"\"특정 감성의 상위/하위 percentile에 해당하는 뉴스 필터링\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # label에 따라 필터링\n",
    "    if label == 'positive':\n",
    "        filtered_df = df[df['SA_result'] == 'positive']\n",
    "        return filtered_df.nlargest(int(len(filtered_df) * percentile/100), 'sentiment_score')\n",
    "    else:  # negative\n",
    "        filtered_df = df[df['SA_result'] == 'negative']\n",
    "        return filtered_df.nsmallest(int(len(filtered_df) * percentile/100), 'sentiment_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvestmentReportGenerator:\n",
    "    \"\"\"Investment report generation class with GPT integration\"\"\"\n",
    "    \n",
    "    MARKDOWN_INSTRUCTION = \"\"\"\n",
    "    응답은 반드시 markdown 문법에 따라 작성되어야 합니다.\n",
    "    ** 보고서에는 반드시 주어진 정보에 대한 분석이 필요합니다 **\n",
    "    \"\"\"\n",
    "\n",
    "    ANALYST_BASE_PROMPT = \"\"\"\n",
    "    당신은 증권회사에 고용된 {role}입니다.\n",
    "    주식투자의 관점에서 주어진 정보들을 요약하고, 이에 대한 의견을 알려주세요.\n",
    "    {additional_instructions}\n",
    "    {markdown_instruction}\n",
    "    \"\"\"\n",
    "\n",
    "    INDIVIDUAL_REPORT_SYSTEM = \"\"\"증권사 애널리스트로서 종목 분석 보고서 작성\n",
    "        # 필수 섹션\n",
    "        1. 기업 개요\n",
    "        - 사업 모델과 핵심 역량\n",
    "        - 시장 포지셔닝\n",
    "\n",
    "        2. 재무 분석\n",
    "        - 핵심 재무지표 분석\n",
    "        - 수익성/성장성 평가\n",
    "\n",
    "        3. 섹터 분석\n",
    "        - 산업 동향과 경쟁력\n",
    "        - 기술적 분석 시사점\n",
    "\n",
    "        4. 투자의견\n",
    "        - 투자포인트 3개\n",
    "        - 주요 리스크\n",
    "        - 목표가 및 근거\n",
    "\n",
    "        요구사항:\n",
    "        - 구체적 데이터 기반\n",
    "        - 명확한 투자 논리 제시\n",
    "        \"\"\" + MARKDOWN_INSTRUCTION\n",
    "\n",
    "    def __init__(self, tickers: list, year: str, quarter: str):\n",
    "        self.tickers = tickers\n",
    "        self.year = year\n",
    "        self.quarter = quarter\n",
    "        self.prompts = self._initialize_prompts()\n",
    "        self.responses = {ticker: {} for ticker in tickers}\n",
    "        self.individual_reports = {}\n",
    "        self.start_date, self.end_date = self._get_date_range()\n",
    "        \n",
    "    def generate_individual_report(self, ticker: str) -> str:\n",
    "        \"\"\"Generate a comprehensive report for a single stock\"\"\"\n",
    "        print(f\"\\n=== {ticker} 분석 중... ===\")\n",
    "        \n",
    "        try:\n",
    "            # Financial analysis\n",
    "            financial_data = self.analyze_financial_data(ticker)\n",
    "            \n",
    "            # Sector and pattern analysis\n",
    "            sector_analysis = self.analyze_sector_and_pattern(ticker)\n",
    "            \n",
    "            # News analysis with enhanced error handling\n",
    "            try:\n",
    "                news_data = corp_rel_news_info(ticker, self.year, self.start_date, self.end_date)\n",
    "                news_summary = self._process_news(news_data) if news_data is not None else {\"Positive\": [], \"Negative\": []}\n",
    "            except FileNotFoundError:\n",
    "                print(f\"{ticker}의 뉴스 데이터가 없습니다. 분석을 계속합니다.\")\n",
    "                news_summary = {\"Positive\": [], \"Negative\": []}\n",
    "            except Exception as e:\n",
    "                print(f\"{ticker}의 뉴스 처리 중 오류 발생: {e}. 분석을 계속합니다.\")\n",
    "                news_summary = {\"Positive\": [], \"Negative\": []}\n",
    "            \n",
    "            # Stock price data\n",
    "            try:\n",
    "                stock_price = stock_price_info(ticker, self.start_date, self.end_date)\n",
    "                price_dict = stock_price.to_dict() if stock_price is not None and not stock_price.empty else None\n",
    "            except Exception as e:\n",
    "                print(f\"{ticker}의 주가 정보 처리 중 오류 발생: {e}. 분석을 계속합니다.\")\n",
    "                price_dict = None\n",
    "            \n",
    "            # Combine all data for individual report\n",
    "            report_prompt = \"\\n\".join([\n",
    "                f\"=== {ticker} 종목 분석 ===\",\n",
    "                f\"재무제표 및 재무 비율 분석: {financial_data}\",\n",
    "                f\"섹터 분석: {sector_analysis}\",\n",
    "                f\"종목 관련 뉴스: {news_summary}\",\n",
    "                f\"주가 정보: {price_dict}\"\n",
    "            ])\n",
    "            \n",
    "            # Generate individual report\n",
    "            report = to_GPT(self.INDIVIDUAL_REPORT_SYSTEM, report_prompt)\n",
    "            self.individual_reports[ticker] = report\n",
    "            return report\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{ticker} 분석 중 오류 발생: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _initialize_prompts(self) -> Dict[str, str]:\n",
    "        \"\"\"Initialize system prompts with templated format\"\"\"\n",
    "        return {\n",
    "            \"financial_system\": self.ANALYST_BASE_PROMPT.format(\n",
    "                role=\"재무전문가\",\n",
    "                additional_instructions=\"보고서 근거 기반 의견 제시\",\n",
    "                markdown_instruction=self.MARKDOWN_INSTRUCTION\n",
    "            ),\n",
    "            \"intl_macro_system\": self.ANALYST_BASE_PROMPT.format(\n",
    "                role=\"국제관계전문가\",\n",
    "                additional_instructions=\"국가별 금리, GDP, 인플레이션 등 거시경제 정보 분석\",\n",
    "                markdown_instruction=self.MARKDOWN_INSTRUCTION\n",
    "            ),\n",
    "            \"sector_system\": \"\"\"증권사 경제전문가로서 투자 관점에서 정보 분석 및 의견 제시\n",
    "                # 필수 포함 사항\n",
    "                - 섹터별 성과와 동향 분석\n",
    "                - 투자 매력도 평가 (근거 제시)\n",
    "                - 차트 패턴 분석 및 기술적 시사점\n",
    "                \"\"\" + self.MARKDOWN_INSTRUCTION,\n",
    "            \"final_system\": \"\"\"증권사 리서치센터장으로서 개별 애널리스트 보고서들을 종합하여 최종 투자전략 보고서 작성\n",
    "                # 필수 섹션\n",
    "                1. 거시경제 분석 요약\n",
    "                - 글로벌 동향 핵심 포인트\n",
    "                - 주요 리스크 요인\n",
    "\n",
    "                2. 개별 종목 분석 종합\n",
    "                - 각 종목 투자매력도 비교\n",
    "                - 상대가치 평가\n",
    "\n",
    "                3. 최종 포트폴리오 전략\n",
    "                - 종목별 투자비중 추천과 근거\n",
    "                - 위험관리 방안\n",
    "\n",
    "                4. 핵심 결론\n",
    "                - 최우선 투자 추천 종목\n",
    "                - 중점 모니터링 요소\n",
    "\n",
    "                작성 지침:\n",
    "                - 개별 애널리스트 보고서의 분석을 비교/종합하여 결론 도출\n",
    "                - 종목간 상대매력도를 구체적 근거와 함께 제시\n",
    "                - 실행 가능한 투자전략 제안\n",
    "                \"\"\" + self.MARKDOWN_INSTRUCTION\n",
    "        }\n",
    "\n",
    "    def _get_date_range(self) -> tuple:\n",
    "        \"\"\"Get start and end dates for the given quarter\"\"\"\n",
    "        quarter_months = {\n",
    "            'Q1': ('01', '03'),\n",
    "            'Q2': ('04', '06'),\n",
    "            'Q3': ('07', '09'),\n",
    "            'Q4': ('10', '12')\n",
    "        }\n",
    "        \n",
    "        if self.quarter in quarter_months:\n",
    "            start_month, end_month = quarter_months[self.quarter]\n",
    "            start_date = f\"{self.year}{start_month}01\"\n",
    "            end_date = f\"{self.year}{end_month}{'30' if end_month in ['06', '09'] else '31'}\"\n",
    "            return start_date, end_date\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid quarter: {self.quarter}\")\n",
    "\n",
    "    def analyze_financial_data(self, ticker: str) -> str:\n",
    "        \"\"\"Analyze financial statements and generate report\"\"\"\n",
    "        try:\n",
    "            fin_statement = get_raw_fin_statement_info(ticker, self.year, self.quarter)\n",
    "            fin_statement_dict = fin_statement.to_dict() if fin_statement is not None else {}\n",
    "        except Exception:\n",
    "            fin_statement_dict = {}\n",
    "\n",
    "        try:\n",
    "            fin_ratio = fin_statement_info(ticker, self.year, self.quarter)\n",
    "            fin_ratio_dict = fin_ratio.to_dict('records')[0] if fin_ratio is not None and not fin_ratio.empty else {}\n",
    "        except Exception:\n",
    "            fin_ratio_dict = {}\n",
    "\n",
    "        try:\n",
    "            fin_report = reports_info(ticker, self.year, self.quarter)\n",
    "            report_content = fin_report['1. 요약재무정보.csv'][0][4:-4] if not fin_report.empty else \"정보 없음\"\n",
    "        except Exception:\n",
    "            report_content = \"정보 없음\"\n",
    "        \n",
    "        prompt_data = {\n",
    "            \"재무제표\": fin_statement_dict,\n",
    "            \"주요 재무 비율\": fin_ratio_dict,\n",
    "            \"재무보고서\": report_content\n",
    "        }\n",
    "        \n",
    "        self.prompts[\"financial_prompt\"] = \"\\n\".join(f\"{k}: {v}\" for k, v in prompt_data.items())\n",
    "        return to_GPT(self.prompts[\"financial_system\"], self.prompts[\"financial_prompt\"])\n",
    "\n",
    "    def analyze_international_macro(self) -> str:\n",
    "        \"\"\"Analyze international news and macroeconomic data\"\"\"\n",
    "        try:\n",
    "            intl_news = intl_news_info(self.year, self.start_date, self.end_date)\n",
    "            news_titles = list(intl_news['news_title']) if intl_news is not None and not intl_news.empty else []\n",
    "        except Exception:\n",
    "            news_titles = []\n",
    "\n",
    "        try:\n",
    "            macro_data = macro_econ_info(self.year, self.start_date, self.end_date)\n",
    "        except Exception:\n",
    "            macro_data = \"거시경제 데이터 없음\"\n",
    "        \n",
    "        self.prompts[\"intl_macro_prompt\"] = \"\\n\".join([\n",
    "            f\"국제 뉴스 헤드라인: {news_titles}\",\n",
    "            f\"거시경제 관련 정보: {macro_data}\"\n",
    "        ])\n",
    "        \n",
    "        return to_GPT(self.prompts[\"intl_macro_system\"], self.prompts[\"intl_macro_prompt\"])\n",
    "\n",
    "    def analyze_sector_and_pattern(self, ticker: str) -> str:\n",
    "        \"\"\"Analyze sector trends and chart patterns\"\"\"\n",
    "        index_prices = {}\n",
    "        try:\n",
    "            sector_list = [s for s in os.listdir('../store_data/raw/market_data/sector') \n",
    "                          if '코스피' not in s]\n",
    "        except Exception:\n",
    "            sector_list = []\n",
    "        \n",
    "        # Collect sector data\n",
    "        for sector in sector_list:\n",
    "            try:\n",
    "                index_price = index_price_info(sector, self.start_date, self.end_date)\n",
    "                if index_price is not None and not index_price.empty:\n",
    "                    index_price = index_price[['Close', 'Transaction_Val', 'Market_Cap', 'RSI_14']]\n",
    "                    index_prices[sector] = index_price.T.to_dict()\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # Collect sector analysis\n",
    "        sector_infos = {}\n",
    "        for sector in sector_list:\n",
    "            try:\n",
    "                sector_analysis = sector_analysis_info(sector, self.year, self.quarter)\n",
    "                if sector_analysis is not None:\n",
    "                    sector_infos[sector] = extract_key_metrics(sector_analysis)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            pattern_data = pattern_info(ticker, self.end_date.replace('-', ''))\n",
    "            pattern_dict = pattern_data.to_dict('records') if pattern_data is not None and not pattern_data.empty else None\n",
    "        except Exception:\n",
    "            pattern_dict = None\n",
    "        \n",
    "        self.prompts[\"sector_prompt\"] = \"\\n\".join([\n",
    "            f\"섹터별 가격 정보: {index_prices}\",\n",
    "            f\"섹터별 carhart 4 factor 분석: {sector_infos}\",\n",
    "            f\"차트 패턴 분석 결과: {pattern_dict}\"\n",
    "        ])\n",
    "        \n",
    "        return to_GPT(self.prompts[\"sector_system\"], self.prompts[\"sector_prompt\"])\n",
    "\n",
    "    def analyze_stocks(self):\n",
    "        \"\"\"Execute analysis for all stocks\"\"\"\n",
    "        # Only analyze macro once\n",
    "        macro_response = self.analyze_international_macro()\n",
    "        self.responses[\"international_macro\"] = macro_response\n",
    "        \n",
    "        for ticker in self.tickers:\n",
    "            print(f\"\\n=== {ticker} 분석 중... ===\")\n",
    "            try:\n",
    "                self.responses[ticker].update({\n",
    "                    \"financial\": self.analyze_financial_data(ticker),\n",
    "                    \"sector_pattern_analysis\": self.analyze_sector_and_pattern(ticker)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"{ticker} 분석 중 오류 발생: {e}\")\n",
    "\n",
    "    def generate_final_report(self) -> dict:\n",
    "        try:\n",
    "            # 종목들의 개별 보고서만 포함하기\n",
    "            combined_prompt = []\n",
    "            \n",
    "            for ticker in self.tickers:\n",
    "                if ticker not in self.individual_reports:\n",
    "                    print(f\"{ticker} 보고서 없음\")\n",
    "                    pass\n",
    "                \n",
    "                report = self.individual_reports.get(ticker)\n",
    "                if report:\n",
    "                    combined_prompt.append(f\"\\n=== {ticker} 종목 분석 ===\")\n",
    "                    report_content = report.get('choices', [{}])[0].get('message', {}).get('content', '') if isinstance(report, dict) else str(report)\n",
    "                    combined_prompt.append(report_content)\n",
    "\n",
    "            prompt = \"\\n\".join(combined_prompt)\n",
    "\n",
    "            # 최종 보고서 생성 요청\n",
    "            final_response = to_GPT(self.prompts[\"final_system\"], prompt)\n",
    "            return final_response\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"generate_final_report에서 예외 발생: {e}\")\n",
    "            return {}\n",
    "\n",
    "    \n",
    "    def _process_news(self, corp_news_df) -> Dict[str, list]:\n",
    "        \"\"\"Process corporate news and extract sentiment\"\"\"\n",
    "        news_summary = {'Positive': [], 'Negative': []}\n",
    "        \n",
    "        if corp_news_df is not None and not corp_news_df.empty:\n",
    "            try:\n",
    "                # 증권 카테고리 필터링\n",
    "                corp_news_df = corp_news_df[corp_news_df['news_category'].str.contains('증권', na=False)]\n",
    "                \n",
    "                if not corp_news_df.empty:\n",
    "                    # SA 결과 및 감성 점수 추출\n",
    "                    corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x: \n",
    "                        get_SA_result(x) if pd.notna(x) else None)\n",
    "                    \n",
    "                    # None이나 NaN이 아닌 행만 감성 점수 추출\n",
    "                    valid_news = corp_news_df.dropna(subset=['SA_result'])\n",
    "                    if not valid_news.empty:\n",
    "                        valid_news = extract_sentiment_score(valid_news)\n",
    "                        \n",
    "                        for sentiment in ['positive', 'negative']:\n",
    "                            try:\n",
    "                                news = filter_by_percentile_and_label(valid_news, sentiment, 20)\n",
    "                                if not news.empty:\n",
    "                                    news_summary[sentiment.capitalize()] = list(news['news_title'])\n",
    "                            except Exception:\n",
    "                                continue\n",
    "            except Exception as e:\n",
    "                print(f\"뉴스 처리 중 오류 발생: {e}\")\n",
    "        \n",
    "        return news_summary\n",
    "\n",
    "    def _get_response_content(self, response: Dict) -> str:\n",
    "        \"\"\"GPT 응답에서 content 추출\"\"\"\n",
    "        try:\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"\"\n",
    "        \n",
    "    def save_final_report(self, final_response: Dict) -> None:\n",
    "        \"\"\"최종 포트폴리오 매니저 보고서 저장\"\"\"\n",
    "        page_title = f\"{self.year}_{self.quarter}_analyst_rp\"\n",
    "        content = self._get_response_content(final_response)\n",
    "        \n",
    "        print(f\"{page_title} 보고서를 노션 DB에 저장합니다...\")\n",
    "        to_DB('t_1', page_title, f\"{self.quarter}_{self.year}\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK에 대해 Inflation Rate 정보를 찾을 수 없습니다. | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/FRED/UK/Inflation Rate/2022/2022_Inflation Rate.csv'\n",
      "\n",
      "=== 093050 분석 중... ===\n",
      "\n",
      "=== 035720 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/035720/_035720_재무제표 ().csv'\n",
      "035720의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "035720의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 031430 분석 중... ===\n",
      "\n",
      "=== 011070 분석 중... ===\n",
      "\n",
      "=== 000480 분석 중... ===\n",
      "\n",
      "=== 039130 분석 중... ===\n",
      "\n",
      "=== 033660 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.10/2022.10_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.11/2022.11_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.12/2022.12_033660.csv 파일을 찾을 수 없습니다.\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "033660의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "033660의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 195870 분석 중... ===\n",
      "\n",
      "=== 029460 분석 중... ===\n",
      "\n",
      "=== 264900 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "264900의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "264900의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 077500 분석 중... ===\n",
      "\n",
      "=== 267850 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "267850의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "267850의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 092220 분석 중... ===\n",
      "\n",
      "=== 004370 분석 중... ===\n",
      "\n",
      "=== 001740 분석 중... ===\n",
      "\n",
      "=== 007810 분석 중... ===\n",
      "\n",
      "=== 008770 분석 중... ===\n",
      "\n",
      "=== 011420 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "011420의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "011420의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 025560 분석 중... ===\n",
      "\n",
      "=== 000990 분석 중... ===\n",
      "\n",
      "=== 020000 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/020000/_020000_재무제표 ().csv'\n",
      "020000의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "020000의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 023800 분석 중... ===\n",
      "\n",
      "=== 003160 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/003160/_003160_재무제표 ().csv'\n",
      "003160의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "003160의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 093050 분석 중... ===\n",
      "\n",
      "=== 035720 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/035720/_035720_재무제표 ().csv'\n",
      "035720의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "035720의 fin_statement_info 정보를 확인할 수 없습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 031430 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 011070 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 000480 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 039130 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 033660 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.10/2022.10_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.11/2022.11_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.12/2022.12_033660.csv 파일을 찾을 수 없습니다.\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "033660의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "033660의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "033660의 뉴스 데이터가 없습니다. 분석을 계속합니다.\n",
      "\n",
      "=== 195870 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 029460 분석 중... ===\n",
      "\n",
      "=== 264900 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "264900의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "264900의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 077500 분석 중... ===\n",
      "\n",
      "=== 267850 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "267850의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "267850의 fin_statement_info 정보를 확인할 수 없습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 092220 분석 중... ===\n",
      "\n",
      "=== 004370 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 001740 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 007810 분석 중... ===\n",
      "\n",
      "=== 008770 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 011420 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "011420의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "011420의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 025560 분석 중... ===\n",
      "\n",
      "=== 000990 분석 중... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 020000 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/020000/_020000_재무제표 ().csv'\n",
      "020000의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "020000의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "\n",
      "=== 023800 분석 중... ===\n",
      "\n",
      "=== 003160 분석 중... ===\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/003160/_003160_재무제표 ().csv'\n",
      "003160의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "003160의 fin_statement_info 정보를 확인할 수 없습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/7hr2z6vd3fb6nbtgn0gwlm840000gn/T/ipykernel_36759/528922390.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corp_news_df['SA_result'] = corp_news_df['news_title'].apply(lambda x:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_file_path = \"/Users/gamjawon/finTF/pipeline/notion_page_ids.json\"\n",
    "\n",
    "# JSON 파일 읽기 함수\n",
    "def read_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "    \n",
    "# JSON 파일 수정\n",
    "def write_json(file_path, new_data):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(new_data, file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "# 'pf_selection_agent' 섹션에서 종목 코드 추출\n",
    "def get_tickers_from_json(agent_type, title):\n",
    "   data = read_json(json_file_path)\n",
    "   if agent_type in data and title in data[agent_type]:\n",
    "       page_id = data[agent_type][title]\n",
    "       content = get_all_text_from_page(page_id)\n",
    "       \n",
    "       try:\n",
    "           # final_portfolio 부분 추출\n",
    "           start = content.find(\"'final_portfolio'\")\n",
    "           end = content.find(\"'corp_analysis_report'\")\n",
    "           portfolio_str = content[start:end].strip()\n",
    "           \n",
    "           # 종목코드만 추출\n",
    "           import re\n",
    "           tickers = re.findall(r\"'(\\d{6})'\", portfolio_str)\n",
    "           return list(set(tickers))  # 중복 제거\n",
    "           \n",
    "       except Exception as e:\n",
    "           print(f\"Error: {e}\")\n",
    "           return []\n",
    "   return []\n",
    "\n",
    "# 예시로 'pf_selection_agent'의 '2022_Q4_init_pf'에서 종목 코드 추출\n",
    "if __name__ == \"__main__\":\n",
    "    # 'pf_selection_agent'에서 '2022_Q4_init_pf' 종목 코드 가져오기\n",
    "    tickers = get_tickers_from_json('pf_selection_agent', '2022_Q4_init_pf')\n",
    "\n",
    "    # 연도 및 분기 설정\n",
    "    year = \"2022\"\n",
    "    quarter = \"Q4\"\n",
    "\n",
    "    # 분석기 객체 생성\n",
    "    analyzer = InvestmentReportGenerator(tickers, year, quarter)\n",
    "\n",
    "    # 분석 실행\n",
    "    analyzer.analyze_stocks()\n",
    "    \n",
    "    # 개별 보고서 생성 \n",
    "    for ticker in tickers:\n",
    "        analyzer.generate_individual_report(ticker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_Q4_analyst_rp 보고서를 노션 DB에 저장합니다...\n",
      "페이지 생성 완료: 184cd049-9633-8185-81a8-cde6fce94a1e\n",
      "텍스트 블럭 추가 완료\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 최종 보고서 생성\n",
    "    final_report = analyzer.generate_final_report()\n",
    "\n",
    "    # 노션에 저장\n",
    "    analyzer.save_final_report(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-AsrWPJxxuhuvJkaEOjQapgojtmKw8', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': '# 최종 투자전략 보고서\\n\\n## 1. 거시경제 분석 요약\\n\\n### 글로벌 동향 핵심 포인트\\n- 금융업과 증권업 전반에서 주가 상승세가 뚜렷하며, 디지털화 및 기술 혁신이 진행되고 있음.\\n- 미국 연준의 금리 인상 지속 여부와 글로벌 경제 불확실성이 주요 투자 변수로 작용하고 있음.\\n- 산업 전반에서 ESG(환경, 사회, 지배구조) 경영에 대한 관심이 높아지고 있으며, 지속 가능한 성장 가능성이 주목받고 있음.\\n\\n### 주요 리스크 요인\\n- 글로벌 경제 둔화 및 인플레이션 지속 가능성.\\n- 금융 시장의 변동성이 클 경우, 투자자의 심리에 부정적인 영향을 미칠 수 있음.\\n- 각국의 규제 변화에 따른 사업 운영의 불확실성.\\n\\n## 2. 개별 종목 분석 종합\\n\\n### 각 종목 투자매력도 비교\\n| 종목 코드 | 회사명 | PER | PBR | ROE | 이익 성장률 | 목표가 | 투자포인트 |\\n|-----------|--------|-----|-----|-----|-------------|--------|------------|\\n| 093050    | A사    | 2.62| 0.28| 10.70%| 30.22%     | 20,000 | 재무 건전성, 성장성 |\\n| 035720    | B사    | 7.44| 1.06| 14.25%| -          | 65,000 | 클라우드 성장성 |\\n| 031430    | C사    | 7.44| 1.06| 14.25%| 43.77%     | 30,000 | 저평가 상태 |\\n| 011070    | D사    | 6.10| 1.40| 22.97%| 10.31%     | 300,000| 안정적 성장 |\\n| 000480    | E사    | 0.61| 0.037| - | 48.45%     | 10,000 | 저평가 상태 |\\n| 039130    | F사    | -15.03| 9.73| -64.77%| -8.34%     | 70,000 | 회복 가능성 |\\n| 033660    | G사    | 0.000003823| 0.000001363| 35.64%| 124.34% | 50,000 | 높은 수익성 |\\n| 029460    | H사    | 1.95| 0.29| 15.03%| 86.36%     | 20,000 | 저평가 상태 |\\n| 264900    | I사    | 1.01| 0.087| 8.59%| 7.12%     | 10,000 | 안정적 수익성 |\\n| 077500    | J사    | 2.56| 0.32| 12.67%| -27.01%    | 5,000  | 저평가 상태 |\\n\\n### 상대가치 평가\\n- **저평가 종목**: 000480, 029460, 264900, H사 등은 PER 및 PBR 수치가 낮아 추가적인 상승 여력이 크다.\\n- **고수익 종목**: 033660은 높은 ROE와 이익 성장률로 인해 매력적인 투자처로 평가됨.\\n\\n## 3. 최종 포트폴리오 전략\\n\\n### 종목별 투자비중 추천과 근거\\n1. **093050 (20%)**: 안정적인 재무 구조와 높은 성장성 보유.\\n2. **035720 (15%)**: 클라우드 및 AI 시장 성장으로 인한 장기적 성장 가능성.\\n3. **031430 (10%)**: 저평가 상태로 매수 기회.\\n4. **011070 (15%)**: 안정적인 성장세와 저평가된 주가.\\n5. **000480 (10%)**: 저평가 상태로 반등 가능성.\\n6. **039130 (5%)**: 회복 가능성을 고려한 소액 투자.\\n7. **033660 (10%)**: 높은 수익성과 성장성.\\n8. **029460 (5%)**: 저평가된 주식으로 매수 기회.\\n9. **264900 (5%)**: 안정적인 수익성 기반.\\n10. **077500 (5%)**: 저평가 상태로 소액 투자.\\n\\n### 위험관리 방안\\n- 포트폴리오 분산 투자로 특정 종목에 대한 리스크를 최소화.\\n- 시장 변동성에 따라 정기적으로 포트폴리오 리밸런싱.\\n- 각 종목의 성과를 지속적으로 모니터링하여 필요시 매도 대응.\\n\\n## 4. 핵심 결론\\n\\n### 최우선 투자 추천 종목\\n- **093050**: 안정성과 높은 성장성을 가진 종목으로 우선 투자 추천.\\n\\n### 중점 모니터링 요소\\n- 금리 인상 및 글로벌 경제 동향에 따른 시장 변동성.\\n- 각종 규제 변화 및 경쟁 업종의 동향.\\n- 주요 종목의 실적 발표 및 시장 반응. \\n\\n--- \\n\\n이 보고서는 종합적인 데이터 분석을 기반으로 작성되었으며, 투자자들은 시장 변화에 따라 신중한 접근을 권장합니다.', 'refusal': None, 'role': 'assistant'}}], 'created': 1737638813, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_72ed7ab54c', 'usage': {'completion_tokens': 1195, 'prompt_tokens': 22029, 'total_tokens': 23224, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}\n"
     ]
    }
   ],
   "source": [
    "print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioManagerReportGenerator:\n",
    "    def __init__(self, tickers: list, year: str, quarter: str):\n",
    "        self.tickers = tickers\n",
    "        self.year = year\n",
    "        self.quarter = quarter\n",
    "        self.prompts = self._initialize_prompts()\n",
    "        self.responses = {}\n",
    "        self.report_data = {}\n",
    "        self.analyst_report = None\n",
    "        self.current_portfolio = None\n",
    "        self.individual_reports = {}\n",
    "        \n",
    "    def _initialize_prompts(self) -> Dict[str, str]:\n",
    "        return {\n",
    "            \"individual_portfolio_system\": \"\"\"당신은 자산운용사의 포트폴리오 매니저입니다.\n",
    "해당 종목에 대한 애널리스트 리서치 보고서를 검토하여 포트폴리오 운용 전략을 제시하세요.\n",
    "\n",
    "# 1. 종목 현황\n",
    "- 현재 비중과 추이\n",
    "- 주요 위험/수익 지표\n",
    "- 투자 성과 분석\n",
    "\n",
    "# 2. 투자 전략\n",
    "- 적정 비중과 근거\n",
    "- 핵심 매력도/리스크\n",
    "- 비중 조정 방향\n",
    "\n",
    "# 3. 리스크 관리\n",
    "- 손절/이익실현 기준\n",
    "- 주요 모니터링 지표\n",
    "\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "\n",
    "            \"final_portfolio_system\": \"\"\"당신은 자산운용사의 수석 포트폴리오 매니저입니다.\n",
    "개별 종목 포트폴리오 보고서들을 종합하여 전체 포트폴리오 최종 운용 전략을 제시하세요.\n",
    "\n",
    "# 1. 포트폴리오 종합 현황\n",
    "- 전체 구성과 섹터 비중\n",
    "- 종목별 성과 비교\n",
    "- 핵심 위험/수익 특성\n",
    "\n",
    "# 2. 전략적 자산배분\n",
    "- 섹터별 비중 전략\n",
    "- 종목간 상대매력도\n",
    "- 전체 위험분산 방안\n",
    "\n",
    "# 3. 최종 포트폴리오 조정안\n",
    "- 종목별 비중 조정 방향\n",
    "- 편입/편출 검토\n",
    "- 우선순위와 실행계획\n",
    "\n",
    "# 4. 종합 리스크 관리\n",
    "- 포트폴리오 전체 관점\n",
    "- 개별종목 리스크 통합 관리\n",
    "- 주요 모니터링 지표\n",
    "\n",
    "작성 지침:\n",
    "- 개별 보고서들의 분석을 통합하여 결론 도출\n",
    "- 종목간 상대가치 고려한 전략 수립\n",
    "- 구체적 실행방안 제시\n",
    "\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "            \"individual_portfolio_prompt\": \"\",\n",
    "            \"final_portfolio_prompt\": \"\"\n",
    "        }\n",
    "        \n",
    "    def generate_individual_report(self, ticker: str, analyst_report: str, portfolio: Dict) -> str:\n",
    "        \"\"\"개별 종목 포트폴리오 보고서 생성\"\"\"\n",
    "        prompt = f\"종목코드: {ticker}\\n\"\n",
    "        prompt += f\"현재 포트폴리오 구성: {portfolio}\\n\"\n",
    "        prompt += f\"애널리스트 보고서: {analyst_report}\"\n",
    "        \n",
    "        response = to_GPT(self.prompts[\"individual_portfolio_system\"], prompt)\n",
    "        self.individual_reports[ticker] = response\n",
    "        return response\n",
    "        \n",
    "    def set_analyst_report(self, report: str) -> None:\n",
    "        \"\"\"애널리스트 보고서 설정\"\"\"\n",
    "        self.analyst_report = report\n",
    "        \n",
    "    def set_current_portfolio(self, portfolio: Dict) -> None:\n",
    "        \"\"\"현재 포트폴리오 설정\"\"\"\n",
    "        self.current_portfolio = portfolio\n",
    "        \n",
    "    def generate_final_report(self) -> str:\n",
    "        \"\"\"최종 포트폴리오 매니저 보고서 생성\"\"\"\n",
    "        if not self.individual_reports:\n",
    "            raise ValueError(\"Individual reports must be generated first\")\n",
    "        \n",
    "        combined_prompt = []\n",
    "        for ticker in self.tickers:\n",
    "            if ticker in self.individual_reports:\n",
    "                combined_prompt.append(f\"\\n=== {ticker} 포트폴리오 보고서 ===\")\n",
    "                combined_prompt.append(self._get_response_content(self.individual_reports[ticker]))\n",
    "        \n",
    "        self.prompts[\"final_portfolio_prompt\"] = \"\\n\".join(combined_prompt)\n",
    "        final_response = to_GPT(self.prompts[\"final_portfolio_system\"], \n",
    "                              self.prompts[\"final_portfolio_prompt\"])\n",
    "        return final_response\n",
    "    \n",
    "    def _get_response_content(self, response: Dict) -> str:\n",
    "        \"\"\"GPT 응답에서 content 추출\"\"\"\n",
    "        try:\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"\"\n",
    "        \n",
    "    def save_final_report(self, final_response: Dict) -> None:\n",
    "        \"\"\"최종 포트폴리오 매니저 보고서 저장\"\"\"\n",
    "        page_title = f\"{self.year}_{self.quarter}_final_portfolio_report\"\n",
    "        content = self._get_response_content(final_response)\n",
    "        \n",
    "        print(f\"{page_title} 보고서를 노션 DB에 저장합니다...\")\n",
    "        to_DB('t_1', page_title, f\"{self.quarter}_{self.year}\", content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_portfolio():\n",
    "    data = read_json(json_file_path)\n",
    "    agent_type = 'pf_selection_agent'\n",
    "    title = '2022_Q4_init_pf'\n",
    "    # 특정 agent_type과 title에 해당하는 종목 코드 추출\n",
    "    if agent_type in data and title in data[agent_type]:\n",
    "        portfolio = data[agent_type][title]\n",
    "        return portfolio\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "093050 포폴 매니저 보고서 추출 완료\n",
      "035720 포폴 매니저 보고서 추출 완료\n",
      "031430 포폴 매니저 보고서 추출 완료\n",
      "011070 포폴 매니저 보고서 추출 완료\n",
      "000480 포폴 매니저 보고서 추출 완료\n",
      "039130 포폴 매니저 보고서 추출 완료\n",
      "033660 포폴 매니저 보고서 추출 완료\n",
      "195870 포폴 매니저 보고서 추출 완료\n",
      "029460 포폴 매니저 보고서 추출 완료\n",
      "264900 포폴 매니저 보고서 추출 완료\n",
      "077500 포폴 매니저 보고서 추출 완료\n",
      "267850 포폴 매니저 보고서 추출 완료\n",
      "092220 포폴 매니저 보고서 추출 완료\n",
      "004370 포폴 매니저 보고서 추출 완료\n",
      "001740 포폴 매니저 보고서 추출 완료\n",
      "007810 포폴 매니저 보고서 추출 완료\n",
      "008770 포폴 매니저 보고서 추출 완료\n",
      "011420 포폴 매니저 보고서 추출 완료\n",
      "025560 포폴 매니저 보고서 추출 완료\n",
      "000990 포폴 매니저 보고서 추출 완료\n",
      "020000 포폴 매니저 보고서 추출 완료\n",
      "023800 포폴 매니저 보고서 추출 완료\n",
      "003160 포폴 매니저 보고서 추출 완료\n",
      "\n",
      "=== 포트폴리오 매니저 종합 보고서 ===\n",
      "# 포트폴리오 최종 운용 전략 보고서\n",
      "\n",
      "## 1. 포트폴리오 종합 현황\n",
      "### 전체 구성과 섹터 비중\n",
      "현재 포트폴리오는 다양한 종목으로 구성되어 있으며, 각 종목의 비중은 다음과 같습니다:\n",
      "- **종목 1 (093050)**: 5%\n",
      "- **종목 2 (035720)**: 5%\n",
      "- **종목 3 (031430)**: 5%\n",
      "- **종목 4 (011070)**: 5%\n",
      "- **종목 5 (000480)**: 5%\n",
      "- **종목 6 (039130)**: 5%\n",
      "- **종목 7 (033660)**: 5%\n",
      "- **종목 8 (195870)**: 5%\n",
      "- **종목 9 (029460)**: 5%\n",
      "- **종목 10 (264900)**: 5%\n",
      "- **종목 11 (077500)**: 5%\n",
      "- **종목 12 (267850)**: 5%\n",
      "- **종목 13 (092220)**: 5%\n",
      "- **종목 14 (004370)**: 5%\n",
      "- **종목 15 (001740)**: 5%\n",
      "- **종목 16 (007810)**: 5%\n",
      "- **종목 17 (008770)**: 5%\n",
      "- **종목 18 (011420)**: 5%\n",
      "- **종목 19 (025560)**: 5%\n",
      "- **종목 20 (000990)**: 5%\n",
      "- **종목 21 (020000)**: 5%\n",
      "- **종목 22 (023800)**: 5%\n",
      "- **종목 23 (003160)**: 5%\n",
      "\n",
      "### 종목별 성과 비교\n",
      "- **핵심 종목 성과**: \n",
      "  - 093050: 15% 수익률\n",
      "  - 035720: -10% 수익률\n",
      "  - 011070: 20% 수익률\n",
      "  - 000480: 정보 부족\n",
      "  - 195870: 정보 부족\n",
      "  - 267850: 정보 부족\n",
      "  - 092220: 정보 부족\n",
      "\n",
      "### 핵심 위험/수익 특성\n",
      "- **변동성**: 고변동성 종목은 093050 (베타 1.2), 035720 (변동성 25%) 등의 종목이 있으며, 이들은 시장의 변동에 민감함.\n",
      "- **수익성**: 안정적인 수익을 보이는 종목은 011070, 267850 등이 있음.\n",
      "\n",
      "## 2. 전략적 자산배분\n",
      "### 섹터별 비중 전략\n",
      "- **기술주**: 30%\n",
      "- **소비재**: 20%\n",
      "- **금융**: 15%\n",
      "- **헬스케어**: 10%\n",
      "- **산업재**: 10%\n",
      "- **기타**: 15%\n",
      "\n",
      "### 종목간 상대매력도\n",
      "- **상대매력 높은 종목**: 011070, 267850\n",
      "- **상대매력 낮은 종목**: 035720, 195870\n",
      "\n",
      "### 전체 위험분산 방안\n",
      "- **고변동성 종목 비중 조정**: 093050, 035720의 비중을 시장 상황에 따라 조정하여 포트폴리오의 전반적인 변동성을 낮출 필요 있음.\n",
      "  \n",
      "## 3. 최종 포트폴리오 조정안\n",
      "### 종목별 비중 조정 방향\n",
      "- **종목 093050**: 비중 5% → 8%로 확대 (긍정적인 성장세)\n",
      "- **종목 035720**: 비중 5% → 3%로 축소 (부정적 실적)\n",
      "- **종목 011070**: 비중 5% → 7%로 확대 (안정적인 성장)\n",
      "- **종목 267850**: 비중 5% → 7%로 확대 (성장 가능성)\n",
      "\n",
      "### 편입/편출 검토\n",
      "- **편입**: 신규 종목 001740와 000990의 5% 비중으로 편입.\n",
      "- **편출**: 성과 부진 종목인 035720을 축소하며, 성과가 부진한 다른 종목도 검토.\n",
      "\n",
      "### 우선순위와 실행계획\n",
      "- **우선순위**: 고성장 종목 비중 확대.\n",
      "- **실행계획**: 1개월 내 신규 비중 조정 실시 후, 3개월 후 성과 평가.\n",
      "\n",
      "## 4. 종합 리스크 관리\n",
      "### 포트폴리오 전체 관점\n",
      "- **리스크 관리 방안**: 고변동성 종목에 대한 손절 및 이익 실현 기준 설정.\n",
      "\n",
      "### 개별종목 리스크 통합 관리\n",
      "- **종목별 손절 기준**: 대부분의 종목에 대해 10% 손실 시 손절.\n",
      "\n",
      "### 주요 모니터링 지표\n",
      "- **주가 변동성**: 주간 및 월간 변동성 체크.\n",
      "- **실적 발표**: 분기별 실적 발표 후 주가 반응 모니터링.\n",
      "- **뉴스 및 외부 경제 지표**: 금리, 환율 등 경제 지표에 대한 지속적인 모니터링.\n",
      "\n",
      "---\n",
      "\n",
      "위의 전략을 기반으로 포트폴리오를 운영하며, 지속적인 시장 동향 및 성과 모니터링을 통해 유연하게 대응할 계획입니다. 추가적인 데이터와 분석을 바탕으로 전략을 조정할 필요가 있습니다.\n",
      "=== 보고서 끝 ===\n",
      "2022_Q4_final_portfolio_report 보고서를 노션 DB에 저장합니다...\n",
      "페이지 생성 완료: 184cd049-9633-817f-8b49-e345956669e8\n",
      "텍스트 블럭 추가 완료\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "# 2. 종합 포트폴리오 매니저 보고서 생성\n",
    "    # 티커는 대표 종목으로 설정하거나 \"MULTI\"와 같은 식별자 사용\n",
    "    portfolio_manager = PortfolioManagerReportGenerator(tickers, year, quarter)\n",
    "    \n",
    "    # 각 종목별 포트폴리오 보고서 생성\n",
    "    for ticker in tickers:\n",
    "        analyst_report = portfolio_manager.set_analyst_report(final_report[\"choices\"][0][\"message\"][\"content\"])# 애널리스트 보고서 가져오기\n",
    "        current_portfolio = portfolio_manager.set_current_portfolio(get_current_portfolio())# 현재 포트폴리오 정보 가져오기\n",
    "        portfolio_manager.generate_individual_report(ticker, analyst_report, current_portfolio)\n",
    "        print(f\"{ticker} 포폴 매니저 보고서 추출 완료\")\n",
    "        \n",
    "    # 보고서 생성\n",
    "    portfolio_report = portfolio_manager.generate_final_report()\n",
    "    \n",
    "    # 보고서 출력\n",
    "    print(\"\\n=== 포트폴리오 매니저 종합 보고서 ===\")\n",
    "    print(portfolio_report[\"choices\"][0][\"message\"][\"content\"])\n",
    "    print(\"=== 보고서 끝 ===\")\n",
    "    \n",
    "    # 선택적으로 노션에 저장\n",
    "    portfolio_manager.save_final_report(portfolio_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraderReportGenerator:\n",
    "    def __init__(self, tickers: list, year: str, quarter: str):\n",
    "        self.tickers = tickers\n",
    "        self.year = year\n",
    "        self.quarter = quarter\n",
    "        self.prompts = self._initialize_prompts()\n",
    "        self.individual_reports = {}\n",
    "        self.responses = {ticker: {} for ticker in tickers}\n",
    "        self.report_data = {}\n",
    "        self.start_date, self.end_date = self._get_date_range()\n",
    "        self.price_data = {}\n",
    "        self.analyst_reports = {}\n",
    "        self.pm_reports = {}\n",
    "        self.price_predictions = {}\n",
    "        \n",
    "    def _initialize_prompts(self) -> Dict[str, str]:\n",
    "        \"\"\"프롬프트 초기화\"\"\"\n",
    "        return {\n",
    "            \"individual_trader_system\": \"\"\"당신은 증권사의 트레이더입니다. 해당 종목의 데이터와 보고서를 분석하여 구체적인 매매 전략을 제시하세요.\n",
    "\n",
    "# 종목 기본 분석\n",
    "- 현재가 동향과 기술적 신호\n",
    "- 예측가격 분석\n",
    "- 거래량 특징\n",
    "\n",
    "# 매매 전략\n",
    "- 매매 방향과 근거\n",
    "- 진입/청산 가격대\n",
    "- 리스크 관리 전략\n",
    "\n",
    "모든 분석은 제공된 데이터에 기반하여 작성하세요.\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "\n",
    "            \"final_trader_system\": \"\"\"당신은 증권사의 수석 트레이더입니다. 개별 종목 트레이딩 보고서들을 종합하여 최종 매매 전략을 제시하세요.\n",
    "\n",
    "# 시장 종합 분석\n",
    "- 주요 매매 환경\n",
    "- 전반적 매매 전략\n",
    "\n",
    "# 우선 매매 종목\n",
    "- 상위 5-7개 종목 선정과 근거\n",
    "- 구체적 매매 전략\n",
    "- 핵심 리스크 관리\n",
    "\n",
    "# 기타 종목 전략\n",
    "- 실제 매수/매도 대상 종목 분석\n",
    "- 종목별 구체적 진입/청산 전략\n",
    "- 종목별 리스크 관리 방안\n",
    "\n",
    "작성 지침:\n",
    "- 개별 보고서 분석 통합\n",
    "- 우선순위 기반 전략 수립\n",
    "- 구체적 실행 방안 제시\n",
    "- 가정이나 예시가 아닌 실제 종목과 데이터 기반 분석 필수\n",
    "- 각 종목별 현재 시장 상황과 기업 실적 반영\n",
    "\n",
    "응답은 markdown 형식으로 작성\"\"\",\n",
    "            \"individual_trader_prompt\": \"\",\n",
    "            \"final_trader_prompt\": \"\"\n",
    "        }\n",
    "\n",
    "    def _get_date_range(self) -> tuple:\n",
    "        \"\"\"분기에 해당하는 시작일과 종료일 반환\"\"\"\n",
    "        quarter_months = {\n",
    "            'Q1': ('01', '03'),\n",
    "            'Q2': ('04', '06'),\n",
    "            'Q3': ('07', '09'),\n",
    "            'Q4': ('10', '12')\n",
    "        }\n",
    "        \n",
    "        if self.quarter in quarter_months:\n",
    "            start_month, end_month = quarter_months[self.quarter]\n",
    "            start_date = f\"{self.year}{start_month}01\"\n",
    "            end_date = f\"{self.year}{end_month}{'30' if end_month in ['06', '09'] else '31'}\"\n",
    "            return start_date, end_date\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid quarter: {self.quarter}\")\n",
    "\n",
    "    def set_price_data(self) -> None:\n",
    "        \"\"\"주가 데이터 설정\"\"\"\n",
    "        try:\n",
    "            for ticker in self.tickers:\n",
    "                self.price_data[ticker] = stock_price_info(ticker, self.start_date, self.end_date)\n",
    "        except Exception as e:\n",
    "            print(f\"가격 데이터 설정 중 오류 발생: {str(e)}\")\n",
    "\n",
    "\n",
    "    def set_analyst_report(self, report: str) -> None:\n",
    "        \"\"\"애널리스트 보고서 설정\"\"\"\n",
    "        self.analyst_report = report\n",
    "\n",
    "    def set_pm_report(self, report: str) -> None:\n",
    "        \"\"\"포트폴리오 매니저 보고서 설정\"\"\"\n",
    "        self.pm_report = report\n",
    "\n",
    "    def get_price_prediction(self) -> None:\n",
    "        \"\"\"GRU 모델을 사용한 가격 예측\"\"\"\n",
    "        try:\n",
    "            self.price_predictions = predict_multiple_prices(\n",
    "                self.tickers,\n",
    "                self.start_date,\n",
    "                self.end_date\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"가격 예측 모델 실행 중 오류 발생: {str(e)}\")\n",
    "    \n",
    "    def generate_individual_report(self, ticker: str) -> str:\n",
    "        \"\"\"개별 종목 트레이더 보고서 생성\"\"\"\n",
    "        price_data = self.price_data.get(ticker, {})\n",
    "        if hasattr(price_data, 'to_dict'):\n",
    "            price_data = price_data.to_dict()\n",
    "            \n",
    "        prompt = f\"종목코드: {ticker}\\n\"\n",
    "        prompt += f\"가격 데이터: {price_data}\\n\"\n",
    "        prompt += f\"가격 예측: {self.price_predictions.get(ticker, {})}\\n\"\n",
    "        prompt += f\"애널리스트 보고서: {self.analyst_reports.get(ticker, '정보 없음')}\\n\"\n",
    "        prompt += f\"PM 보고서: {self.pm_reports.get(ticker, '정보 없음')}\"\n",
    "\n",
    "        response = to_GPT(self.prompts[\"individual_trader_system\"], prompt)\n",
    "        self.individual_reports[ticker] = response\n",
    "        return response\n",
    "\n",
    "    def generate_final_report(self) -> str:\n",
    "        \"\"\"최종 트레이더 보고서 생성\"\"\"\n",
    "        if not self.individual_reports:\n",
    "            raise ValueError(\"Individual reports must be generated first\")\n",
    "        \n",
    "        combined_prompt = []\n",
    "        for ticker in self.tickers:\n",
    "            if ticker in self.individual_reports:\n",
    "                combined_prompt.append(f\"\\n=== {ticker} 트레이딩 보고서 ===\")\n",
    "                combined_prompt.append(self._get_response_content(self.individual_reports[ticker]))\n",
    "        \n",
    "        self.prompts[\"final_trader_prompt\"] = \"\\n\".join(combined_prompt)\n",
    "        final_response = to_GPT(self.prompts[\"final_trader_system\"], \n",
    "                              self.prompts[\"final_trader_prompt\"])\n",
    "        return final_response\n",
    "    \n",
    "    def _get_response_content(self, response: Dict) -> str:\n",
    "        try:\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"\"\n",
    "\n",
    "    def save_final_report(self, final_response: Dict) -> None:\n",
    "        page_title = f\"{self.year}_{self.quarter}_final_trader_report\"\n",
    "        content = self._get_response_content(final_response)\n",
    "        \n",
    "        print(f\"{page_title} 보고서를 노션 DB에 저장합니다...\")\n",
    "        to_DB('t_1', page_title, f\"{self.quarter}_{self.year}\", content)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.04444444444444429 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1394 - mae: 0.4435 - val_loss: 0.2124 - val_mae: 0.6457 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0912 - mae: 0.3598 - val_loss: 0.1582 - val_mae: 0.5559 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0659 - mae: 0.3007 - val_loss: 0.1135 - val_mae: 0.4684 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0401 - mae: 0.2387 - val_loss: 0.0819 - val_mae: 0.3948 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0295 - mae: 0.2068 - val_loss: 0.0562 - val_mae: 0.3231 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0245 - mae: 0.1847 - val_loss: 0.0374 - val_mae: 0.2579 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0247 - mae: 0.1843 - val_loss: 0.0255 - val_mae: 0.2064 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0209 - mae: 0.1626 - val_loss: 0.0193 - val_mae: 0.1774 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0204 - mae: 0.1564 - val_loss: 0.0168 - val_mae: 0.1646 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0207 - mae: 0.1517 - val_loss: 0.0169 - val_mae: 0.1648 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0157 - mae: 0.1348 - val_loss: 0.0180 - val_mae: 0.1692 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0128 - mae: 0.1225 - val_loss: 0.0196 - val_mae: 0.1760 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0166 - mae: 0.1410 - val_loss: 0.0223 - val_mae: 0.1904 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0122 - mae: 0.1280 - val_loss: 0.0233 - val_mae: 0.1960 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.1237 - val_loss: 0.0223 - val_mae: 0.1905 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0116 - mae: 0.1241 - val_loss: 0.0198 - val_mae: 0.1767 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0123 - mae: 0.1219 - val_loss: 0.0172 - val_mae: 0.1628 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.1121 - val_loss: 0.0145 - val_mae: 0.1485 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0113 - mae: 0.1137 - val_loss: 0.0126 - val_mae: 0.1375 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0102 - mae: 0.1061 - val_loss: 0.0110 - val_mae: 0.1269 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0115 - mae: 0.1125 - val_loss: 0.0102 - val_mae: 0.1212 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0105 - mae: 0.1063 - val_loss: 0.0094 - val_mae: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0109 - mae: 0.1071 - val_loss: 0.0087 - val_mae: 0.1116 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0112 - mae: 0.1112 - val_loss: 0.0082 - val_mae: 0.1080 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0107 - mae: 0.1067 - val_loss: 0.0079 - val_mae: 0.1061 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0082 - mae: 0.0924 - val_loss: 0.0079 - val_mae: 0.1055 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0082 - mae: 0.0949 - val_loss: 0.0078 - val_mae: 0.1045 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0872 - val_loss: 0.0075 - val_mae: 0.1025 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.1050 - val_loss: 0.0077 - val_mae: 0.1036 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0088 - mae: 0.0953 - val_loss: 0.0077 - val_mae: 0.1041 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0082 - mae: 0.0910 - val_loss: 0.0075 - val_mae: 0.1025 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0089 - mae: 0.0976 - val_loss: 0.0071 - val_mae: 0.0987 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0088 - mae: 0.0958 - val_loss: 0.0065 - val_mae: 0.0941 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0078 - mae: 0.0887 - val_loss: 0.0060 - val_mae: 0.0891 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0055 - val_mae: 0.0838 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0080 - mae: 0.0891 - val_loss: 0.0053 - val_mae: 0.0823 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0052 - val_mae: 0.0820 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0064 - mae: 0.0824 - val_loss: 0.0053 - val_mae: 0.0825 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0083 - mae: 0.0927 - val_loss: 0.0054 - val_mae: 0.0840 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0054 - val_mae: 0.0848 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0082 - mae: 0.0923 - val_loss: 0.0054 - val_mae: 0.0855 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0054 - val_mae: 0.0860 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0062 - mae: 0.0819 - val_loss: 0.0055 - val_mae: 0.0865 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0056 - val_mae: 0.0876 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0065 - mae: 0.0866 - val_loss: 0.0058 - val_mae: 0.0892 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0064 - mae: 0.0810 - val_loss: 0.0060 - val_mae: 0.0906 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0072 - mae: 0.0865 - val_loss: 0.0060 - val_mae: 0.0903 - learning_rate: 1.2500e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "검증 세트 MSE: 0.01004490810520289\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/035720/_035720_재무제표 ().csv'\n",
      "035720의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "035720의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.03389830508474567 ~ 1.0\n",
      "035720 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 0.8571428571428577\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.2998 - mae: 0.7408 - val_loss: 0.2031 - val_mae: 0.6287 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2253 - mae: 0.6302 - val_loss: 0.1749 - val_mae: 0.5823 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1650 - mae: 0.5186 - val_loss: 0.1536 - val_mae: 0.5443 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1173 - mae: 0.4200 - val_loss: 0.1333 - val_mae: 0.5057 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0921 - mae: 0.3415 - val_loss: 0.1150 - val_mae: 0.4679 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0844 - mae: 0.3181 - val_loss: 0.1038 - val_mae: 0.4433 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0686 - mae: 0.2722 - val_loss: 0.0943 - val_mae: 0.4210 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0453 - mae: 0.2188 - val_loss: 0.0843 - val_mae: 0.3966 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0539 - mae: 0.2460 - val_loss: 0.0743 - val_mae: 0.3705 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0395 - mae: 0.2076 - val_loss: 0.0656 - val_mae: 0.3461 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0339 - mae: 0.1963 - val_loss: 0.0576 - val_mae: 0.3223 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0319 - mae: 0.2004 - val_loss: 0.0501 - val_mae: 0.2980 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0295 - mae: 0.1973 - val_loss: 0.0434 - val_mae: 0.2743 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0330 - mae: 0.2092 - val_loss: 0.0379 - val_mae: 0.2534 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0296 - mae: 0.2052 - val_loss: 0.0347 - val_mae: 0.2403 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0300 - mae: 0.2061 - val_loss: 0.0326 - val_mae: 0.2311 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0284 - mae: 0.1993 - val_loss: 0.0309 - val_mae: 0.2238 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0274 - mae: 0.1940 - val_loss: 0.0299 - val_mae: 0.2188 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0248 - mae: 0.1820 - val_loss: 0.0287 - val_mae: 0.2132 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0259 - mae: 0.1872 - val_loss: 0.0272 - val_mae: 0.2060 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0200 - mae: 0.1644 - val_loss: 0.0256 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0212 - mae: 0.1694 - val_loss: 0.0232 - val_mae: 0.1849 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0189 - mae: 0.1529 - val_loss: 0.0207 - val_mae: 0.1710 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0198 - mae: 0.1618 - val_loss: 0.0184 - val_mae: 0.1588 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0190 - mae: 0.1601 - val_loss: 0.0163 - val_mae: 0.1474 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0171 - mae: 0.1499 - val_loss: 0.0147 - val_mae: 0.1370 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0166 - mae: 0.1495 - val_loss: 0.0134 - val_mae: 0.1297 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0178 - mae: 0.1549 - val_loss: 0.0120 - val_mae: 0.1222 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0151 - mae: 0.1431 - val_loss: 0.0111 - val_mae: 0.1167 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0169 - mae: 0.1477 - val_loss: 0.0108 - val_mae: 0.1142 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0139 - mae: 0.1343 - val_loss: 0.0103 - val_mae: 0.1103 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0133 - mae: 0.1333 - val_loss: 0.0098 - val_mae: 0.1065 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1413 - val_loss: 0.0093 - val_mae: 0.1021 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0135 - mae: 0.1340 - val_loss: 0.0090 - val_mae: 0.0987 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0130 - mae: 0.1337 - val_loss: 0.0085 - val_mae: 0.0943 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0149 - mae: 0.1405 - val_loss: 0.0082 - val_mae: 0.0928 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0115 - mae: 0.1227 - val_loss: 0.0081 - val_mae: 0.0921 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0111 - mae: 0.1217 - val_loss: 0.0077 - val_mae: 0.0917 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0114 - mae: 0.1230 - val_loss: 0.0075 - val_mae: 0.0935 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0123 - mae: 0.1239 - val_loss: 0.0073 - val_mae: 0.0954 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0104 - mae: 0.1149 - val_loss: 0.0073 - val_mae: 0.0968 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0119 - mae: 0.1219 - val_loss: 0.0075 - val_mae: 0.0974 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0104 - mae: 0.1197 - val_loss: 0.0076 - val_mae: 0.0980 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.1156 - val_loss: 0.0075 - val_mae: 0.1012 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0104 - mae: 0.1156 - val_loss: 0.0075 - val_mae: 0.1030 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0110 - mae: 0.1149 - val_loss: 0.0076 - val_mae: 0.1028 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0120 - mae: 0.1225 - val_loss: 0.0076 - val_mae: 0.1025 - learning_rate: 5.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.1176 - val_loss: 0.0077 - val_mae: 0.1028 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0106 - mae: 0.1196 - val_loss: 0.0076 - val_mae: 0.1037 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0113 - mae: 0.1158 - val_loss: 0.0076 - val_mae: 0.1050 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "검증 세트 MSE: 0.01371148998737101\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0941 - mae: 0.4090 - val_loss: 0.0097 - val_mae: 0.1304 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0497 - mae: 0.2891 - val_loss: 0.0031 - val_mae: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0216 - mae: 0.1713 - val_loss: 0.0067 - val_mae: 0.0924 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0122 - mae: 0.1169 - val_loss: 0.0150 - val_mae: 0.1608 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.1381 - val_loss: 0.0186 - val_mae: 0.1816 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0181 - mae: 0.1595 - val_loss: 0.0157 - val_mae: 0.1635 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0154 - mae: 0.1414 - val_loss: 0.0117 - val_mae: 0.1352 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0107 - mae: 0.1130 - val_loss: 0.0101 - val_mae: 0.1210 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0104 - mae: 0.1023 - val_loss: 0.0088 - val_mae: 0.1091 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0970 - val_loss: 0.0082 - val_mae: 0.1025 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0082 - mae: 0.0880 - val_loss: 0.0079 - val_mae: 0.0987 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0088 - mae: 0.0881 - val_loss: 0.0077 - val_mae: 0.0961 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "검증 세트 MSE: 0.015739235794138648\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.2198 - mae: 0.5902 - val_loss: 0.4217 - val_mae: 0.8448 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1559 - mae: 0.4838 - val_loss: 0.3332 - val_mae: 0.7467 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1312 - mae: 0.4305 - val_loss: 0.2534 - val_mae: 0.6522 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0999 - mae: 0.3627 - val_loss: 0.1847 - val_mae: 0.5761 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0646 - mae: 0.2832 - val_loss: 0.1325 - val_mae: 0.5026 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0412 - mae: 0.2207 - val_loss: 0.0936 - val_mae: 0.4285 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0277 - mae: 0.1906 - val_loss: 0.0682 - val_mae: 0.3573 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0203 - mae: 0.1776 - val_loss: 0.0582 - val_mae: 0.3082 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0138 - mae: 0.1488 - val_loss: 0.0547 - val_mae: 0.2681 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0138 - mae: 0.1484 - val_loss: 0.0551 - val_mae: 0.2331 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0135 - mae: 0.1411 - val_loss: 0.0569 - val_mae: 0.2178 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - mae: 0.1402 - val_loss: 0.0577 - val_mae: 0.2148 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0129 - mae: 0.1312 - val_loss: 0.0573 - val_mae: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0129 - mae: 0.1331 - val_loss: 0.0561 - val_mae: 0.2159 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0147 - mae: 0.1462 - val_loss: 0.0552 - val_mae: 0.2177 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0125 - mae: 0.1344 - val_loss: 0.0544 - val_mae: 0.2211 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0130 - mae: 0.1368 - val_loss: 0.0536 - val_mae: 0.2256 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0105 - mae: 0.1242 - val_loss: 0.0531 - val_mae: 0.2297 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0125 - mae: 0.1373 - val_loss: 0.0527 - val_mae: 0.2335 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0101 - mae: 0.1222 - val_loss: 0.0524 - val_mae: 0.2367 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0109 - mae: 0.1274 - val_loss: 0.0523 - val_mae: 0.2377 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0097 - mae: 0.1191 - val_loss: 0.0522 - val_mae: 0.2374 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0107 - mae: 0.1265 - val_loss: 0.0521 - val_mae: 0.2370 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0107 - mae: 0.1260 - val_loss: 0.0521 - val_mae: 0.2353 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0112 - mae: 0.1315 - val_loss: 0.0521 - val_mae: 0.2325 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.1212 - val_loss: 0.0522 - val_mae: 0.2304 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0112 - mae: 0.1302 - val_loss: 0.0523 - val_mae: 0.2275 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0092 - mae: 0.1146 - val_loss: 0.0525 - val_mae: 0.2245 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0105 - mae: 0.1261 - val_loss: 0.0526 - val_mae: 0.2227 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0108 - mae: 0.1262 - val_loss: 0.0528 - val_mae: 0.2213 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0109 - mae: 0.1271 - val_loss: 0.0529 - val_mae: 0.2202 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0089 - mae: 0.1142 - val_loss: 0.0530 - val_mae: 0.2191 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.1238 - val_loss: 0.0531 - val_mae: 0.2186 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0095 - mae: 0.1198 - val_loss: 0.0530 - val_mae: 0.2187 - learning_rate: 1.2500e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "검증 세트 MSE: 0.13792634205759646\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0736 - mae: 0.3250 - val_loss: 0.2329 - val_mae: 0.6673 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0539 - mae: 0.2694 - val_loss: 0.1759 - val_mae: 0.5768 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0437 - mae: 0.2421 - val_loss: 0.1330 - val_mae: 0.4998 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0292 - mae: 0.1848 - val_loss: 0.0991 - val_mae: 0.4275 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0185 - mae: 0.1424 - val_loss: 0.0669 - val_mae: 0.3439 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0134 - mae: 0.1295 - val_loss: 0.0413 - val_mae: 0.2586 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.1065 - val_loss: 0.0253 - val_mae: 0.1868 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0079 - mae: 0.1040 - val_loss: 0.0176 - val_mae: 0.1582 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0088 - mae: 0.1115 - val_loss: 0.0151 - val_mae: 0.1469 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.1040 - val_loss: 0.0163 - val_mae: 0.1527 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0950 - val_loss: 0.0203 - val_mae: 0.1692 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0065 - mae: 0.0927 - val_loss: 0.0259 - val_mae: 0.1897 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0905 - val_loss: 0.0312 - val_mae: 0.2160 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0064 - mae: 0.0924 - val_loss: 0.0337 - val_mae: 0.2272 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0053 - mae: 0.0822 - val_loss: 0.0340 - val_mae: 0.2284 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0866 - val_loss: 0.0337 - val_mae: 0.2273 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0057 - mae: 0.0859 - val_loss: 0.0328 - val_mae: 0.2232 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0059 - mae: 0.0874 - val_loss: 0.0308 - val_mae: 0.2139 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0056 - mae: 0.0867 - val_loss: 0.0283 - val_mae: 0.2017 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "검증 세트 MSE: 0.037944239152246276\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.10/2022.10_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.11/2022.11_033660.csv 파일을 찾을 수 없습니다.\n",
      "/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/market_data/price/033660/2022.12/2022.12_033660.csv 파일을 찾을 수 없습니다.\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/033660/_033660_재무제표 ().csv'\n",
      "033660의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "033660의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 로드 실패: \"None of [Index(['TRD_DD', 'LIST_SHRS', 'FORN_HD_QTY', 'FORN_SHR_RT', 'FORN_ORD_LMT_QTY',\\n       'FORN_LMT_EXHST_RT'],\\n      dtype='object')] are in the [columns]\"\n",
      "[DEBUG] 최종 데이터 shape: (0, 5)\n",
      "[WARNING] PER이 모두 0입니다. 평균값으로 대체합니다.\n",
      "033660 예측 중 오류 발생: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by MinMaxScaler.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0000000000000004\n",
      "y_train 값 범위: 0.0 ~ 0.9424083769633507\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.2165 - mae: 0.6002 - val_loss: 0.0282 - val_mae: 0.2101 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1696 - mae: 0.5198 - val_loss: 0.0212 - val_mae: 0.1803 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1486 - mae: 0.4886 - val_loss: 0.0149 - val_mae: 0.1477 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1309 - mae: 0.4592 - val_loss: 0.0126 - val_mae: 0.1331 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1283 - mae: 0.4500 - val_loss: 0.0105 - val_mae: 0.1170 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1094 - mae: 0.4119 - val_loss: 0.0086 - val_mae: 0.1030 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1117 - mae: 0.4129 - val_loss: 0.0071 - val_mae: 0.0949 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0930 - mae: 0.3676 - val_loss: 0.0061 - val_mae: 0.0912 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0904 - mae: 0.3693 - val_loss: 0.0059 - val_mae: 0.0907 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0807 - mae: 0.3417 - val_loss: 0.0066 - val_mae: 0.0967 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0716 - mae: 0.3111 - val_loss: 0.0089 - val_mae: 0.1090 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0708 - mae: 0.3028 - val_loss: 0.0131 - val_mae: 0.1343 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0612 - mae: 0.2822 - val_loss: 0.0195 - val_mae: 0.1681 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0487 - mae: 0.2370 - val_loss: 0.0291 - val_mae: 0.2171 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0392 - mae: 0.2008 - val_loss: 0.0354 - val_mae: 0.2446 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0330 - mae: 0.1838 - val_loss: 0.0430 - val_mae: 0.2740 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0236 - mae: 0.1557 - val_loss: 0.0518 - val_mae: 0.3046 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0274 - mae: 0.1713 - val_loss: 0.0622 - val_mae: 0.3371 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0287 - mae: 0.1770 - val_loss: 0.0735 - val_mae: 0.3693 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "검증 세트 MSE: 0.011276468106452255\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.21176470588235308 ~ 0.9999999999999996\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.2231 - mae: 0.5983 - val_loss: 0.1873 - val_mae: 0.6092 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1915 - mae: 0.5458 - val_loss: 0.1426 - val_mae: 0.5302 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1497 - mae: 0.4613 - val_loss: 0.1021 - val_mae: 0.4463 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1088 - mae: 0.3762 - val_loss: 0.0647 - val_mae: 0.3513 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0796 - mae: 0.3120 - val_loss: 0.0326 - val_mae: 0.2440 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0558 - mae: 0.2744 - val_loss: 0.0110 - val_mae: 0.1297 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0349 - mae: 0.2217 - val_loss: 0.0023 - val_mae: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0270 - mae: 0.2059 - val_loss: 0.0082 - val_mae: 0.1154 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0238 - mae: 0.1893 - val_loss: 0.0209 - val_mae: 0.1944 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0258 - mae: 0.1899 - val_loss: 0.0286 - val_mae: 0.2316 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0277 - mae: 0.1939 - val_loss: 0.0268 - val_mae: 0.2245 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0235 - mae: 0.1723 - val_loss: 0.0202 - val_mae: 0.1935 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0198 - mae: 0.1647 - val_loss: 0.0160 - val_mae: 0.1708 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0158 - mae: 0.1446 - val_loss: 0.0122 - val_mae: 0.1469 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0155 - mae: 0.1454 - val_loss: 0.0091 - val_mae: 0.1243 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0140 - mae: 0.1421 - val_loss: 0.0071 - val_mae: 0.1075 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0135 - mae: 0.1422 - val_loss: 0.0056 - val_mae: 0.0937 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "검증 세트 MSE: 0.001876591381624578\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/264900'\n",
      "264900의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "264900의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.13821138211382067 ~ 1.0\n",
      "264900 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.2769230769230768 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1711 - mae: 0.5588 - val_loss: 0.1022 - val_mae: 0.4423 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1166 - mae: 0.4567 - val_loss: 0.0703 - val_mae: 0.3634 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0802 - mae: 0.3710 - val_loss: 0.0486 - val_mae: 0.2975 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0452 - mae: 0.2694 - val_loss: 0.0306 - val_mae: 0.2294 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0285 - mae: 0.1896 - val_loss: 0.0154 - val_mae: 0.1564 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0128 - mae: 0.1160 - val_loss: 0.0069 - val_mae: 0.0940 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0078 - mae: 0.0993 - val_loss: 0.0043 - val_mae: 0.0641 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0112 - mae: 0.1235 - val_loss: 0.0043 - val_mae: 0.0702 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0128 - mae: 0.1354 - val_loss: 0.0043 - val_mae: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0124 - mae: 0.1335 - val_loss: 0.0046 - val_mae: 0.0672 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0086 - mae: 0.1072 - val_loss: 0.0060 - val_mae: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.1044 - val_loss: 0.0078 - val_mae: 0.1036 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0074 - mae: 0.0909 - val_loss: 0.0086 - val_mae: 0.1106 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0899 - val_loss: 0.0091 - val_mae: 0.1145 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0068 - mae: 0.0870 - val_loss: 0.0093 - val_mae: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0080 - mae: 0.0949 - val_loss: 0.0093 - val_mae: 0.1166 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0091 - val_mae: 0.1150 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0090 - val_mae: 0.1136 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0067 - mae: 0.0870 - val_loss: 0.0088 - val_mae: 0.1121 - learning_rate: 2.5000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "검증 세트 MSE: 0.010807813131795675\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/267850/_267850_재무제표 ().csv'\n",
      "267850의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "267850의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.0 ~ 0.9999999999999998\n",
      "267850 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0000000000000004\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.2805 - mae: 0.7239 - val_loss: 0.0214 - val_mae: 0.1633 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2075 - mae: 0.6202 - val_loss: 0.0141 - val_mae: 0.1348 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1607 - mae: 0.5419 - val_loss: 0.0094 - val_mae: 0.1175 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1121 - mae: 0.4504 - val_loss: 0.0082 - val_mae: 0.1147 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0756 - mae: 0.3628 - val_loss: 0.0109 - val_mae: 0.1292 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0360 - mae: 0.2434 - val_loss: 0.0184 - val_mae: 0.1645 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0199 - mae: 0.1710 - val_loss: 0.0307 - val_mae: 0.2205 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0075 - mae: 0.1042 - val_loss: 0.0459 - val_mae: 0.2825 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0063 - mae: 0.0905 - val_loss: 0.0599 - val_mae: 0.3293 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0111 - mae: 0.1104 - val_loss: 0.0633 - val_mae: 0.3397 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0116 - mae: 0.1154 - val_loss: 0.0633 - val_mae: 0.3396 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0128 - mae: 0.1261 - val_loss: 0.0606 - val_mae: 0.3314 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0115 - mae: 0.1150 - val_loss: 0.0565 - val_mae: 0.3189 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0073 - mae: 0.0914 - val_loss: 0.0526 - val_mae: 0.3062 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "검증 세트 MSE: 0.019541519821417913\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.2123287671232874 ~ 1.0000000000000004\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.2130 - mae: 0.6087 - val_loss: 0.4963 - val_mae: 0.9927 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1358 - mae: 0.4824 - val_loss: 0.3656 - val_mae: 0.8496 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1014 - mae: 0.4202 - val_loss: 0.2754 - val_mae: 0.7364 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0736 - mae: 0.3534 - val_loss: 0.2061 - val_mae: 0.6357 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0486 - mae: 0.2862 - val_loss: 0.1498 - val_mae: 0.5401 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0315 - mae: 0.2294 - val_loss: 0.1047 - val_mae: 0.4493 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0187 - mae: 0.1764 - val_loss: 0.0686 - val_mae: 0.3611 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0098 - mae: 0.1240 - val_loss: 0.0416 - val_mae: 0.2775 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0726 - val_loss: 0.0229 - val_mae: 0.2006 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0117 - val_mae: 0.1385 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0421 - val_loss: 0.0064 - val_mae: 0.1031 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0632 - val_loss: 0.0049 - val_mae: 0.0913 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0729 - val_loss: 0.0053 - val_mae: 0.0953 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0651 - val_loss: 0.0073 - val_mae: 0.1092 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0539 - val_loss: 0.0105 - val_mae: 0.1311 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0142 - val_mae: 0.1524 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0425 - val_loss: 0.0178 - val_mae: 0.1739 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0190 - val_mae: 0.1809 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0197 - val_mae: 0.1843 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0389 - val_loss: 0.0196 - val_mae: 0.1840 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0191 - val_mae: 0.1811 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0385 - val_loss: 0.0183 - val_mae: 0.1769 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "검증 세트 MSE: 0.014991244630466683\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0235294117647058 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.2461 - mae: 0.6787 - val_loss: 0.1251 - val_mae: 0.4805 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1882 - mae: 0.5884 - val_loss: 0.1009 - val_mae: 0.4289 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1534 - mae: 0.5286 - val_loss: 0.0798 - val_mae: 0.3785 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1155 - mae: 0.4560 - val_loss: 0.0605 - val_mae: 0.3255 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0848 - mae: 0.3866 - val_loss: 0.0430 - val_mae: 0.2737 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0571 - mae: 0.3152 - val_loss: 0.0281 - val_mae: 0.2229 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0370 - mae: 0.2457 - val_loss: 0.0167 - val_mae: 0.1709 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0185 - mae: 0.1699 - val_loss: 0.0093 - val_mae: 0.1201 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0112 - mae: 0.1206 - val_loss: 0.0057 - val_mae: 0.0842 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0108 - mae: 0.1096 - val_loss: 0.0052 - val_mae: 0.0729 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0135 - mae: 0.1214 - val_loss: 0.0057 - val_mae: 0.0769 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0136 - mae: 0.1240 - val_loss: 0.0057 - val_mae: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0182 - mae: 0.1411 - val_loss: 0.0054 - val_mae: 0.0734 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0125 - mae: 0.1178 - val_loss: 0.0053 - val_mae: 0.0767 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0131 - mae: 0.1163 - val_loss: 0.0056 - val_mae: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0095 - mae: 0.1025 - val_loss: 0.0059 - val_mae: 0.0859 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0088 - mae: 0.1038 - val_loss: 0.0061 - val_mae: 0.0886 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.1050 - val_loss: 0.0064 - val_mae: 0.0912 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0096 - mae: 0.0995 - val_loss: 0.0066 - val_mae: 0.0931 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0112 - mae: 0.1133 - val_loss: 0.0067 - val_mae: 0.0944 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "검증 세트 MSE: 0.028121982009216503\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.2524 - mae: 0.6777 - val_loss: 0.0127 - val_mae: 0.1372 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1979 - mae: 0.5994 - val_loss: 0.0086 - val_mae: 0.1125 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1480 - mae: 0.5173 - val_loss: 0.0056 - val_mae: 0.0932 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1200 - mae: 0.4575 - val_loss: 0.0035 - val_mae: 0.0754 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0857 - mae: 0.3831 - val_loss: 0.0024 - val_mae: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0573 - mae: 0.3026 - val_loss: 0.0017 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0373 - mae: 0.2379 - val_loss: 0.0016 - val_mae: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0250 - mae: 0.1817 - val_loss: 0.0023 - val_mae: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0136 - mae: 0.1276 - val_loss: 0.0041 - val_mae: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0082 - mae: 0.0899 - val_loss: 0.0069 - val_mae: 0.1058 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0065 - mae: 0.0907 - val_loss: 0.0100 - val_mae: 0.1327 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0068 - mae: 0.1022 - val_loss: 0.0123 - val_mae: 0.1488 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0080 - mae: 0.1072 - val_loss: 0.0126 - val_mae: 0.1512 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.1123 - val_loss: 0.0122 - val_mae: 0.1486 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0088 - mae: 0.1133 - val_loss: 0.0113 - val_mae: 0.1422 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0073 - mae: 0.1009 - val_loss: 0.0101 - val_mae: 0.1336 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0069 - mae: 0.0996 - val_loss: 0.0088 - val_mae: 0.1232 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "검증 세트 MSE: 0.0066818712814551125\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.1771 - mae: 0.5238 - val_loss: 0.4729 - val_mae: 0.9705 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1337 - mae: 0.4460 - val_loss: 0.3564 - val_mae: 0.8399 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1056 - mae: 0.3878 - val_loss: 0.2813 - val_mae: 0.7457 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0757 - mae: 0.3281 - val_loss: 0.2190 - val_mae: 0.6575 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0575 - mae: 0.2893 - val_loss: 0.1637 - val_mae: 0.5672 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0438 - mae: 0.2559 - val_loss: 0.1151 - val_mae: 0.4739 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0299 - mae: 0.2068 - val_loss: 0.0755 - val_mae: 0.3810 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0206 - mae: 0.1697 - val_loss: 0.0453 - val_mae: 0.2909 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0153 - mae: 0.1412 - val_loss: 0.0252 - val_mae: 0.2080 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0110 - mae: 0.1188 - val_loss: 0.0144 - val_mae: 0.1435 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0104 - mae: 0.1166 - val_loss: 0.0092 - val_mae: 0.1000 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0113 - mae: 0.1162 - val_loss: 0.0068 - val_mae: 0.0817 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0104 - mae: 0.1157 - val_loss: 0.0062 - val_mae: 0.0782 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.1110 - val_loss: 0.0071 - val_mae: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.1211 - val_loss: 0.0087 - val_mae: 0.0956 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0103 - mae: 0.1127 - val_loss: 0.0108 - val_mae: 0.1134 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0104 - mae: 0.1120 - val_loss: 0.0123 - val_mae: 0.1263 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0115 - mae: 0.1209 - val_loss: 0.0135 - val_mae: 0.1355 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.1203 - val_loss: 0.0141 - val_mae: 0.1399 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0083 - mae: 0.0987 - val_loss: 0.0143 - val_mae: 0.1411 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0095 - mae: 0.1101 - val_loss: 0.0143 - val_mae: 0.1411 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0116 - mae: 0.1176 - val_loss: 0.0142 - val_mae: 0.1403 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0138 - val_mae: 0.1377 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "검증 세트 MSE: 0.012327566413414232\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/011420/_011420_재무제표 ().csv'\n",
      "011420의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "011420의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "011420 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.09397344228804894 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1242 - mae: 0.4188 - val_loss: 0.1712 - val_mae: 0.5797 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1111 - mae: 0.3980 - val_loss: 0.1295 - val_mae: 0.5032 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0817 - mae: 0.3260 - val_loss: 0.1009 - val_mae: 0.4432 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0576 - mae: 0.2650 - val_loss: 0.0753 - val_mae: 0.3817 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0461 - mae: 0.2449 - val_loss: 0.0527 - val_mae: 0.3174 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0361 - mae: 0.2175 - val_loss: 0.0342 - val_mae: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0230 - mae: 0.1771 - val_loss: 0.0201 - val_mae: 0.1908 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0150 - mae: 0.1510 - val_loss: 0.0102 - val_mae: 0.1302 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0154 - mae: 0.1546 - val_loss: 0.0046 - val_mae: 0.0863 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0175 - mae: 0.1620 - val_loss: 0.0025 - val_mae: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0183 - mae: 0.1629 - val_loss: 0.0023 - val_mae: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0171 - mae: 0.1551 - val_loss: 0.0029 - val_mae: 0.0685 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1490 - val_loss: 0.0044 - val_mae: 0.0839 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0132 - mae: 0.1410 - val_loss: 0.0062 - val_mae: 0.1010 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0126 - mae: 0.1366 - val_loss: 0.0081 - val_mae: 0.1154 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0111 - mae: 0.1248 - val_loss: 0.0094 - val_mae: 0.1243 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0127 - mae: 0.1376 - val_loss: 0.0091 - val_mae: 0.1222 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0110 - mae: 0.1250 - val_loss: 0.0083 - val_mae: 0.1166 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0122 - mae: 0.1281 - val_loss: 0.0072 - val_mae: 0.1083 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0112 - mae: 0.1270 - val_loss: 0.0061 - val_mae: 0.0996 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0109 - mae: 0.1255 - val_loss: 0.0051 - val_mae: 0.0908 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "검증 세트 MSE: 0.011421158986977433\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0\n",
      "y_train 값 범위: 0.0 ~ 1.0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1536 - mae: 0.5278 - val_loss: 0.0049 - val_mae: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1172 - mae: 0.4526 - val_loss: 0.0037 - val_mae: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0723 - mae: 0.3445 - val_loss: 0.0080 - val_mae: 0.1010 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0464 - mae: 0.2575 - val_loss: 0.0173 - val_mae: 0.1717 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0217 - mae: 0.1705 - val_loss: 0.0313 - val_mae: 0.2418 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0135 - mae: 0.1315 - val_loss: 0.0467 - val_mae: 0.3004 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0123 - mae: 0.1294 - val_loss: 0.0560 - val_mae: 0.3305 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0145 - mae: 0.1427 - val_loss: 0.0536 - val_mae: 0.3231 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0140 - mae: 0.1405 - val_loss: 0.0465 - val_mae: 0.3004 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0133 - mae: 0.1367 - val_loss: 0.0384 - val_mae: 0.2717 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0097 - mae: 0.1175 - val_loss: 0.0312 - val_mae: 0.2436 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0986 - val_loss: 0.0253 - val_mae: 0.2172 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "검증 세트 MSE: 0.010321957503734446\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/020000/_020000_재무제표 ().csv'\n",
      "020000의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "020000의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.06578947368421062 ~ 1.0\n",
      "020000 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "[DEBUG] 재무제표 데이터 로드: True\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: 0.0 ~ 1.0000000000000002\n",
      "y_train 값 범위: 0.0 ~ 0.4136253041362532\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0599 - mae: 0.3391 - val_loss: 0.0070 - val_mae: 0.0993 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0395 - mae: 0.2737 - val_loss: 0.0032 - val_mae: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0267 - mae: 0.2218 - val_loss: 0.0018 - val_mae: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0182 - mae: 0.1812 - val_loss: 0.0015 - val_mae: 0.0469 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0135 - mae: 0.1506 - val_loss: 0.0026 - val_mae: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0082 - mae: 0.1092 - val_loss: 0.0051 - val_mae: 0.0893 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0838 - val_loss: 0.0089 - val_mae: 0.1253 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0668 - val_loss: 0.0133 - val_mae: 0.1573 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - mae: 0.0576 - val_loss: 0.0175 - val_mae: 0.1824 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0607 - val_loss: 0.0190 - val_mae: 0.1905 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0668 - val_loss: 0.0191 - val_mae: 0.1912 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0694 - val_loss: 0.0187 - val_mae: 0.1886 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029 - mae: 0.0621 - val_loss: 0.0178 - val_mae: 0.1838 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029 - mae: 0.0603 - val_loss: 0.0164 - val_mae: 0.1758 - learning_rate: 5.0000e-04\n",
      "\n",
      "[DEBUG] 모델 평가:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "검증 세트 MSE: 0.0035810561350440363\n",
      "로드 데이터 함수 시작\n",
      "[DEBUG] 새로운 데이터 로드 시도\n",
      "[DEBUG] 연도: 2022, 월: 10\n",
      "[DEBUG] 매핑된 분기: Q4\n",
      "재무제표를 불러오는 과정에서 오류가 발생했습니다 | [Errno 2] No such file or directory: '/Users/gamjawon/finTF/pipeline/sub_func/get_info/../../../store_data/raw/opendart/store_financial_statement/003160/_003160_재무제표 ().csv'\n",
      "003160의 이전 년도 재무 데이터를 불러올 수 없습니다.\n",
      "003160의 fin_statement_info 정보를 확인할 수 없습니다.\n",
      "[DEBUG] 재무제표 데이터 로드: False\n",
      "\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 시도\n",
      "[DEBUG] 외국인 보유 비중 데이터 로드 성공\n",
      "[DEBUG] 데이터 병합 완료\n",
      "[DEBUG] 최종 데이터 shape: (62, 5)\n",
      "[DEBUG] 학습 데이터 통계:\n",
      "X_train shape: (47, 15, 3)\n",
      "y_train shape: (47,)\n",
      "X_train 값 범위: nan ~ nan\n",
      "y_train 값 범위: 0.17263843648208432 ~ 1.0\n",
      "003160 예측 중 오류 발생: 입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/Users/gamjawon/finTF/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "093050 트레이더 보고서 추출 완료\n",
      "035720 트레이더 보고서 추출 완료\n",
      "031430 트레이더 보고서 추출 완료\n",
      "011070 트레이더 보고서 추출 완료\n",
      "000480 트레이더 보고서 추출 완료\n",
      "039130 트레이더 보고서 추출 완료\n",
      "033660 트레이더 보고서 추출 완료\n",
      "195870 트레이더 보고서 추출 완료\n",
      "029460 트레이더 보고서 추출 완료\n",
      "264900 트레이더 보고서 추출 완료\n",
      "077500 트레이더 보고서 추출 완료\n",
      "267850 트레이더 보고서 추출 완료\n",
      "092220 트레이더 보고서 추출 완료\n",
      "004370 트레이더 보고서 추출 완료\n",
      "001740 트레이더 보고서 추출 완료\n",
      "007810 트레이더 보고서 추출 완료\n",
      "008770 트레이더 보고서 추출 완료\n",
      "011420 트레이더 보고서 추출 완료\n",
      "025560 트레이더 보고서 추출 완료\n",
      "000990 트레이더 보고서 추출 완료\n",
      "020000 트레이더 보고서 추출 완료\n",
      "023800 트레이더 보고서 추출 완료\n",
      "003160 트레이더 보고서 추출 완료\n",
      "2022_Q4_final_trader_report 보고서를 노션 DB에 저장합니다...\n",
      "페이지 생성 완료: 188cd049-9633-816b-bbc1-dc5dbcff68d3\n",
      "텍스트 블럭 추가 완료\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tickers = get_tickers_from_json('pf_selection_agent', '2022_Q4_init_pf')\n",
    "    year = \"2022\"\n",
    "    quarter = \"Q4\"\n",
    "    \n",
    "    trader = TraderReportGenerator(tickers, year, quarter)\n",
    "    \n",
    "    # 필요한 데이터 설정\n",
    "    trader.set_price_data()\n",
    "    trader.get_price_prediction()\n",
    "    \n",
    "    # 각 종목별 트레이더 보고서 생성\n",
    "    for ticker in tickers:\n",
    "        trader.generate_individual_report(ticker)\n",
    "        print(f\"{ticker} 트레이더 보고서 추출 완료\")\n",
    "    \n",
    "    # 최종 트레이더 보고서 생성\n",
    "    final_report = trader.generate_final_report()\n",
    "    trader.save_final_report(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.1.21-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.69.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/gamjawon/finTF/venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl (239.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.1.21-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.69.0-cp312-cp312-macosx_10_14_universal2.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp312-cp312-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl (405 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.8/417.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.0-cp312-cp312-macosx_11_0_arm64.whl (335 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.8/335.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.1.21 gast-0.6.0 google-pasta-0.2.0 grpcio-1.69.0 h5py-3.12.1 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 protobuf-5.29.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wheel-0.45.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sub_func import *\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "from pykrx import stock\n",
    "\n",
    "def predict_multiple_prices(tickers: list, start_date: str, end_date: str, price_data_dict=None) -> dict:\n",
    "    predictions = {}\n",
    "    \n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = load_stock_data(ticker, start_date, end_date)\n",
    "            if data is None:\n",
    "                continue\n",
    "                \n",
    "            # PER이 0인 경우 처리\n",
    "            if np.all(data['PER'] == 0):\n",
    "                print(\"[WARNING] PER이 모두 0입니다. 평균값으로 대체합니다.\")\n",
    "                data['PER'] = 15.0  # 일반적인 PER 평균값으로 대체\n",
    "            \n",
    "            # 스케일링\n",
    "            scaler = MinMaxScaler()\n",
    "            scaled_data = scaler.fit_transform(data[['close', 'high', 'PER', 'foreign_holding']])\n",
    "            data[['close', 'high', 'PER', 'foreign_holding']] = scaled_data\n",
    "            \n",
    "            # 시계열 데이터 준비\n",
    "            window_size = 15\n",
    "            X = []\n",
    "            y = []\n",
    "            for i in range(window_size, len(data)):\n",
    "                X.append(data[['high', 'PER', 'foreign_holding']].values[i-window_size:i])\n",
    "                y.append(data['close'].values[i])\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            \n",
    "            # 모델 학습\n",
    "            model = create_and_train_model(X, y, ticker)\n",
    "            \n",
    "            # 예측 수행\n",
    "            last_sequence = X[-1:]\n",
    "            future_predictions = []\n",
    "            current_sequence = last_sequence.copy()\n",
    "            \n",
    "            for _ in range(20):\n",
    "                pred = model.predict(current_sequence, verbose=0)\n",
    "                future_predictions.append(float(pred[0, 0]))\n",
    "                \n",
    "                current_sequence = np.roll(current_sequence, -1, axis=1)\n",
    "                current_sequence[0, -1] = [pred[0, 0], data['PER'].iloc[-1], data['foreign_holding'].iloc[-1]]\n",
    "            \n",
    "            # 예측값 역변환\n",
    "            future_predictions = np.array(future_predictions).reshape(-1, 1)\n",
    "            future_predictions = np.concatenate([future_predictions, np.zeros((len(future_predictions), 3))], axis=1)\n",
    "            future_predictions = scaler.inverse_transform(future_predictions)[:, 0]\n",
    "            \n",
    "            predictions[ticker] = {\n",
    "                'current_price': float(scaler.inverse_transform([[data['close'].iloc[-1], 0, 0, 0]])[0, 0]),\n",
    "                'predicted_prices': future_predictions.tolist(),\n",
    "                'prediction_dates': pd.date_range(\n",
    "                    start=pd.to_datetime(data['date'].iloc[-1]) + pd.Timedelta(days=1),\n",
    "                    periods=20\n",
    "                ).strftime('%Y-%m-%d').tolist()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{ticker} 예측 중 오류 발생: {str(e)}\")\n",
    "            predictions[ticker] = None\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def predict_price(ticker: str, start_date: str = None, end_date: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    GRU 모델을 사용하여 주가를 예측하는 함수\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): 주식 종목 코드\n",
    "        start_date (str): 예측 시작일 (YYYYMMDD 형식)\n",
    "        end_date (str): 예측 종료일 (YYYYMMDD 형식)\n",
    "    \n",
    "    Returns:\n",
    "        dict: 예측 결과를 담은 딕셔너리\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 모델 및 스케일러 경로 설정\n",
    "        MODEL_PATH = f'models/{ticker}_gru_model.h5'\n",
    "        SCALER_PATH = f'models/{ticker}_scaler.pkl'\n",
    "        \n",
    "        # 데이터 로드 \n",
    "        data = load_stock_data(ticker, start_date, end_date)  \n",
    "        \n",
    "        # 데이터 전처리\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        data = data.sort_values('date')\n",
    "        \n",
    "        # 저장된 스케일러 로드 또는 새로 생성\n",
    "        if os.path.exists(SCALER_PATH):\n",
    "            scaler = joblib.load(SCALER_PATH)\n",
    "        else:\n",
    "            scaler = MinMaxScaler()\n",
    "            data[['close', 'high', 'PER', 'foreign_holding']] = scaler.fit_transform(\n",
    "                data[['close', 'high', 'PER', 'foreign_holding']]\n",
    "            )\n",
    "            joblib.dump(scaler, SCALER_PATH)\n",
    "        \n",
    "        # 시계열 데이터 준비\n",
    "        window_size = 15\n",
    "        X = []\n",
    "        for i in range(window_size, len(data)):\n",
    "            X.append(data[['high', 'PER', 'foreign_holding']].values[i-window_size:i])\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # 모델 로드 또는 새로 생성\n",
    "        if os.path.exists(MODEL_PATH):\n",
    "            model = load_model(MODEL_PATH)\n",
    "        else:\n",
    "            model = create_and_train_model(X, data['close'].values[window_size:], ticker)\n",
    "        \n",
    "        # 다음 분기 예측\n",
    "        future_predictions = []\n",
    "        last_sequence = X[-1:]\n",
    "        \n",
    "        # 다음 20일(약 한 달) 예측\n",
    "        for _ in range(20):\n",
    "            next_pred = model.predict(last_sequence)\n",
    "            future_predictions.append(next_pred[0, 0])\n",
    "            \n",
    "            # 다음 예측을 위한 시퀀스 업데이트\n",
    "            last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "            last_sequence[0, -1] = next_pred\n",
    "        \n",
    "        # 예측값 역변환\n",
    "        future_predictions = np.array(future_predictions).reshape(-1, 1)\n",
    "        future_predictions = scaler.inverse_transform(\n",
    "            np.concatenate((future_predictions, np.zeros((future_predictions.shape[0], 3))), axis=1)\n",
    "        )[:, 0]\n",
    "        \n",
    "        # 결과 정리\n",
    "        result = {\n",
    "            'current_price': data['close'].iloc[-1],\n",
    "            'predicted_prices': future_predictions.tolist(),\n",
    "            'prediction_dates': pd.date_range(\n",
    "                start=data['date'].iloc[-1] + pd.Timedelta(days=1), \n",
    "                periods=20\n",
    "            ).strftime('%Y-%m-%d').tolist(),\n",
    "            'confidence_level': calculate_confidence_level(model, X, data['close'].values[window_size:])\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"예측 중 오류 발생: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_and_train_model(X_train, y_train, ticker):\n",
    "    \"\"\"GRU 모델 생성 및 학습\"\"\"\n",
    "    print(f\"[DEBUG] 학습 데이터 통계:\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_train 값 범위: {np.min(X_train)} ~ {np.max(X_train)}\")\n",
    "    print(f\"y_train 값 범위: {np.min(y_train)} ~ {np.max(y_train)}\")\n",
    "\n",
    "    # 입력 데이터 검증\n",
    "    if np.any(np.isnan(X_train)) or np.any(np.isinf(X_train)):\n",
    "        raise ValueError(\"입력 데이터에 NaN 또는 무한값이 포함되어 있습니다.\")\n",
    "\n",
    "    if np.any(np.isnan(y_train)) or np.any(np.isinf(y_train)):\n",
    "        raise ValueError(\"타겟 데이터에 NaN 또는 무한값이 포함되어 있습니다.\")\n",
    "\n",
    "    # 모델 구조\n",
    "    model = Sequential([\n",
    "        GRU(32, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # 컴파일\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # 콜백\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=0.0001\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 학습\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=16,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 학습 결과 검증\n",
    "    print(\"\\n[DEBUG] 모델 평가:\")\n",
    "    val_predictions = model.predict(X_train[-int(len(X_train)*0.2):])\n",
    "    val_true = y_train[-int(len(y_train)*0.2):]\n",
    "    mse = np.mean((val_predictions - val_true) ** 2)\n",
    "    print(f\"검증 세트 MSE: {mse}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_confidence_level(model, X, y_true):\n",
    "    \"\"\"예측 신뢰도 계산\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    mse = np.mean((y_pred - y_true.reshape(-1, 1)) ** 2)\n",
    "    confidence = np.exp(-mse)  # 0~1 사이의 값으로 변환\n",
    "    return float(confidence)\n",
    "\n",
    "def load_stock_data(ticker: str, start_date: str, end_date: str, price_data=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    주식 데이터를 로드하는 함수\n",
    "    price_data: TraderReportGenerator에서 이미 로드된 가격 데이터\n",
    "    \"\"\"\n",
    "    print(\"로드 데이터 함수 시작\")\n",
    "    try:\n",
    "        if price_data is not None:\n",
    "            print(\"[DEBUG] 기존 price_data 사용\")  # 디버깅\n",
    "            selected_data = pd.DataFrame()\n",
    "            selected_data['close'] = price_data['Close']\n",
    "            selected_data['high'] = price_data['High']\n",
    "            selected_data['date'] = price_data.index\n",
    "            selected_data = selected_data.reset_index(drop=True)\n",
    "        else:\n",
    "            print(\"[DEBUG] 새로운 데이터 로드 시도\")  # 디버깅\n",
    "            price_data = stock_price_info(ticker, start_date, end_date)\n",
    "            \n",
    "            if price_data is None:\n",
    "                print(f\"Warning: 가격 데이터를 가져올 수 없습니다: {ticker}\")\n",
    "                return None\n",
    "            \n",
    "            selected_data = pd.DataFrame()\n",
    "            selected_data['close'] = price_data['Close']\n",
    "            selected_data['high'] = price_data['High']\n",
    "            selected_data['date'] = price_data.index\n",
    "            selected_data = selected_data.reset_index(drop=True)\n",
    "            \n",
    "        # 연도와 분기 추출\n",
    "        year = start_date[:4]\n",
    "        month = start_date[4:6]\n",
    "        print(f\"[DEBUG] 연도: {year}, 월: {month}\")  # 디버깅\n",
    "        \n",
    "        # 분기 매핑\n",
    "        quarter_map = {\n",
    "            'Q1': ['01', '02', '03'],\n",
    "            'Q2': ['04', '05', '06'],\n",
    "            'Q3': ['07', '08', '09'],\n",
    "            'Q4': ['10', '11', '12']\n",
    "        }\n",
    "        \n",
    "        quarter = next(q for q, months in quarter_map.items() if month in months)\n",
    "        print(f\"[DEBUG] 매핑된 분기: {quarter}\")  # 디버깅\n",
    "        \n",
    "        # PER 데이터 가져오기\n",
    "        fin_data = fin_statement_info(ticker, year, quarter)\n",
    "        print(f\"[DEBUG] 재무제표 데이터 로드: {fin_data is not None}\")  # 디버깅\n",
    "        \n",
    "        if fin_data is not None:\n",
    "            per_value = fin_data['PER'].iloc[0]\n",
    "        else:\n",
    "            per_value = None\n",
    "            \n",
    "        # PER 컬럼 추가\n",
    "        selected_data['PER'] = per_value\n",
    "        \n",
    "        # 외국인 보유 비중 추가\n",
    "        try:\n",
    "            print(\"\\n[DEBUG] 외국인 보유 비중 데이터 로드 시도\")\n",
    "            foreign_data = stock.get_exhaustion_rates_of_foreign_investment(start_date, end_date, ticker)\n",
    "            print(f\"[DEBUG] 외국인 보유 비중 데이터 로드 성공\")\n",
    "            \n",
    "            # 데이터 병합을 위해 인덱스 처리\n",
    "            selected_data['date'] = pd.to_datetime(selected_data['date'])\n",
    "            foreign_data = foreign_data.reset_index()\n",
    "            foreign_data.columns = ['date' if col == '날짜' else col for col in foreign_data.columns]\n",
    "            foreign_data['date'] = pd.to_datetime(foreign_data['date'])\n",
    "            \n",
    "            # 날짜 기준으로 데이터 병합\n",
    "            selected_data = pd.merge(selected_data, \n",
    "                                   foreign_data[['date', '지분율']], \n",
    "                                   on='date', \n",
    "                                   how='left')\n",
    "            selected_data = selected_data.rename(columns={'지분율': 'foreign_holding'})\n",
    "            \n",
    "            print(\"[DEBUG] 데이터 병합 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] 외국인 보유 비중 로드 실패: {str(e)}\")\n",
    "            selected_data['foreign_holding'] = 0\n",
    "            \n",
    "        print(f\"[DEBUG] 최종 데이터 shape: {selected_data.shape}\")  # 디버깅\n",
    "        return selected_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"데이터 로드 중 오류 발생: {str(e)}\")\n",
    "        print(f\"[DEBUG] 오류 발생 위치 정보: {e.__traceback__.tb_lineno}\")  # 디버깅\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
